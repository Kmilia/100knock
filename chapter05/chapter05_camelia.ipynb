{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 07:31:55 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2022-02-01 07:31:55 INFO: Use device: cpu\n",
      "2022-02-01 07:31:55 INFO: Loading: tokenize\n",
      "2022-02-01 07:31:55 INFO: Loading: pos\n",
      "2022-02-01 07:31:56 INFO: Loading: lemma\n",
      "2022-02-01 07:31:56 INFO: Loading: depparse\n",
      "2022-02-01 07:31:57 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "_nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,pos,lemma,depparse\")\n",
    "\n",
    "_AI_FILE = \"data/ai.en/ai.en.txt\"\n",
    "_OUTPUT_FILE = \"data/ai.en.depparse.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 40. Read the parse result (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, word: dict) -> None:\n",
    "        self.id = int(word.id) - 1\n",
    "        self.text = word.text.lower()\n",
    "        self.pos = word.xpos\n",
    "        self.lemma = word.lemma.lower()\n",
    "        self.head = int(word.head) - 1\n",
    "        self.dep = word.deprel\n",
    "        self.children = []\n",
    "            \n",
    "    def __str__(self) -> str:\n",
    "        children = [child.text for child in self.children]\n",
    "        return f\"id: {self.id}\\n\" \\\n",
    "               f\"text: {self.text}\\nlemma: {self.lemma}\\npos: {self.pos}\\n\"\\\n",
    "               f\"head: {self.head}\\ndep: {self.dep}\\nchildren: {children}\\n\"\n",
    "    \n",
    "    def add_child(self, word: object) -> None:\n",
    "        self.children.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_data(file_object, CHUNK_SIZE: int = -1) -> str:\n",
    "    while True:\n",
    "        data = file_object.read(CHUNK_SIZE)\n",
    "        if not data:\n",
    "            break\n",
    "        yield data\n",
    "\n",
    "_sentences = []\n",
    "\n",
    "with open(_AI_FILE) as _input_file, open(_OUTPUT_FILE, \"w\") as _output_file:\n",
    "    for data in _read_data(_input_file):\n",
    "        doc = _nlp(data)\n",
    "        for sentence in doc.sentences:\n",
    "            current_sent = []\n",
    "            for word in sentence.words:\n",
    "                _output_file.write(f\"{sentence.id} {word}\\n\")\n",
    "                current_sent.append(Word(word))\n",
    "            _sentences.append(current_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0\n",
      "text: in\n",
      "lemma: in\n",
      "pos: IN\n",
      "head: 2\n",
      "dep: case\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 1\n",
      "text: computer\n",
      "lemma: computer\n",
      "pos: NN\n",
      "head: 2\n",
      "dep: compound\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 2\n",
      "text: science\n",
      "lemma: science\n",
      "pos: NN\n",
      "head: 16\n",
      "dep: obl\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 3\n",
      "text: ,\n",
      "lemma: ,\n",
      "pos: ,\n",
      "head: 16\n",
      "dep: punct\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 4\n",
      "text: artificial\n",
      "lemma: artificial\n",
      "pos: JJ\n",
      "head: 5\n",
      "dep: amod\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 5\n",
      "text: intelligence\n",
      "lemma: intelligence\n",
      "pos: NN\n",
      "head: 16\n",
      "dep: nsubj\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 6\n",
      "text: (\n",
      "lemma: (\n",
      "pos: -LRB-\n",
      "head: 7\n",
      "dep: punct\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 7\n",
      "text: ai\n",
      "lemma: ai\n",
      "pos: NN\n",
      "head: 5\n",
      "dep: appos\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 8\n",
      "text: )\n",
      "lemma: )\n",
      "pos: -RRB-\n",
      "head: 7\n",
      "dep: punct\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 9\n",
      "text: ,\n",
      "lemma: ,\n",
      "pos: ,\n",
      "head: 11\n",
      "dep: punct\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 10\n",
      "text: sometimes\n",
      "lemma: sometimes\n",
      "pos: RB\n",
      "head: 11\n",
      "dep: advmod\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 11\n",
      "text: called\n",
      "lemma: call\n",
      "pos: VBN\n",
      "head: 5\n",
      "dep: acl\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 12\n",
      "text: machine\n",
      "lemma: machine\n",
      "pos: NN\n",
      "head: 13\n",
      "dep: compound\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 13\n",
      "text: intelligence\n",
      "lemma: intelligence\n",
      "pos: NN\n",
      "head: 11\n",
      "dep: xcomp\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 14\n",
      "text: ,\n",
      "lemma: ,\n",
      "pos: ,\n",
      "head: 16\n",
      "dep: punct\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 15\n",
      "text: is\n",
      "lemma: be\n",
      "pos: VBZ\n",
      "head: 16\n",
      "dep: cop\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 16\n",
      "text: intelligence\n",
      "lemma: intelligence\n",
      "pos: NN\n",
      "head: -1\n",
      "dep: root\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 17\n",
      "text: demonstrated\n",
      "lemma: demonstrate\n",
      "pos: VBN\n",
      "head: 16\n",
      "dep: acl\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 18\n",
      "text: by\n",
      "lemma: by\n",
      "pos: IN\n",
      "head: 19\n",
      "dep: case\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 19\n",
      "text: machines\n",
      "lemma: machine\n",
      "pos: NNS\n",
      "head: 17\n",
      "dep: obl\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 20\n",
      "text: ,\n",
      "lemma: ,\n",
      "pos: ,\n",
      "head: 22\n",
      "dep: punct\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 21\n",
      "text: in\n",
      "lemma: in\n",
      "pos: IN\n",
      "head: 22\n",
      "dep: case\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 22\n",
      "text: contrast\n",
      "lemma: contrast\n",
      "pos: NN\n",
      "head: 17\n",
      "dep: obl\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 23\n",
      "text: to\n",
      "lemma: to\n",
      "pos: IN\n",
      "head: 26\n",
      "dep: case\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 24\n",
      "text: the\n",
      "lemma: the\n",
      "pos: DT\n",
      "head: 26\n",
      "dep: det\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 25\n",
      "text: natural\n",
      "lemma: natural\n",
      "pos: JJ\n",
      "head: 26\n",
      "dep: amod\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 26\n",
      "text: intelligence\n",
      "lemma: intelligence\n",
      "pos: NN\n",
      "head: 22\n",
      "dep: nmod\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 27\n",
      "text: displayed\n",
      "lemma: display\n",
      "pos: VBN\n",
      "head: 26\n",
      "dep: acl\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 28\n",
      "text: by\n",
      "lemma: by\n",
      "pos: IN\n",
      "head: 29\n",
      "dep: case\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 29\n",
      "text: humans\n",
      "lemma: human\n",
      "pos: NNS\n",
      "head: 27\n",
      "dep: obl\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 30\n",
      "text: and\n",
      "lemma: and\n",
      "pos: CC\n",
      "head: 31\n",
      "dep: cc\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 31\n",
      "text: animals\n",
      "lemma: animal\n",
      "pos: NNS\n",
      "head: 29\n",
      "dep: conj\n",
      "children: []\n",
      "\n",
      "\n",
      "id: 32\n",
      "text: .\n",
      "lemma: .\n",
      "pos: .\n",
      "head: 16\n",
      "dep: punct\n",
      "children: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in _sentences[0]:\n",
    "    print(f\"{word}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 41. Read the parse result (dependency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in _sentences:\n",
    "    for word in sentence:\n",
    "        if word.head > -1:\n",
    "            sentence[word.head].add_child(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show_sentence_pairs(sentence: list, sentence_number: int) -> None:\n",
    "    for word in sentence:\n",
    "        children = [child.lemma for child in word.children]\n",
    "        print(f\"SENTENCE N°{sentence_number} WORD {word.lemma} --> {children}\\n\")\n",
    "        \n",
    "_show_sentence_pairs(_sentences[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 42. Show root words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_root_words = []\n",
    "for sentence in _sentences:\n",
    "    index = 0\n",
    "    while sentence[index].head != -1:\n",
    "        index += 1\n",
    "    _root_words.append(sentence[index])\n",
    "\n",
    "for word in _root_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 43. Show verb governors and noun dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show_verb_noun_pairs(sentence: list, sentence_number: int) -> None:\n",
    "    for word in sentence:\n",
    "        head_word = sentence[word.head]\n",
    "        if head_word.pos.startswith(\"V\") and word.pos.startswith(\"N\"):\n",
    "            print(f\"SENTENCE N°{sentence_number} head: {head_word.lemma} --> noun: {word.lemma}\\n\")\n",
    "\n",
    "for index in range(0, len(_sentences)):\n",
    "    _show_verb_noun_pairs(_sentences[index], index)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 44. Visualize dependency trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "\n",
    "def _get_correct_syntax(word: Word) -> str:\n",
    "    return word.text.join([\"\\\"\", \"\\\"\"])\n",
    "\n",
    "def _draw_dependency_tree(FILE_NAME: str, sentence: list) -> str:\n",
    "    graph = pydot.Dot(FILE_NAME, graph_type=\"graph\")\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word.dep != \"punct\":\n",
    "            head = _get_correct_syntax(sentence[word.head])\n",
    "            tail = _get_correct_syntax(word)\n",
    "            graph.add_node(pydot.Node(head, xlabel=sentence[word.head].pos))\n",
    "            graph.add_node(pydot.Node(tail, xlabel=word.pos))\n",
    "            graph.add_edge(pydot.Edge(head, tail, label=word.dep))\n",
    "\n",
    "    graph.write_raw(\"\".join([FILE_NAME, \".dot\"]))\n",
    "    return graph.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 45. Triple with subject, verb, and direct object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_tuple_element(word: Word, component: list) -> list:\n",
    "    return component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_tuple(tuples: list, subject_type: str, object_type: str) -> None:\n",
    "    for sentence in _sentences:\n",
    "        for word in sentence:\n",
    "            if word.pos == \"VBD\":\n",
    "                _subject_flag = False\n",
    "                _object_flag = False\n",
    "                for child in word.children:\n",
    "                    if child.pos.startswith(\"N\") and child.dep.startswith(subject_type):\n",
    "                        _subject_flag = True\n",
    "                        _subject = \" \".join(_find_tuple_element(child, [child.text]))\n",
    "                    elif child.pos.startswith(\"N\") and child.dep.startswith(object_type):\n",
    "                        _object_flag = True\n",
    "                        _object = \" \".join(_find_tuple_element(child, [child.text]))\n",
    "                if _subject_flag and _object_flag:\n",
    "                    tuples.append((_subject, word.text, _object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('governments', 'cut', 'research'),\n",
       " ('project', 'inspired', 'governments'),\n",
       " ('development', 'enabled', 'development'),\n",
       " ('match', 'defeated', 'champions'),\n",
       " ('alphago', 'won', 'match'),\n",
       " ('china', 'accelerated', 'funding'),\n",
       " ('councilmen', 'refused', 'permit'),\n",
       " ('researchers', 'developed', 'algorithms'),\n",
       " ('deepmind', 'developed', 'intelligence'),\n",
       " ('number', 'explored', 'connection'),\n",
       " ('one', 'developed', 'style'),\n",
       " ('john', 'named', 'approaches'),\n",
       " ('economist', 'studied', 'skills'),\n",
       " ('work', 'laid', 'foundations'),\n",
       " ('team', 'used', 'results'),\n",
       " ('people', 'used', 'algorithms'),\n",
       " ('roger', 'described', 'approaches'),\n",
       " ('researchers', 'rejected', 'ai'),\n",
       " ('work', 'revived', 'point'),\n",
       " ('researchers', 'adopted', 'tools'),\n",
       " ('language', 'permitted', 'level'),\n",
       " ('frank', 'invented', 'perceptron'),\n",
       " ('publication', 'introduced', 'way'),\n",
       " ('yann', 'applied', 'backpropagation'),\n",
       " ('recognition', 'experienced', 'jump'),\n",
       " ('google', 'used', 'lstm'),\n",
       " ('lstm', 'improved', 'captioning'),\n",
       " ('alphago', 'brought', 'era'),\n",
       " ('machine', 'performed', 'diagnosis'),\n",
       " ('study', 'demonstrated', 'surgery'),\n",
       " ('team', 'supervised', 'robot'),\n",
       " ('association', 'dedicated', 'issue'),\n",
       " ('electronica', 'opened', 'exhibitions'),\n",
       " ('festival', 'thematized', 'role'),\n",
       " ('scientists', 'described', 'goals'),\n",
       " ('power', 'did', 'steam'),\n",
       " ('wendell', 'introduced', 'concept'),\n",
       " ('david', 'identified', 'problems'),\n",
       " ('writer', 'named', 'singularity'),\n",
       " ('survey', 'showed', 'disagreement'),\n",
       " ('union', 'published', 'paper'),\n",
       " ('isaac', 'introduced', 'laws'),\n",
       " ('sorayama', 'considered', 'robots')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tuples = []\n",
    "_find_tuple(_tuples, \"nsubj\", \"obj\")\n",
    "_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 46. Expanding subjects and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_tuple_element(word: Word, component: list) -> list:\n",
    "    for child in word.children:\n",
    "        if child.dep in (\"compound\", \"flat\", \"amod\"):\n",
    "            component.append(child.text)\n",
    "            _find_tuple_element(child, component)\n",
    "    return component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('governments u.s.', 'cut', 'research exploratory'),\n",
       " ('project generation fifth computer', 'inspired', 'governments u.s'),\n",
       " ('development', 'enabled', 'development'),\n",
       " ('match jeopardy quiz show exhibition',\n",
       "  'defeated',\n",
       "  'champions greatest jeopardy'),\n",
       " ('alphago', 'won', 'match game'),\n",
       " ('china', 'accelerated', 'funding government'),\n",
       " ('councilmen city', 'refused', 'permit'),\n",
       " ('researchers early', 'developed', 'algorithms'),\n",
       " ('deepmind', 'developed', 'intelligence generalized artificial'),\n",
       " ('number', 'explored', 'connection'),\n",
       " ('one', 'developed', 'style own'),\n",
       " ('john haugeland', 'named', 'approaches symbolic'),\n",
       " ('economist herbert simon', 'studied', 'skills human problem- solving'),\n",
       " ('work', 'laid', 'foundations'),\n",
       " ('team research', 'used', 'results'),\n",
       " ('people', 'used', 'algorithms same'),\n",
       " ('roger schank', 'described', 'approaches anti-logic'),\n",
       " ('researchers', 'rejected', 'ai symbolic'),\n",
       " ('work', 'revived', 'point non-symbolic'),\n",
       " ('researchers', 'adopted', 'tools sophisticated mathematical'),\n",
       " ('language shared mathematical', 'permitted', 'level high'),\n",
       " ('frank rosenblatt', 'invented', 'perceptron similar'),\n",
       " ('publication', 'introduced', 'way'),\n",
       " ('yann lecun', 'applied', 'backpropagation'),\n",
       " ('recognition speech', 'experienced', 'jump dramatic performance'),\n",
       " ('google', 'used', 'lstm'),\n",
       " ('lstm', 'improved', 'captioning automatic image'),\n",
       " ('alphago', 'brought', 'era'),\n",
       " ('machine', 'performed', 'diagnosis'),\n",
       " ('study recent', 'demonstrated', 'surgery'),\n",
       " ('team', 'supervised', 'robot'),\n",
       " ('association', 'dedicated', 'issue special magazine'),\n",
       " ('electronica austrian ars', 'opened', 'exhibitions'),\n",
       " ('festival', 'thematized', 'role'),\n",
       " ('scientists', 'described', 'goals term short research'),\n",
       " ('power', 'did', 'steam'),\n",
       " ('wendell wallach', 'introduced', 'concept'),\n",
       " ('david chalmers', 'identified', 'problems'),\n",
       " ('writer fiction science', 'named', 'singularity'),\n",
       " ('survey', 'showed', 'disagreement'),\n",
       " ('union european', 'published', 'paper strategy draft'),\n",
       " ('isaac asimov', 'introduced', 'laws'),\n",
       " ('sorayama', 'considered', 'robots organic')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tuples = []\n",
    "_find_tuple(_tuples, \"nsubj\", \"obj\")\n",
    "_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 47. Triple from the passive sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_object_element(word: Word, component: list) -> list:\n",
    "    for child in word.children:\n",
    "        if child.pos == \"IN\":\n",
    "            return component, child.text\n",
    "        if child.dep in (\"compound\", \"flat\", \"obl\", \"nmod\"):\n",
    "            component.append(child.text)\n",
    "            _find_object_element(child, component)\n",
    "    return component, \"\"\n",
    "                    \n",
    "def _find_tuple(tuples: list, subject_type: str, object_type: str) -> None:\n",
    "    for sentence in _sentences:\n",
    "        for word in sentence:\n",
    "            if word.pos == \"VBD\":\n",
    "                _subject_flag = False\n",
    "                _object_flag = False\n",
    "                for child in word.children:\n",
    "                    if child.dep.startswith(subject_type):\n",
    "                        _subject_flag = True\n",
    "                        _subject = \" \".join(_find_tuple_element(child, [child.text]))\n",
    "                    elif child.dep.startswith(object_type):\n",
    "                        _object_flag = True\n",
    "                        result, prep = _find_object_element(child, [child.text])\n",
    "                        _object = \" \".join(result)\n",
    "                    if _subject_flag and _object_flag:\n",
    "                        tuples.append((_subject, \"-\".join([word.text, prep]), _object))\n",
    "                        _object_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beings thought capable artificial', 'appeared-as', 'devices'),\n",
       " ('study', 'began-with', 'philosophers'),\n",
       " ('study', 'began-in', 'antiquity'),\n",
       " ('study', 'led-to', 'theory'),\n",
       " ('this', 'led-along', 'discoveries'),\n",
       " ('press', 'described-as', 'astonishing'),\n",
       " ('governments u.s.', 'cut-in', 'response'),\n",
       " ('governments u.s.', 'cut-in', 'ai'),\n",
       " ('project generation fifth computer', 'inspired-at', 'time'),\n",
       " ('development', 'enabled-in', 'form'),\n",
       " ('match jeopardy quiz show exhibition', 'defeated-in', '2011'),\n",
       " ('match jeopardy quiz show exhibition', 'defeated-by', 'margin'),\n",
       " ('that', 'emerged-from', 'research'),\n",
       " ('alphago', 'won-in', '2016'),\n",
       " ('alphago', 'won-out', 'games'),\n",
       " ('alphago', 'won-in', 'future'),\n",
       " ('who', 'held-at', 'time'),\n",
       " ('who', 'held-for', 'years'),\n",
       " ('one', 'reported-in', 'survey'),\n",
       " ('china', 'accelerated-around', '2016'),\n",
       " ('that', 'worked-in', 'past'),\n",
       " ('sun', 'rose-', 'morning'),\n",
       " ('sun', 'rose-for', 'days'),\n",
       " ('who', 'stated-in', '1988'),\n",
       " ('number', 'explored-in', '1940s'),\n",
       " ('john mccarthy', 'felt-unlike', 'simon'),\n",
       " ('which', 'led-to', 'development'),\n",
       " ('roger schank', 'described-as', 'scruffy'),\n",
       " ('revolution knowledge', 'led-to', 'development'),\n",
       " ('progress', 'seemed-by', '1980s'),\n",
       " ('this', 'coincided-with', 'development'),\n",
       " ('that', 'worked-on', 'models'),\n",
       " ('language shared mathematical', 'permitted-with', 'fields'),\n",
       " ('successes increased', 'led-to', 'emphasis'),\n",
       " ('approach', 'performed-in', 'context'),\n",
       " ('kind different', 'came-to', 'prominence'),\n",
       " ('kind different', 'came-in', '1990s'),\n",
       " ('study', 'began-in', 'decade'),\n",
       " ('igor aizenberg', 'introduced-to', 'networks'),\n",
       " ('igor aizenberg', 'introduced-in', '2000'),\n",
       " ('publication', 'introduced-in', '2006'),\n",
       " ('yann lecun', 'applied-in', '1989'),\n",
       " ('yann lecun', 'applied-to', 'architecture'),\n",
       " ('cnns', 'processed-in', 'application'),\n",
       " ('cnns', 'processed-to', '% %'),\n",
       " ('that', 'beat-in', '2016'),\n",
       " ('recognition speech', 'experienced-in', '2015'),\n",
       " ('alphago', 'brought-to', 'close'),\n",
       " ('study groundbreaking', 'found-in', '2016'),\n",
       " ('formula mathematical', 'developed-with', 'help'),\n",
       " ('machine', 'performed-to', 'ophthalmologist'),\n",
       " ('study recent', 'demonstrated-', 'cnn'),\n",
       " ('study recent', 'demonstrated-with', 'robot'),\n",
       " ('spending worldwide annual military', 'rose-from', '$'),\n",
       " ('spending worldwide annual military', 'rose-in', '2010'),\n",
       " ('spending worldwide annual military', 'rose-to', '$'),\n",
       " ('artists', 'experimented-with', 'algorithm'),\n",
       " ('which', 'took-in', 'angeles'),\n",
       " ('which', 'took-in', 'fall'),\n",
       " ('association', 'dedicated-in', 'spring'),\n",
       " ('association', 'dedicated-to', 'subject'),\n",
       " ('electronica austrian ars', 'opened-on', 'ai'),\n",
       " ('electronica austrian ars', 'opened-in', '2019'),\n",
       " ('festival', 'thematized-for', 'transformation'),\n",
       " ('scientists', 'described-among', 'others'),\n",
       " ('musk', 'donated-in', 'january'),\n",
       " ('power', 'did-to', 'ones'),\n",
       " ('wendell wallach', 'introduced-in', 'book'),\n",
       " ('paper february union european white', 'advocated-for', 'intelligence'),\n",
       " ('elon musk', 'called-in', '2017'),\n",
       " ('elon musk', 'called-for', 'regulation'),\n",
       " ('union european', 'published-in', 'february'),\n",
       " ('beings thought capable artificial', 'appeared-as', 'devices'),\n",
       " ('beings thought capable artificial', 'appeared-since', 'antiquity'),\n",
       " ('trope common', 'began-with', 'frankenstein'),\n",
       " ('isaac asimov', 'introduced-in', 'books')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tuples = []\n",
    "_find_tuple(_tuples, \"nsubj\", \"obl\")\n",
    "_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 48. Extract paths from the root to nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intelligence -> science\n",
      "intelligence -> science -> computer\n",
      "intelligence -> intelligence\n",
      "intelligence -> intelligence -> ai\n",
      "intelligence -> intelligence -> intelligence\n",
      "intelligence -> intelligence -> intelligence -> machine\n",
      "intelligence -> machines\n",
      "intelligence -> contrast\n",
      "intelligence -> contrast -> intelligence\n",
      "intelligence -> contrast -> intelligence -> humans\n",
      "intelligence -> contrast -> intelligence -> humans -> animals\n",
      "define -> textbooks\n",
      "define -> field\n",
      "define -> study\n",
      "define -> study -> agents\n",
      "define -> study -> agents -> device\n",
      "define -> study -> agents -> device -> environment\n",
      "define -> study -> agents -> device -> actions\n",
      "define -> study -> agents -> device -> actions -> chance\n",
      "define -> study -> agents -> device -> actions -> chance -> goals\n",
      "used -> term\n",
      "used -> term -> intelligence\n",
      "used -> machines\n",
      "used -> machines -> computers\n",
      "used -> machines -> functions\n",
      "used -> machines -> functions -> humans\n",
      "used -> machines -> functions -> mind\n",
      "used -> machines -> functions -> mind -> learning\n",
      "used -> machines -> functions -> mind -> learning -> solving\n",
      "used -> machines -> functions -> mind -> learning -> solving -> problem\n",
      "removed -> machines\n",
      "removed -> tasks\n",
      "removed -> tasks -> intelligence\n",
      "removed -> definition\n",
      "removed -> definition -> ai\n",
      "removed -> definition -> phenomenon\n",
      "removed -> definition -> phenomenon -> effect\n",
      "removed -> definition -> phenomenon -> effect -> ai\n",
      "quip -> tesler\n",
      "says -> theorem\n",
      "excluded -> instance\n",
      "excluded -> recognition\n",
      "excluded -> recognition -> character\n",
      "excluded -> things\n",
      "excluded -> technology\n",
      "excluded -> technology -> routine\n",
      "capabilities -> machine\n",
      "capabilities -> speech\n",
      "capabilities -> level\n",
      "capabilities -> level -> systems\n",
      "capabilities -> level -> systems -> game\n",
      "capabilities -> level -> systems -> chess\n",
      "capabilities -> level -> systems -> chess -> go\n",
      "capabilities -> cars\n",
      "capabilities -> cars -> routing\n",
      "capabilities -> cars -> routing -> networks\n",
      "capabilities -> cars -> routing -> networks -> content\n",
      "capabilities -> cars -> routing -> networks -> delivery\n",
      "capabilities -> cars -> simulations\n",
      "founded -> intelligence\n",
      "founded -> discipline\n",
      "founded -> years\n",
      "founded -> waves\n",
      "founded -> waves -> optimism\n",
      "founded -> waves -> disappointment\n",
      "founded -> waves -> disappointment -> loss\n",
      "founded -> waves -> disappointment -> loss -> funding\n",
      "founded -> waves -> disappointment -> loss -> winter\n",
      "founded -> waves -> disappointment -> loss -> winter -> ai\n",
      "founded -> waves -> disappointment -> loss -> approaches\n",
      "founded -> waves -> disappointment -> loss -> approaches -> success\n",
      "founded -> waves -> disappointment -> loss -> approaches -> funding\n",
      "divided -> history\n",
      "divided -> research\n",
      "divided -> sub-fields\n",
      "based -> sub-fields\n",
      "based -> considerations\n",
      "based -> considerations -> goals\n",
      "based -> considerations -> goals -> robotics\n",
      "based -> considerations -> goals -> robotics -> learning\n",
      "based -> considerations -> goals -> robotics -> learning -> machine\n",
      "based -> considerations -> goals -> use\n",
      "based -> considerations -> goals -> use -> tools\n",
      "based -> considerations -> goals -> use -> tools -> logic\n",
      "based -> considerations -> goals -> use -> tools -> logic -> networks\n",
      "based -> considerations -> goals -> use -> tools -> differences\n",
      "based -> sub-fields\n",
      "based -> factors\n",
      "based -> factors -> institutions\n",
      "based -> factors -> institutions -> work\n",
      "based -> factors -> institutions -> work -> researchers\n",
      "include -> problems\n",
      "include -> problems -> goals\n",
      "include -> problems -> research\n",
      "include -> problems -> research -> ai\n",
      "include -> reasoning\n",
      "include -> reasoning -> representation\n",
      "include -> reasoning -> representation -> knowledge\n",
      "include -> reasoning -> planning\n",
      "include -> reasoning -> learning\n",
      "include -> reasoning -> processing\n",
      "include -> reasoning -> processing -> language\n",
      "include -> reasoning -> perception\n",
      "include -> reasoning -> ability\n",
      "include -> reasoning -> ability -> objects\n",
      "goals -> intelligence\n",
      "goals -> field\n",
      "include -> approaches\n",
      "include -> methods\n",
      "include -> methods -> intelligence\n",
      "include -> methods -> ai\n",
      "used -> tools\n",
      "used -> ai\n",
      "used -> ai -> versions\n",
      "used -> ai -> versions -> search\n",
      "used -> ai -> versions -> search -> optimization\n",
      "used -> ai -> versions -> search -> networks\n",
      "used -> ai -> versions -> methods\n",
      "used -> ai -> versions -> methods -> statistics\n",
      "used -> ai -> versions -> methods -> statistics -> probability\n",
      "used -> ai -> versions -> methods -> statistics -> economics\n",
      "draws -> field\n",
      "draws -> field -> ai\n",
      "draws -> science\n",
      "draws -> science -> computer\n",
      "draws -> science -> engineering\n",
      "draws -> science -> engineering -> information\n",
      "draws -> science -> mathematics\n",
      "draws -> science -> psychology\n",
      "draws -> science -> linguistics\n",
      "draws -> science -> philosophy\n",
      "draws -> science -> fields\n",
      "founded -> field\n",
      "founded -> assumption\n",
      "founded -> assumption -> intelligence\n",
      "founded -> assumption -> machine\n",
      "raises -> arguments\n",
      "raises -> arguments -> nature\n",
      "raises -> arguments -> nature -> mind\n",
      "raises -> arguments -> nature -> mind -> ethics\n",
      "raises -> arguments -> nature -> mind -> ethics -> beings\n",
      "raises -> arguments -> nature -> mind -> ethics -> beings -> intelligence\n",
      "explored -> issues\n",
      "explored -> myth\n",
      "explored -> myth -> fiction\n",
      "explored -> myth -> philosophy\n",
      "explored -> antiquity\n",
      "consider -> people\n",
      "consider -> danger\n",
      "consider -> danger -> humanity\n",
      "believe -> others\n",
      "believe -> revolutions\n",
      "believe -> risk\n",
      "believe -> risk -> unemployment\n",
      "experienced -> century\n",
      "experienced -> techniques\n",
      "experienced -> techniques -> ai\n",
      "experienced -> resurgence\n",
      "experienced -> resurgence -> advances\n",
      "experienced -> resurgence -> advances -> power\n",
      "experienced -> resurgence -> advances -> power -> computer\n",
      "experienced -> resurgence -> advances -> power -> amounts\n",
      "experienced -> resurgence -> advances -> power -> amounts -> data\n",
      "experienced -> resurgence -> advances -> power -> understanding\n",
      "experienced -> techniques\n",
      "experienced -> part\n",
      "experienced -> part -> industry\n",
      "experienced -> part -> industry -> technology\n",
      "experienced -> part -> problems\n",
      "experienced -> part -> problems -> science\n",
      "experienced -> part -> problems -> science -> computer\n",
      "experienced -> part -> problems -> science -> engineering\n",
      "experienced -> part -> problems -> science -> engineering -> software\n",
      "experienced -> part -> problems -> science -> research\n",
      "experienced -> part -> problems -> science -> research -> operations\n",
      "appeared -> beings\n",
      "appeared -> devices\n",
      "appeared -> devices -> storytelling\n",
      "appeared -> devices -> antiquity\n",
      "appeared -> fiction\n",
      "appeared -> frankenstein\n",
      "appeared -> frankenstein -> mary\n",
      "appeared -> frankenstein -> mary -> shelley\n",
      "appeared -> frankenstein -> r.u.r.\n",
      "appeared -> frankenstein -> r.u.r. -> karel\n",
      "appeared -> frankenstein -> r.u.r. -> karel -> čapek\n",
      "appeared -> frankenstein -> r.u.r. -> robots\n",
      "appeared -> frankenstein -> r.u.r. -> robots -> rossum\n",
      "appeared -> frankenstein -> r.u.r. -> robots -> universal\n",
      "raised -> characters\n",
      "raised -> characters -> fates\n",
      "raised -> issues\n",
      "raised -> issues -> ethics\n",
      "raised -> issues -> ethics -> intelligence\n",
      "began -> study\n",
      "began -> study -> reasoning\n",
      "began -> philosophers\n",
      "began -> philosophers -> mathematicians\n",
      "began -> antiquity\n",
      "led -> study\n",
      "led -> study -> logic\n",
      "led -> theory\n",
      "led -> theory -> alan\n",
      "led -> theory -> alan -> turing\n",
      "led -> theory -> computation\n",
      "led -> theory -> machine\n",
      "led -> theory -> machine -> symbols\n",
      "led -> theory -> act\n",
      "led -> theory -> act -> deduction\n",
      "known -> insight\n",
      "known -> insight -> computers\n",
      "known -> insight -> process\n",
      "known -> insight -> process -> reasoning\n",
      "known -> thesis\n",
      "known -> thesis -> church\n",
      "known -> thesis -> –turing\n",
      "led -> discoveries\n",
      "led -> discoveries -> neurobiology\n",
      "led -> discoveries -> neurobiology -> theory\n",
      "led -> discoveries -> neurobiology -> theory -> information\n",
      "led -> discoveries -> neurobiology -> cybernetics\n",
      "led -> researchers\n",
      "led -> possibility\n",
      "led -> possibility -> brain\n",
      "proposed -> turing\n",
      "proposed -> question\n",
      "proposed -> question -> machine\n",
      "proposed -> question -> machinery\n",
      "proposed -> question -> behaviour\n",
      "design -> work\n",
      "design -> work -> ai\n",
      "design -> mccullouch\n",
      "design -> mccullouch -> pitts\n",
      "design -> neurons\n",
      "born -> field\n",
      "born -> field -> research\n",
      "born -> field -> research -> ai\n",
      "born -> workshop\n",
      "born -> workshop -> college\n",
      "born -> workshop -> college -> dartmouth\n",
      "born -> workshop -> term\n",
      "born -> workshop -> term -> intelligence\n",
      "born -> workshop -> term -> intelligence -> artificial\n",
      "born -> workshop -> john\n",
      "born -> workshop -> john -> mccarthy\n",
      "born -> workshop -> field\n",
      "born -> workshop -> field -> cybernetics\n",
      "born -> workshop -> influence\n",
      "born -> workshop -> influence -> norbert\n",
      "born -> workshop -> influence -> norbert -> wiener\n",
      "became -> attendees\n",
      "became -> attendees -> allen\n",
      "became -> attendees -> newell\n",
      "became -> attendees -> cmu\n",
      "became -> attendees -> herbert\n",
      "became -> attendees -> herbert -> simon\n",
      "became -> attendees -> herbert -> cmu\n",
      "became -> attendees -> john\n",
      "became -> attendees -> john -> mccarthy\n",
      "became -> attendees -> john -> mit\n",
      "became -> attendees -> marvin\n",
      "became -> attendees -> marvin -> minsky\n",
      "became -> attendees -> marvin -> mit\n",
      "became -> attendees -> arthur\n",
      "became -> attendees -> arthur -> samuel\n",
      "became -> attendees -> arthur -> ibm\n",
      "became -> founders\n",
      "became -> founders -> leaders\n",
      "became -> founders -> leaders -> research\n",
      "became -> founders -> leaders -> research -> ai\n",
      "produced -> students\n",
      "produced -> programs\n",
      "produced -> programs -> press\n",
      "produced -> computers\n",
      "produced -> strategies\n",
      "produced -> strategies -> checkers\n",
      "produced -> problems\n",
      "produced -> problems -> word\n",
      "produced -> problems -> algebra\n",
      "produced -> theorems\n",
      "produced -> theorems -> logic\n",
      "produced -> theorems -> logic -> theorist\n",
      "produced -> english\n",
      "funded -> middle\n",
      "funded -> middle -> 1960s\n",
      "funded -> research\n",
      "funded -> research -> u.s.\n",
      "funded -> department\n",
      "funded -> department -> defense\n",
      "funded -> laboratories\n",
      "funded -> world\n",
      "optimistic -> founders\n",
      "optimistic -> founders -> ai\n",
      "optimistic -> future\n",
      "optimistic -> herbert\n",
      "optimistic -> herbert -> simon\n",
      "optimistic -> machines\n",
      "optimistic -> years\n",
      "optimistic -> work\n",
      "optimistic -> work -> man\n",
      "agreed -> marvin\n",
      "agreed -> marvin -> minsky\n",
      "agreed -> generation\n",
      "agreed -> problem\n",
      "agreed -> problem -> intelligence\n",
      "failed -> difficulty\n",
      "failed -> difficulty -> tasks\n",
      "slowed -> progress\n",
      "slowed -> response\n",
      "slowed -> response -> criticism\n",
      "slowed -> response -> criticism -> sir\n",
      "slowed -> response -> criticism -> sir -> james\n",
      "slowed -> response -> criticism -> sir -> lighthill\n",
      "slowed -> response -> criticism -> sir -> pressure\n",
      "slowed -> response -> criticism -> sir -> pressure -> congress\n",
      "slowed -> response -> criticism -> sir -> pressure -> congress -> us\n",
      "slowed -> response -> criticism -> sir -> pressure -> projects\n",
      "slowed -> governments\n",
      "slowed -> governments -> u.s.\n",
      "slowed -> research\n",
      "slowed -> ai\n",
      "called -> years\n",
      "called -> winter\n",
      "called -> winter -> ai\n",
      "called -> winter -> period\n",
      "called -> projects\n",
      "called -> projects -> ai\n",
      "revived -> 1980s\n",
      "revived -> research\n",
      "revived -> research -> ai\n",
      "revived -> success\n",
      "revived -> success -> systems\n",
      "revived -> success -> systems -> expert\n",
      "revived -> success -> systems -> form\n",
      "revived -> success -> systems -> form -> program\n",
      "revived -> success -> systems -> form -> program -> ai\n",
      "revived -> success -> systems -> form -> program -> knowledge\n",
      "revived -> success -> systems -> form -> program -> knowledge -> skills\n",
      "revived -> success -> systems -> form -> program -> knowledge -> skills -> experts\n",
      "reached -> market\n",
      "reached -> market -> ai\n",
      "reached -> dollars\n",
      "inspired -> time\n",
      "inspired -> project\n",
      "inspired -> project -> japan\n",
      "inspired -> project -> generation\n",
      "inspired -> project -> computer\n",
      "inspired -> governments\n",
      "inspired -> governments -> u.s\n",
      "inspired -> funding\n",
      "inspired -> funding -> research\n",
      "fell -> collapse\n",
      "fell -> collapse -> market\n",
      "fell -> collapse -> market -> lisp\n",
      "fell -> collapse -> market -> machine\n",
      "fell -> disrepute\n",
      "fell -> hiatus\n",
      "enabled -> development\n",
      "enabled -> development -> integration\n",
      "enabled -> development -> integration -> –semiconductor\n",
      "enabled -> development -> integration -> –semiconductor -> metal–oxide\n",
      "enabled -> development -> integration -> –semiconductor -> mos\n",
      "enabled -> development -> integration -> vlsi\n",
      "enabled -> form\n",
      "enabled -> form -> technology\n",
      "enabled -> form -> technology -> mos\n",
      "enabled -> form -> technology -> mos -> cmos\n",
      "enabled -> form -> technology -> transistor\n",
      "enabled -> development\n",
      "enabled -> development -> technology\n",
      "enabled -> development -> technology -> network\n",
      "enabled -> development -> technology -> network -> ann\n",
      "enabled -> development -> technology -> 1980s\n",
      "book -> publication\n",
      "book -> publication -> field\n",
      "book -> implementation\n",
      "book -> implementation -> vlsi\n",
      "book -> implementation -> systems\n",
      "book -> implementation -> systems -> neural\n",
      "book -> carver\n",
      "book -> carver -> a.\n",
      "book -> carver -> mead\n",
      "book -> carver -> mohammed\n",
      "book -> carver -> mohammed -> ismail\n",
      "began -> 1990s\n",
      "began -> 1990s -> century\n",
      "began -> logistics\n",
      "began -> logistics -> mining\n",
      "began -> logistics -> mining -> data\n",
      "began -> logistics -> diagnosis\n",
      "began -> logistics -> areas\n",
      "increasing -> success\n",
      "increasing -> power\n",
      "increasing -> power -> law\n",
      "increasing -> power -> law -> moore\n",
      "increasing -> power -> law -> count\n",
      "increasing -> power -> law -> count -> transistor\n",
      "increasing -> power -> emphasis\n",
      "increasing -> power -> emphasis -> problems\n",
      "increasing -> power -> ties\n",
      "increasing -> power -> ties -> ai\n",
      "increasing -> power -> ties -> ai -> fields\n",
      "increasing -> power -> ties -> statistics\n",
      "increasing -> power -> ties -> statistics -> economics\n",
      "increasing -> power -> ties -> statistics -> mathematics\n",
      "increasing -> power -> ties -> statistics -> commitment\n",
      "increasing -> power -> ties -> statistics -> commitment -> researchers\n",
      "increasing -> power -> ties -> statistics -> commitment -> researchers -> methods\n",
      "increasing -> power -> ties -> statistics -> commitment -> researchers -> methods -> standards\n",
      "became -> blue\n",
      "became -> blue -> deep\n",
      "became -> system\n",
      "became -> system -> computer\n",
      "became -> system -> playing\n",
      "became -> system -> playing -> chess\n",
      "became -> system -> champion\n",
      "became -> system -> champion -> world\n",
      "became -> system -> champion -> chess\n",
      "became -> system -> champion -> garry\n",
      "became -> system -> champion -> garry -> kasparov\n",
      "became -> system -> may\n",
      "defeated -> match\n",
      "defeated -> match -> jeopardy\n",
      "defeated -> match -> quiz\n",
      "defeated -> match -> show\n",
      "defeated -> match -> exhibition\n",
      "defeated -> match -> system\n",
      "defeated -> match -> system -> ibm\n",
      "defeated -> match -> system -> question\n",
      "defeated -> match -> system -> answering\n",
      "defeated -> match -> system -> watson\n",
      "defeated -> champions\n",
      "defeated -> champions -> jeopardy\n",
      "defeated -> champions -> brad\n",
      "defeated -> champions -> brad -> rutter\n",
      "defeated -> champions -> brad -> ken\n",
      "defeated -> champions -> brad -> ken -> jennings\n",
      "defeated -> margin\n",
      "started -> computers\n",
      "started -> computers -> improvements\n",
      "started -> computers -> access\n",
      "started -> computers -> access -> amounts\n",
      "started -> computers -> access -> amounts -> data\n",
      "started -> computers -> access -> amounts -> advances\n",
      "started -> computers -> access -> amounts -> advances -> learning\n",
      "started -> computers -> access -> amounts -> advances -> learning -> machine\n",
      "started -> computers -> access -> amounts -> advances -> learning -> perception\n",
      "started -> methods\n",
      "started -> methods -> learning\n",
      "started -> benchmarks\n",
      "started -> benchmarks -> accuracy\n",
      "uses -> kinect\n",
      "uses -> kinect -> interface\n",
      "uses -> kinect -> interface -> body–motion\n",
      "uses -> kinect -> interface -> body–motion -> 3d\n",
      "uses -> kinect -> interface -> xbox\n",
      "uses -> kinect -> interface -> xbox -> one\n",
      "uses -> kinect -> interface -> xbox -> one -> xbox\n",
      "uses -> algorithms\n",
      "uses -> algorithms -> research\n",
      "uses -> algorithms -> research -> ai\n",
      "uses -> algorithms -> assistants\n",
      "uses -> algorithms -> smartphones\n",
      "won -> march\n",
      "won -> alphago\n",
      "won -> games\n",
      "won -> games -> match\n",
      "won -> games -> match -> champion\n",
      "won -> games -> match -> champion -> go\n",
      "won -> games -> match -> champion -> lee\n",
      "won -> games -> match -> champion -> lee -> sedol\n",
      "won -> system\n",
      "won -> system -> computer\n",
      "won -> system -> player\n",
      "won -> system -> player -> go\n",
      "won -> system -> handicaps\n",
      "won -> future\n",
      "won -> future -> go\n",
      "won -> future -> summit\n",
      "won -> alphago\n",
      "won -> match\n",
      "won -> match -> game\n",
      "won -> match -> ke\n",
      "won -> match -> ke -> jie\n",
      "won -> match -> time\n",
      "won -> match -> world\n",
      "won -> match -> ranking\n",
      "won -> match -> ranking -> no.\n",
      "won -> match -> years\n",
      "marked -> completion\n",
      "marked -> completion -> milestone\n",
      "marked -> completion -> milestone -> development\n",
      "marked -> completion -> milestone -> development -> intelligence\n",
      "marked -> completion -> milestone -> development -> intelligence -> artificial\n",
      "marked -> game\n",
      "marked -> game -> go\n",
      "marked -> game -> chess\n",
      "increased -> year\n",
      "increased -> year -> jack\n",
      "increased -> year -> jack -> bloomberg\n",
      "increased -> year -> jack -> clark\n",
      "increased -> year -> intelligence\n",
      "increased -> number\n",
      "increased -> number -> projects\n",
      "increased -> number -> projects -> software\n",
      "increased -> number -> projects -> ai\n",
      "increased -> number -> projects -> google\n",
      "increased -> usage\n",
      "increased -> projects\n",
      "presents -> clark\n",
      "presents -> data\n",
      "presents -> data -> improvements\n",
      "presents -> data -> improvements -> ai\n",
      "presents -> data -> improvements -> rates\n",
      "presents -> data -> improvements -> rates -> error\n",
      "presents -> data -> improvements -> rates -> tasks\n",
      "presents -> data -> improvements -> rates -> tasks -> image\n",
      "presents -> data -> improvements -> rates -> tasks -> processing\n",
      "attributes -> increase\n",
      "attributes -> increase -> networks\n",
      "attributes -> rise\n",
      "attributes -> rise -> infrastructure\n",
      "attributes -> rise -> infrastructure -> computing\n",
      "attributes -> rise -> increase\n",
      "attributes -> rise -> increase -> tools\n",
      "attributes -> rise -> increase -> tools -> research\n",
      "attributes -> rise -> increase -> tools -> datasets\n",
      "include -> examples\n",
      "include -> development\n",
      "include -> development -> microsoft\n",
      "include -> development -> system\n",
      "include -> development -> system -> skype\n",
      "include -> development -> system -> language\n",
      "include -> development -> system -> language -> system\n",
      "include -> development -> system -> language -> system -> facebook\n",
      "include -> development -> system -> language -> system -> images\n",
      "include -> development -> system -> language -> system -> people\n",
      "reported -> survey\n",
      "reported -> companies\n",
      "reported -> ai\n",
      "reported -> offerings\n",
      "reported -> offerings -> processes\n",
      "accelerated -> china\n",
      "accelerated -> funding\n",
      "accelerated -> funding -> government\n",
      "accelerated -> supply\n",
      "accelerated -> supply -> data\n",
      "accelerated -> supply -> output\n",
      "accelerated -> supply -> output -> research\n",
      "accelerated -> observers\n",
      "accelerated -> track\n",
      "accelerated -> track -> superpower\n",
      "accelerated -> track -> superpower -> ai\n",
      "acknowledged -> reports\n",
      "acknowledged -> reports -> intelligence\n",
      "defines -> science\n",
      "defines -> science -> computer\n",
      "defines -> research\n",
      "defines -> study\n",
      "defines -> study -> agents\n",
      "defines -> study -> agents -> device\n",
      "defines -> study -> agents -> device -> environment\n",
      "defines -> study -> agents -> device -> actions\n",
      "defines -> study -> agents -> device -> actions -> chance\n",
      "defines -> study -> agents -> device -> actions -> chance -> goals\n",
      "ai -> definition\n",
      "ai -> ability\n",
      "ai -> ability -> system\n",
      "ai -> ability -> data\n",
      "ai -> ability -> data\n",
      "ai -> ability -> learnings\n",
      "ai -> ability -> learnings -> goals\n",
      "ai -> ability -> learnings -> goals -> tasks\n",
      "ai -> ability -> learnings -> adaptation\n",
      "analyzes -> ai\n",
      "analyzes -> environment\n",
      "analyzes -> actions\n",
      "analyzes -> actions -> chance\n",
      "analyzes -> actions -> chance -> success\n",
      "simple -> function\n",
      "simple -> function -> ai\n",
      "simple -> function -> utility\n",
      "simple -> function -> goal\n",
      "simple -> ai\n",
      "simple -> game\n",
      "simple -> game -> go\n",
      "simple -> actions\n",
      "simple -> actions -> ones\n",
      "simple -> actions -> ones -> past\n",
      "defined -> goals\n",
      "induced -> ai\n",
      "induced -> learning\n",
      "induced -> learning -> reinforcement\n",
      "induced -> goals\n",
      "induced -> types\n",
      "induced -> types -> behavior\n",
      "induced -> types -> behavior -> others\n",
      "induce -> system\n",
      "induce -> goals\n",
      "induce -> function\n",
      "induce -> function -> fitness\n",
      "induce -> scoring\n",
      "induce -> scoring -> systems\n",
      "induce -> scoring -> systems -> animals\n",
      "induce -> scoring -> systems -> goals\n",
      "induce -> scoring -> systems -> goals -> food\n",
      "systems -> neighbor\n",
      "systems -> reason\n",
      "systems -> reason -> analogy\n",
      "systems -> systems\n",
      "systems -> goals\n",
      "systems -> degree\n",
      "systems -> degree -> goals\n",
      "systems -> degree -> data\n",
      "systems -> degree -> data -> training\n",
      "benchmarked -> systems\n",
      "benchmarked -> system\n",
      "benchmarked -> system\n",
      "benchmarked -> system -> goal\n",
      "benchmarked -> system -> task\n",
      "benchmarked -> system -> task -> classification\n",
      "revolves -> use\n",
      "revolves -> use -> algorithms\n",
      "set -> algorithm\n",
      "set -> instructions\n",
      "set -> instructions -> computer\n",
      "built -> algorithm\n",
      "built -> top\n",
      "built -> top -> algorithms\n",
      "recipe -> example\n",
      "recipe -> example -> algorithm\n",
      "recipe -> player\n",
      "recipe -> play\n",
      "recipe -> play -> toe\n",
      "capable -> algorithms\n",
      "capable -> algorithms -> ai\n",
      "capable -> data\n",
      "capable -> heuristics\n",
      "capable -> heuristics -> strategies\n",
      "capable -> heuristics -> rules\n",
      "capable -> heuristics -> rules -> thumb\n",
      "capable -> heuristics -> past\n",
      "capable -> heuristics -> algorithms\n",
      "learn -> learners\n",
      "learn -> networks\n",
      "learn -> networks -> trees\n",
      "learn -> networks -> trees -> decision\n",
      "learn -> networks -> neighbor\n",
      "learn -> data\n",
      "learn -> data -> time\n",
      "learn -> data -> memory\n",
      "learn -> function\n",
      "learn -> function -> combination\n",
      "learn -> function -> combination -> functions\n",
      "learn -> function -> world\n",
      "derive -> learners\n",
      "derive -> knowledge\n",
      "derive -> hypothesis\n",
      "derive -> data\n",
      "possible -> practice\n",
      "possible -> possibility\n",
      "possible -> phenomenon\n",
      "possible -> phenomenon -> explosion\n",
      "possible -> phenomenon -> explosion -> amount\n",
      "possible -> phenomenon -> explosion -> amount -> time\n",
      "possible -> phenomenon -> explosion -> problem\n",
      "involves -> research\n",
      "involves -> range\n",
      "involves -> range -> possibilities\n",
      "skip -> example\n",
      "skip -> map\n",
      "skip -> route\n",
      "skip -> route -> driving\n",
      "skip -> route -> denver\n",
      "skip -> route -> denver -> york\n",
      "skip -> route -> denver -> york -> new\n",
      "skip -> route -> denver -> york -> east\n",
      "skip -> cases\n",
      "skip -> path\n",
      "skip -> path -> san\n",
      "skip -> path -> san -> francisco\n",
      "skip -> path -> san -> areas\n",
      "skip -> path -> san -> west\n",
      "skip -> ai\n",
      "skip -> ai -> algorithm\n",
      "skip -> ai -> algorithm -> pathfinding\n",
      "skip -> ai -> a*\n",
      "skip -> ai -> explosion\n",
      "skip -> ai -> explosion -> route\n",
      "skip -> ai -> explosion -> turn\n",
      "symbolism -> approach\n",
      "symbolism -> approach -> ai\n",
      "symbolism -> logic\n",
      "symbolism -> adult\n",
      "symbolism -> fever\n",
      "symbolism -> influenza\n",
      "inference -> approach\n",
      "inference -> patient\n",
      "inference -> fever\n",
      "inference -> probability\n",
      "inference -> probability -> influenza\n",
      "inference -> probability -> and-\n",
      "inference -> probability -> way\n",
      "applications -> approach\n",
      "applications -> approach -> business\n",
      "applications -> approach -> business -> routine\n",
      "applications -> analogizers\n",
      "applications -> analogizers -> svm\n",
      "applications -> analogizers -> svm -> neighbor\n",
      "applications -> analogizers -> records\n",
      "applications -> analogizers -> records -> patients\n",
      "applications -> analogizers -> records -> patients -> temperature\n",
      "applications -> analogizers -> records -> patients -> temperature -> symptoms\n",
      "applications -> analogizers -> records -> patients -> temperature -> age\n",
      "applications -> analogizers -> records -> patients -> temperature -> factors\n",
      "applications -> analogizers -> records -> patients -> patient\n",
      "applications -> analogizers -> records -> patients -> %\n",
      "applications -> analogizers -> records -> patients -> % -> patients\n",
      "applications -> analogizers -> records -> patients -> influenza\n",
      "harder -> approach\n",
      "harder -> machinery\n",
      "harder -> machinery -> brain\n",
      "harder -> approach\n",
      "harder -> approach -> network\n",
      "harder -> neurons\n",
      "harder -> neurons -> output\n",
      "harder -> neurons -> strengths\n",
      "harder -> neurons -> strengths -> connections\n",
      "harder -> neurons -> strengths -> connections -> neurons\n",
      "harder -> neurons -> strengths -> connections -> neurons -> connections\n",
      "overlap -> approaches\n",
      "overlap -> systems\n",
      "overlap -> example\n",
      "overlap -> nets\n",
      "overlap -> inferences\n",
      "overlap -> analogies\n",
      "use -> systems\n",
      "use -> approaches\n",
      "use -> ai\n",
      "use -> ai -> algorithms\n",
      "use -> ai -> algorithms -> -ai\n",
      "use -> approach\n",
      "use -> problem\n",
      "work -> algorithms\n",
      "work -> basis\n",
      "work -> basis -> strategies\n",
      "work -> basis -> strategies -> algorithms\n",
      "work -> basis -> strategies -> inferences\n",
      "work -> basis -> strategies -> inferences -> past\n",
      "work -> basis -> future\n",
      "obvious -> inferences\n",
      "obvious -> sun\n",
      "obvious -> morning\n",
      "obvious -> days\n",
      "obvious -> morning\n",
      "obvious -> morning -> tomorrow\n",
      "nuanced -> %\n",
      "nuanced -> % -> families\n",
      "nuanced -> species\n",
      "nuanced -> species -> variants\n",
      "nuanced -> species -> variants -> color\n",
      "nuanced -> chance\n",
      "nuanced -> chance -> %\n",
      "nuanced -> chance -> swans\n",
      "work -> learners\n",
      "work -> basis\n",
      "work -> basis -> razor\n",
      "work -> basis -> razor -> occam\n",
      "likeliest -> theory\n",
      "likeliest -> theory -> data\n",
      "designed -> principle\n",
      "designed -> principle -> occam\n",
      "designed -> principle -> razor\n",
      "designed -> learner\n",
      "designed -> theories\n",
      "designed -> theories -> theories\n",
      "designed -> cases\n",
      "designed -> cases -> theory\n",
      "known -> theory\n",
      "known -> theory -> data\n",
      "known -> theory -> data -> training\n",
      "attempt -> systems\n",
      "attempt -> theory\n",
      "attempt -> theory -> accordance\n",
      "attempt -> theory -> accordance -> data\n",
      "attempt -> theory -> accordance -> theory\n",
      "attempt -> theory -> accordance -> theory -> accordance\n",
      "attempt -> theory -> accordance -> theory -> accordance -> theory\n",
      "disappoint -> overfitting\n",
      "disappoint -> learners\n",
      "disappoint -> lesson\n",
      "is -> example\n",
      "is -> example -> toy\n",
      "is -> classifier\n",
      "is -> classifier -> image\n",
      "is -> classifier -> pictures\n",
      "is -> classifier -> pictures -> horses\n",
      "is -> classifier -> pictures -> horses -> cats\n",
      "is -> patches\n",
      "is -> horses\n",
      "is -> example\n",
      "is -> humans\n",
      "is -> classifiers\n",
      "is -> classifiers -> image\n",
      "is -> relationship\n",
      "is -> relationship -> components\n",
      "is -> relationship -> components -> picture\n",
      "is -> patterns\n",
      "is -> patterns -> pixels\n",
      "is -> patterns -> pixels -> humans\n",
      "is -> images\n",
      "is -> images -> types\n",
      "is -> images -> types -> objects\n",
      "superimposing -> pattern\n",
      "superimposing -> pattern -> results\n",
      "superimposing -> pattern -> results -> image\n",
      "superimposing -> pattern -> results -> image\n",
      "superimposing -> pattern -> results -> image -> system\n",
      "lacks -> humans\n",
      "lacks -> ai\n",
      "lacks -> features\n",
      "lacks -> features -> reasoning\n",
      "lacks -> humans\n",
      "lacks -> mechanisms\n",
      "lacks -> mechanisms -> reasoning\n",
      "lacks -> mechanisms -> reasoning -> physics\n",
      "lacks -> mechanisms -> reasoning -> physics -> space\n",
      "lacks -> mechanisms -> reasoning -> physics -> space -> time\n",
      "lacks -> mechanisms -> reasoning -> physics -> space -> interactions\n",
      "enables -> children\n",
      "enables -> inferences\n",
      "enables -> pen\n",
      "enables -> table\n",
      "enables -> floor\n",
      "have -> humans\n",
      "have -> mechanism\n",
      "have -> mechanism -> psychology\n",
      "have -> mechanism -> psychology -> sentences\n",
      "have -> mechanism -> psychology -> sentences -> language\n",
      "have -> mechanism -> psychology -> sentences -> councilmen\n",
      "have -> mechanism -> psychology -> sentences -> councilmen -> city\n",
      "have -> mechanism -> psychology -> sentences -> demonstrators\n",
      "have -> mechanism -> psychology -> sentences -> permit\n",
      "have -> mechanism -> psychology -> sentences -> violence\n",
      "has -> ai\n",
      "has -> difficulty\n",
      "has -> difficulty -> councilmen\n",
      "has -> difficulty -> councilmen -> ones\n",
      "has -> difficulty -> councilmen -> ones -> violence\n",
      "has -> difficulty -> councilmen -> demonstrators\n",
      "means -> lack\n",
      "means -> lack -> knowledge\n",
      "means -> mistakes\n",
      "means -> humans\n",
      "means -> ways\n",
      "reason -> example\n",
      "reason -> cars\n",
      "reason -> cars -> self-\n",
      "reason -> cars -> driving\n",
      "reason -> location\n",
      "reason -> location -> intentions\n",
      "reason -> location -> intentions -> pedestrians\n",
      "reason -> location -> intentions -> way\n",
      "reason -> location -> intentions -> way -> humans\n",
      "reason -> modes\n",
      "reason -> modes -> reasoning\n",
      "reason -> modes -> reasoning -> accidents\n",
      "limited -> capabilities\n",
      "limited -> capabilities -> architectures\n",
      "limited -> version\n",
      "limited -> version -> intelligence\n",
      "come -> instance\n",
      "come -> mind\n",
      "come -> ways\n",
      "come -> ways -> measure\n",
      "come -> ways -> measure -> explanations\n",
      "come -> ways -> measure -> explanations -> occurrences\n",
      "come -> ways -> measure -> explanations -> occurrences -> life\n",
      "challenging -> problem\n",
      "challenging -> mind\n",
      "gives -> rise\n",
      "gives -> classes\n",
      "gives -> classes -> models\n",
      "aim -> models\n",
      "aim -> operations\n",
      "aim -> operations -> intelligence\n",
      "aim -> operations -> mind\n",
      "aim -> operations -> mind -> reasoning\n",
      "aim -> operations -> mind -> reasoning -> logic\n",
      "refers -> model\n",
      "refers -> data\n",
      "refers -> data -> counterpart\n",
      "create -> goal\n",
      "create -> goal -> research\n",
      "create -> goal -> intelligence\n",
      "create -> technology\n",
      "create -> technology -> computers\n",
      "create -> technology -> computers -> machines\n",
      "create -> technology -> manner\n",
      "broken -> problem\n",
      "broken -> problem -> intelligence\n",
      "broken -> sub-problems\n",
      "consist -> traits\n",
      "consist -> traits -> capabilities\n",
      "consist -> traits -> researchers\n",
      "consist -> traits -> system\n",
      "received -> traits\n",
      "received -> attention\n",
      "developed -> researchers\n",
      "developed -> algorithms\n",
      "developed -> algorithms -> reasoning\n",
      "developed -> algorithms -> reasoning -> humans\n",
      "developed -> algorithms -> reasoning -> puzzles\n",
      "developed -> algorithms -> reasoning -> deductions\n",
      "developed -> 1980s\n",
      "developed -> 1980s -> 1990s\n",
      "developed -> research\n",
      "developed -> methods\n",
      "developed -> methods -> information\n",
      "developed -> methods -> concepts\n",
      "developed -> methods -> concepts -> probability\n",
      "developed -> methods -> concepts -> probability -> economics\n",
      "proved -> algorithms\n",
      "proved -> problems\n",
      "proved -> problems -> reasoning\n",
      "proved -> explosion\n",
      "proved -> problems\n",
      "use -> fact\n",
      "use -> humans\n",
      "use -> deduction\n",
      "use -> deduction -> research\n",
      "solve -> problems\n",
      "solve -> problems -> judgments\n",
      "central -> representation\n",
      "central -> representation -> knowledge\n",
      "central -> representation -> engineering\n",
      "central -> representation -> engineering -> knowledge\n",
      "central -> research\n",
      "central -> research -> ai\n",
      "attempt -> systems\n",
      "attempt -> systems -> expert\n",
      "attempt -> knowledge\n",
      "attempt -> knowledge -> experts\n",
      "attempt -> knowledge -> domain\n",
      "attempt -> addition\n",
      "attempt -> projects\n",
      "attempt -> knowledge\n",
      "attempt -> knowledge -> person\n",
      "attempt -> knowledge -> database\n",
      "attempt -> knowledge -> database -> knowledge\n",
      "attempt -> knowledge -> database -> knowledge -> world\n",
      "objects -> things\n",
      "objects -> things -> base\n",
      "objects -> things -> base -> knowledge\n",
      "objects -> properties\n",
      "objects -> categories\n",
      "objects -> relations\n",
      "objects -> relations -> objects\n",
      "objects -> relations -> objects -> time\n",
      "objects -> situations\n",
      "objects -> events\n",
      "objects -> states\n",
      "objects -> causes\n",
      "objects -> causes -> effects\n",
      "objects -> knowledge\n",
      "objects -> knowledge -> knowledge\n",
      "objects -> knowledge -> people\n",
      "objects -> domains\n",
      "ontology -> representation\n",
      "ontology -> set\n",
      "ontology -> set -> objects\n",
      "ontology -> set -> objects -> relations\n",
      "ontology -> set -> objects -> concepts\n",
      "ontology -> set -> objects -> properties\n",
      "ontology -> agents\n",
      "ontology -> agents -> software\n",
      "captured -> semantics\n",
      "captured -> description\n",
      "captured -> concepts\n",
      "captured -> concepts -> logic\n",
      "captured -> concepts -> roles\n",
      "captured -> concepts -> individuals\n",
      "captured -> classes\n",
      "captured -> classes -> properties\n",
      "captured -> classes -> individuals\n",
      "captured -> classes -> individuals -> language\n",
      "captured -> classes -> individuals -> language -> web\n",
      "captured -> classes -> individuals -> language -> ontology\n",
      "called -> ontologies\n",
      "called -> ontologies\n",
      "called -> ontologies -> foundation\n",
      "called -> ontologies -> foundation -> knowledge\n",
      "called -> ontologies -> mediators\n",
      "called -> ontologies -> mediators -> ontologies\n",
      "called -> ontologies -> mediators -> ontologies -> domain\n",
      "called -> ontologies -> mediators -> ontologies -> knowledge\n",
      "called -> ontologies -> mediators -> ontologies -> knowledge -> domain\n",
      "called -> ontologies -> mediators -> ontologies -> knowledge -> domain -> knowledge\n",
      "called -> ontologies -> mediators -> ontologies -> knowledge -> domain -> field\n",
      "called -> ontologies -> mediators -> ontologies -> knowledge -> domain -> field -> interest\n",
      "called -> ontologies -> mediators -> ontologies -> knowledge -> domain -> field -> interest -> area\n",
      "called -> ontologies -> mediators -> ontologies -> knowledge -> domain -> field -> interest -> concern\n",
      "used -> representations\n",
      "used -> representations -> knowledge\n",
      "used -> indexing\n",
      "used -> indexing -> content\n",
      "used -> indexing -> retrieval\n",
      "used -> indexing -> interpretation\n",
      "used -> indexing -> interpretation -> scene\n",
      "used -> indexing -> support\n",
      "used -> indexing -> support -> decision\n",
      "used -> indexing -> discovery\n",
      "used -> indexing -> discovery -> knowledge\n",
      "used -> indexing -> mining\n",
      "used -> indexing -> inferences\n",
      "used -> indexing -> inferences -> databases\n",
      "used -> indexing -> areas\n",
      "are -> problems\n",
      "are -> problems -> representation\n",
      "are -> problems -> representation -> knowledge\n",
      "able -> agents\n",
      "able -> goals\n",
      "need -> way\n",
      "need -> way -> future\n",
      "need -> way -> future -> representation\n",
      "need -> way -> future -> representation -> state\n",
      "need -> way -> future -> representation -> state -> world\n",
      "need -> predictions\n",
      "need -> predictions -> actions\n",
      "need -> choices\n",
      "need -> choices -> utility\n",
      "need -> choices -> utility -> value\n",
      "need -> choices -> utility -> choices\n",
      "assume -> problems\n",
      "assume -> problems -> planning\n",
      "assume -> agent\n",
      "assume -> system\n",
      "assume -> system -> world\n",
      "assume -> system -> agent\n",
      "assume -> system -> consequences\n",
      "assume -> system -> consequences -> actions\n",
      "requires -> actor\n",
      "requires -> actor -> agent\n",
      "requires -> agent\n",
      "requires -> uncertainty\n",
      "calls -> agent\n",
      "calls -> agent -> environment\n",
      "calls -> agent -> predictions\n",
      "calls -> agent -> predictions\n",
      "calls -> agent -> assessment\n",
      "uses -> planning\n",
      "uses -> cooperation\n",
      "uses -> cooperation -> competition\n",
      "uses -> cooperation -> agents\n",
      "uses -> goal\n",
      "used -> behavior\n",
      "used -> algorithms\n",
      "used -> algorithms -> intelligence\n",
      "used -> algorithms -> intelligence -> swarm\n",
      "study -> learning\n",
      "study -> learning -> machine\n",
      "study -> learning -> ml\n",
      "study -> learning -> concept\n",
      "study -> learning -> concept -> research\n",
      "study -> learning -> concept -> research -> ai\n",
      "study -> learning -> concept -> research -> inception\n",
      "study -> learning -> concept -> research -> inception -> field\n",
      "study -> algorithms\n",
      "study -> algorithms -> computer\n",
      "study -> algorithms -> experience\n",
      "ability -> learning\n",
      "ability -> patterns\n",
      "ability -> stream\n",
      "ability -> stream -> input\n",
      "ability -> human\n",
      "ability -> human -> inputs\n",
      "includes -> learning\n",
      "includes -> classification\n",
      "includes -> classification -> regression\n",
      "includes -> classification -> human\n",
      "includes -> classification -> data\n",
      "includes -> classification -> data -> input\n",
      "used -> classification\n",
      "used -> category\n",
      "used -> something\n",
      "used -> program\n",
      "used -> number\n",
      "used -> number -> examples\n",
      "used -> number -> examples -> things\n",
      "used -> number -> examples -> things -> categories\n",
      "attempt -> regression\n",
      "attempt -> function\n",
      "attempt -> function -> relationship\n",
      "attempt -> function -> relationship -> inputs\n",
      "attempt -> function -> relationship -> inputs -> outputs\n",
      "attempt -> function -> outputs\n",
      "attempt -> function -> change\n",
      "attempt -> function -> change -> inputs\n",
      "viewed -> classifiers\n",
      "viewed -> classifiers -> learners\n",
      "viewed -> classifiers -> learners -> regression\n",
      "viewed -> approximators\n",
      "viewed -> approximators -> function\n",
      "viewed -> function\n",
      "viewed -> example\n",
      "viewed -> classifier\n",
      "viewed -> classifier -> spam\n",
      "viewed -> function\n",
      "viewed -> function -> text\n",
      "viewed -> function -> text -> email\n",
      "viewed -> function -> text -> email -> categories\n",
      "viewed -> function -> text -> email -> categories -> spam\n",
      "viewed -> function -> text -> email -> categories -> spam\n",
      "assess -> theory\n",
      "assess -> theory -> learning\n",
      "assess -> learners\n",
      "assess -> complexity\n",
      "assess -> complexity\n",
      "assess -> complexity -> sample\n",
      "assess -> complexity -> data\n",
      "assess -> complexity -> notions\n",
      "assess -> complexity -> notions -> optimization\n",
      "rewarded -> reinforcement\n",
      "rewarded -> agent\n",
      "rewarded -> responses\n",
      "rewarded -> ones\n",
      "uses -> agent\n",
      "uses -> sequence\n",
      "uses -> sequence -> rewards\n",
      "uses -> sequence -> rewards -> punishments\n",
      "uses -> strategy\n",
      "uses -> strategy -> space\n",
      "uses -> strategy -> space -> problem\n",
      "gives -> processing\n",
      "gives -> processing -> language\n",
      "gives -> processing -> nlp\n",
      "gives -> machines\n",
      "gives -> ability\n",
      "gives -> ability -> language\n",
      "enable -> system\n",
      "enable -> system -> processing\n",
      "enable -> system -> processing -> language\n",
      "enable -> interfaces\n",
      "enable -> interfaces -> language\n",
      "enable -> interfaces -> user\n",
      "enable -> interfaces -> acquisition\n",
      "enable -> interfaces -> acquisition -> knowledge\n",
      "enable -> interfaces -> acquisition -> sources\n",
      "enable -> interfaces -> acquisition -> sources -> texts\n",
      "enable -> interfaces -> acquisition -> sources -> texts -> newswire\n",
      "include -> applications\n",
      "include -> applications -> processing\n",
      "include -> applications -> processing -> language\n",
      "include -> retrieval\n",
      "include -> retrieval -> information\n",
      "include -> retrieval -> mining\n",
      "include -> retrieval -> mining -> text\n",
      "include -> retrieval -> answering\n",
      "include -> retrieval -> answering -> question\n",
      "include -> retrieval -> translation\n",
      "include -> retrieval -> translation -> machine\n",
      "use -> approaches\n",
      "use -> frequencies\n",
      "use -> frequencies -> word\n",
      "use -> frequencies -> co-occurrence\n",
      "use -> representations\n",
      "use -> representations -> text\n",
      "popular -> strategies\n",
      "popular -> strategies -> keyword\n",
      "popular -> strategies -> search\n",
      "popular -> query\n",
      "popular -> query -> search\n",
      "popular -> query -> dog\n",
      "popular -> documents\n",
      "popular -> word\n",
      "popular -> word -> dog\n",
      "popular -> document\n",
      "popular -> document -> word\n",
      "popular -> document -> word -> poodle\n",
      "use -> strategies\n",
      "use -> strategies -> affinity\n",
      "use -> occurrence\n",
      "use -> occurrence -> words\n",
      "use -> occurrence -> words -> accident\n",
      "use -> sentiment\n",
      "use -> sentiment -> document\n",
      "combine -> approaches\n",
      "combine -> approaches -> nlp\n",
      "combine -> strategies\n",
      "combine -> strategies -> others\n",
      "combine -> accuracy\n",
      "combine -> accuracy -> page\n",
      "combine -> accuracy -> page -> level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine -> accuracy -> page -> level -> paragraph\n",
      "combine -> understanding\n",
      "combine -> understanding -> sentences\n",
      "scales -> difficulties\n",
      "scales -> difficulties -> knowledge\n",
      "scales -> nlp\n",
      "scales -> applications\n",
      "scales -> applications -> business\n",
      "is -> goal\n",
      "is -> goal -> nlp\n",
      "is -> nlp\n",
      "is -> understanding\n",
      "is -> understanding -> reasoning\n",
      "ability -> perception\n",
      "ability -> perception -> machine\n",
      "ability -> input\n",
      "ability -> sensors\n",
      "ability -> sensors -> cameras\n",
      "ability -> sensors -> cameras -> spectrum\n",
      "ability -> sensors -> cameras -> microphones\n",
      "ability -> sensors -> cameras -> signals\n",
      "ability -> sensors -> cameras -> lidar\n",
      "ability -> sensors -> cameras -> lidar -> sonar\n",
      "ability -> sensors -> cameras -> radar\n",
      "ability -> sensors -> cameras -> sensors\n",
      "ability -> aspects\n",
      "ability -> aspects -> world\n",
      "include -> applications\n",
      "include -> recognition\n",
      "include -> recognition -> speech\n",
      "include -> recognition -> recognition\n",
      "include -> recognition -> recognition\n",
      "include -> recognition -> recognition -> object\n",
      "ability -> vision\n",
      "ability -> vision -> computer\n",
      "ability -> input\n",
      "ambiguous -> input\n",
      "ambiguous -> giant\n",
      "ambiguous -> giant -> pedestrian\n",
      "ambiguous -> pixels\n",
      "ambiguous -> pedestrian\n",
      "ambiguous -> ai\n",
      "ambiguous -> ai -> likelihood\n",
      "ambiguous -> ai -> likelihood -> reasonableness\n",
      "ambiguous -> ai -> likelihood -> interpretations\n",
      "ambiguous -> ai -> example\n",
      "ambiguous -> ai -> model\n",
      "ambiguous -> ai -> model -> object\n",
      "ambiguous -> ai -> pedestrians\n",
      "ambiguous -> ai -> pedestrians -> -meter\n",
      "used -> robotics\n",
      "learn -> arms\n",
      "learn -> arms -> robots\n",
      "learn -> arms -> robots -> factories\n",
      "learn -> experience\n",
      "learn -> experience -> presence\n",
      "learn -> experience -> presence -> friction\n",
      "learn -> experience -> presence -> friction -> slippage\n",
      "learn -> experience -> presence -> friction -> slippage -> gear\n",
      "determine -> robot\n",
      "determine -> environment\n",
      "determine -> location\n",
      "determine -> environment\n",
      "determine -> environments\n",
      "determine -> environments -> endoscopy\n",
      "determine -> environments -> interior\n",
      "determine -> environments -> interior -> body\n",
      "determine -> environments -> interior -> body -> patient\n",
      "determine -> environments -> interior -> body -> breathing\n",
      "determine -> challenge\n",
      "process -> planning\n",
      "process -> planning -> motion\n",
      "process -> task\n",
      "process -> task -> movement\n",
      "process -> primitives\n",
      "process -> primitives -> movements\n",
      "involves -> movement\n",
      "involves -> motion\n",
      "involves -> motion -> process\n",
      "involves -> motion -> process -> movement\n",
      "involves -> motion -> process -> contact\n",
      "involves -> motion -> process -> object\n",
      "generalizes -> paradox\n",
      "generalizes -> paradox -> moravec\n",
      "generalizes -> skills\n",
      "generalizes -> skills -> humans\n",
      "generalizes -> robot\n",
      "generalizes -> paradox\n",
      "generalizes -> hans\n",
      "generalizes -> hans -> moravec\n",
      "generalizes -> hans -> computers\n",
      "generalizes -> hans -> performance\n",
      "generalizes -> hans -> performance -> level\n",
      "generalizes -> hans -> tests\n",
      "generalizes -> hans -> tests -> intelligence\n",
      "generalizes -> hans -> checkers\n",
      "generalizes -> hans -> skills\n",
      "generalizes -> hans -> skills -> year\n",
      "generalizes -> hans -> skills -> perception\n",
      "generalizes -> hans -> skills -> perception -> mobility\n",
      "attributed -> fact\n",
      "attributed -> fact -> target\n",
      "attributed -> fact -> target -> checkers\n",
      "attributed -> fact -> target -> dexterity\n",
      "attributed -> fact -> target -> selection\n",
      "attributed -> fact -> target -> selection -> millions\n",
      "attributed -> fact -> target -> selection -> millions -> years\n",
      "extended -> paradox\n",
      "extended -> paradox -> moravec\n",
      "extended -> forms\n",
      "extended -> forms -> intelligence\n",
      "remains -> coordination\n",
      "remains -> coordination -> vehicles\n",
      "remains -> problem\n",
      "umbrella -> computing\n",
      "umbrella -> systems\n",
      "umbrella -> systems -> process\n",
      "umbrella -> systems -> affects\n",
      "include -> successes\n",
      "include -> successes -> computing\n",
      "include -> analysis\n",
      "include -> analysis -> sentiment\n",
      "include -> analysis -> analysis\n",
      "include -> analysis -> analysis -> affect\n",
      "include -> analysis -> analysis -> analysis\n",
      "include -> analysis -> analysis -> analysis -> sentiment\n",
      "include -> ai\n",
      "include -> affects\n",
      "include -> affects -> subject\n",
      "valuable -> run\n",
      "valuable -> skills\n",
      "valuable -> skills -> understanding\n",
      "valuable -> skills -> understanding -> emotion\n",
      "valuable -> skills -> understanding -> emotion -> theory\n",
      "valuable -> skills -> understanding -> emotion -> theory -> game\n",
      "valuable -> agent\n",
      "allow -> actions\n",
      "allow -> actions -> others\n",
      "allow -> motives\n",
      "allow -> motives -> states\n",
      "allow -> agent\n",
      "allow -> agent -> decisions\n",
      "mimic -> systems\n",
      "mimic -> systems -> computer\n",
      "mimic -> emotion\n",
      "mimic -> emotion -> expressions\n",
      "mimic -> dynamics\n",
      "mimic -> dynamics -> interaction\n",
      "mimic -> interaction\n",
      "mimic -> interaction -> human–computer\n",
      "programmed -> assistants\n",
      "programmed -> users\n",
      "programmed -> conception\n",
      "programmed -> conception -> agents\n",
      "programmed -> conception -> agents -> computer\n",
      "attempted -> projects\n",
      "attempted -> projects -> base\n",
      "attempted -> projects -> base -> cyc\n",
      "attempted -> projects -> base -> knowledge\n",
      "attempted -> projects -> base -> initiative\n",
      "attempted -> projects -> base -> initiative -> generation\n",
      "attempted -> projects -> base -> initiative -> generation -> fifth\n",
      "attempted -> projects -> base -> initiative -> systems\n",
      "attempted -> projects -> base -> initiative -> systems -> computer\n",
      "attempted -> breadth\n",
      "attempted -> breadth -> cognition\n",
      "failed -> projects\n",
      "failed -> limitations\n",
      "failed -> limitations -> models\n",
      "failed -> limitations -> models -> logic\n",
      "failed -> retrospect\n",
      "failed -> difficulty\n",
      "failed -> difficulty -> ai\n",
      "work -> majority\n",
      "work -> majority -> researchers\n",
      "work -> majority -> researchers -> ai\n",
      "work -> applications\n",
      "work -> applications -> ai\n",
      "work -> applications -> diagnosis\n",
      "work -> applications -> diagnosis -> navigation\n",
      "work -> applications -> diagnosis -> navigation -> automobile\n",
      "predict -> researchers\n",
      "predict -> work\n",
      "predict -> work -> ai\n",
      "predict -> work -> domains\n",
      "predict -> machine\n",
      "predict -> machine -> intelligence\n",
      "predict -> machine -> intelligence -> agi\n",
      "predict -> skills\n",
      "predict -> skills -> article\n",
      "predict -> point\n",
      "predict -> ability\n",
      "predict -> areas\n",
      "have -> advances\n",
      "have -> significance\n",
      "is -> example\n",
      "is -> example -> profile\n",
      "is -> deepmind\n",
      "is -> deepmind -> 2010s\n",
      "is -> intelligence\n",
      "is -> intelligence -> games\n",
      "is -> intelligence -> games -> atari\n",
      "is -> intelligence -> variant\n",
      "is -> intelligence -> variant -> system\n",
      "include -> learning\n",
      "include -> learning -> transfer\n",
      "include -> breakthroughs\n",
      "include -> breakthroughs -> agi\n",
      "include -> development\n",
      "include -> development -> architectures\n",
      "include -> development -> architectures -> decision\n",
      "include -> development -> architectures -> metareasoning\n",
      "include -> development -> architectures -> base\n",
      "include -> development -> architectures -> base -> knowledge\n",
      "include -> development -> architectures -> base -> web\n",
      "argue -> kind\n",
      "argue -> algorithm\n",
      "argue -> algorithm -> master\n",
      "argue -> agi\n",
      "look -> approaches\n",
      "look -> intelligence\n",
      "look -> features\n",
      "look -> features -> brain\n",
      "look -> features -> brain -> development\n",
      "look -> features -> brain -> development -> child\n",
      "look -> point\n",
      "look -> point -> intelligence\n",
      "require -> problems\n",
      "require -> problems -> article\n",
      "require -> intelligence\n",
      "require -> machines\n",
      "require -> problems\n",
      "require -> people\n",
      "require -> example\n",
      "require -> tasks\n",
      "require -> tasks -> translation\n",
      "require -> tasks -> translation -> machine\n",
      "require -> languages\n",
      "require -> languages -> nlp\n",
      "require -> machine\n",
      "require -> argument\n",
      "require -> argument -> author\n",
      "require -> argument -> reason\n",
      "require -> knowledge\n",
      "require -> intent\n",
      "require -> intent -> author\n",
      "require -> intent -> intelligence\n",
      "considered -> problem\n",
      "considered -> problem -> translation\n",
      "considered -> problem -> translation -> machine\n",
      "considered -> ai\n",
      "considered -> problems\n",
      "considered -> order\n",
      "considered -> performance\n",
      "considered -> performance -> machine\n",
      "is -> theory\n",
      "is -> theory -> paradigm\n",
      "is -> research\n",
      "disagree -> researchers\n",
      "disagree -> issues\n",
      "these -> questions\n",
      "these -> questions -> standing\n",
      "these -> intelligence\n",
      "these -> intelligence\n",
      "these -> psychology\n",
      "these -> psychology -> neurobiology\n",
      "irrelevant -> biology\n",
      "irrelevant -> research\n",
      "irrelevant -> engineering\n",
      "irrelevant -> engineering -> biology\n",
      "irrelevant -> engineering -> biology -> bird\n",
      "described -> behavior\n",
      "described -> principles\n",
      "described -> principles -> logic\n",
      "described -> principles -> logic -> optimization\n",
      "require -> number\n",
      "require -> number -> problems\n",
      "explored -> 1940s\n",
      "explored -> 1940s -> 1950s\n",
      "explored -> number\n",
      "explored -> number -> researchers\n",
      "explored -> connection\n",
      "explored -> connection -> neurobiology\n",
      "explored -> connection -> neurobiology -> theory\n",
      "explored -> connection -> neurobiology -> theory -> information\n",
      "explored -> connection -> neurobiology -> cybernetics\n",
      "built -> machines\n",
      "built -> machines -> networks\n",
      "built -> machines -> intelligence\n",
      "built -> machines -> intelligence -> turtles\n",
      "built -> machines -> intelligence -> turtles -> w.\n",
      "built -> machines -> intelligence -> turtles -> w. -> grey\n",
      "built -> machines -> intelligence -> turtles -> w. -> walter\n",
      "built -> machines -> intelligence -> turtles -> beast\n",
      "built -> machines -> intelligence -> turtles -> beast -> johns\n",
      "built -> machines -> intelligence -> turtles -> beast -> hopkins\n",
      "gathered -> researchers\n",
      "gathered -> meetings\n",
      "gathered -> meetings -> society\n",
      "gathered -> meetings -> society -> teleological\n",
      "gathered -> meetings -> society -> university\n",
      "gathered -> meetings -> society -> university -> princeton\n",
      "gathered -> meetings -> society -> university -> club\n",
      "gathered -> meetings -> society -> university -> club -> ratio\n",
      "gathered -> meetings -> society -> university -> club -> england\n",
      "abandoned -> approach\n",
      "abandoned -> elements\n",
      "abandoned -> 1980s\n",
      "began -> access\n",
      "began -> access -> computers\n",
      "began -> mid-1950s\n",
      "began -> research\n",
      "began -> possibility\n",
      "began -> possibility -> intelligence\n",
      "began -> possibility -> manipulation\n",
      "began -> possibility -> manipulation -> symbol\n",
      "centered -> research\n",
      "centered -> institutions\n",
      "centered -> institutions -> university\n",
      "centered -> institutions -> university -> carnegie\n",
      "centered -> institutions -> university -> mellon\n",
      "centered -> institutions -> university -> stanford\n",
      "centered -> institutions -> university -> mit\n",
      "centered -> one\n",
      "centered -> style\n",
      "centered -> style -> research\n",
      "named -> john\n",
      "named -> john -> haugeland\n",
      "named -> approaches\n",
      "named -> ai\n",
      "named -> ai -> gofai\n",
      "achieved -> 1960s\n",
      "achieved -> approaches\n",
      "achieved -> success\n",
      "achieved -> success -> level\n",
      "achieved -> success -> level -> high-\n",
      "achieved -> success -> programs\n",
      "achieved -> success -> programs -> demonstration\n",
      "abandoned -> approaches\n",
      "abandoned -> approaches -> cybernetics\n",
      "abandoned -> approaches -> cybernetics -> networks\n",
      "abandoned -> background\n",
      "convinced -> researchers\n",
      "convinced -> researchers -> 1960s\n",
      "convinced -> researchers -> 1960s -> 1970s\n",
      "convinced -> approaches\n",
      "convinced -> machine\n",
      "convinced -> machine -> intelligence\n",
      "convinced -> goal\n",
      "convinced -> goal -> field\n",
      "studied -> economist\n",
      "studied -> economist -> herbert\n",
      "studied -> economist -> simon\n",
      "studied -> economist -> allen\n",
      "studied -> economist -> allen -> newell\n",
      "studied -> skills\n",
      "studied -> skills -> solving\n",
      "studied -> work\n",
      "studied -> foundations\n",
      "studied -> foundations -> field\n",
      "studied -> foundations -> field -> intelligence\n",
      "studied -> foundations -> field -> science\n",
      "studied -> foundations -> field -> science -> research\n",
      "studied -> foundations -> field -> science -> research -> operations\n",
      "studied -> foundations -> field -> science -> science\n",
      "studied -> foundations -> field -> science -> science -> management\n",
      "used -> team\n",
      "used -> team -> research\n",
      "used -> results\n",
      "used -> results -> experiments\n",
      "used -> programs\n",
      "used -> programs -> techniques\n",
      "used -> programs -> techniques -> people\n",
      "used -> programs -> techniques -> problems\n",
      "culminate -> tradition\n",
      "culminate -> tradition -> university\n",
      "culminate -> tradition -> university -> carnegie\n",
      "culminate -> tradition -> university -> mellon\n",
      "culminate -> development\n",
      "culminate -> development -> architecture\n",
      "culminate -> development -> architecture -> soar\n",
      "culminate -> 1980s\n",
      "felt -> simon\n",
      "felt -> simon -> newell\n",
      "felt -> john\n",
      "felt -> john -> mccarthy\n",
      "felt -> machines\n",
      "felt -> thought\n",
      "felt -> essence\n",
      "felt -> essence -> reasoning\n",
      "felt -> essence -> reasoning -> abstract\n",
      "felt -> essence -> reasoning -> problem-solving\n",
      "felt -> people\n",
      "felt -> algorithms\n",
      "focused -> laboratory\n",
      "focused -> laboratory -> stanford\n",
      "focused -> laboratory -> stanford -> sail\n",
      "focused -> logic\n",
      "focused -> variety\n",
      "focused -> variety -> problems\n",
      "focused -> variety -> representation\n",
      "focused -> variety -> representation -> knowledge\n",
      "focused -> variety -> representation -> planning\n",
      "focused -> variety -> representation -> learning\n",
      "focus -> logic\n",
      "focus -> work\n",
      "focus -> work -> university\n",
      "focus -> work -> university -> edinburgh\n",
      "focus -> work -> university -> europe\n",
      "focus -> work -> university -> europe -> development\n",
      "focus -> work -> university -> europe -> development -> language\n",
      "focus -> work -> university -> europe -> development -> language -> programming\n",
      "focus -> work -> university -> europe -> development -> language -> prolog\n",
      "focus -> work -> university -> europe -> development -> language -> science\n",
      "focus -> work -> university -> europe -> development -> language -> science -> programming\n",
      "focus -> work -> university -> europe -> development -> language -> science -> programming -> logic\n",
      "found -> researchers\n",
      "found -> researchers -> mit\n",
      "found -> researchers -> marvin\n",
      "found -> researchers -> marvin -> minsky\n",
      "found -> researchers -> marvin -> seymour\n",
      "found -> researchers -> marvin -> seymour -> papert\n",
      "found -> problems\n",
      "found -> problems -> vision\n",
      "found -> problems -> vision -> processing\n",
      "found -> problems -> vision -> processing -> language\n",
      "found -> problems -> vision -> processing -> solutions\n",
      "found -> principle\n",
      "found -> principle -> logic\n",
      "found -> principle -> aspects\n",
      "found -> principle -> aspects -> behavior\n",
      "described -> roger\n",
      "described -> roger -> schank\n",
      "described -> approaches\n",
      "described -> paradigms\n",
      "described -> paradigms -> cmu\n",
      "described -> paradigms -> cmu -> stanford\n",
      "example -> bases\n",
      "example -> bases -> knowledge\n",
      "example -> bases -> cyc\n",
      "example -> bases -> cyc -> doug\n",
      "example -> bases -> cyc -> doug -> lenat\n",
      "example -> ai\n",
      "example -> hand\n",
      "example -> concept\n",
      "example -> concept -> time\n",
      "began -> computers\n",
      "began -> computers -> memories\n",
      "began -> researchers\n",
      "began -> researchers -> traditions\n",
      "began -> knowledge\n",
      "began -> applications\n",
      "began -> applications -> ai\n",
      "led -> revolution\n",
      "led -> revolution -> knowledge\n",
      "led -> development\n",
      "led -> development -> deployment\n",
      "led -> development -> systems\n",
      "led -> development -> systems -> expert\n",
      "led -> development -> systems -> edward\n",
      "led -> development -> systems -> edward -> feigenbaum\n",
      "led -> development -> form\n",
      "led -> development -> form -> software\n",
      "led -> development -> form -> software -> ai\n",
      "base -> component\n",
      "base -> component -> architecture\n",
      "base -> component -> architecture -> system\n",
      "base -> component -> architecture -> systems\n",
      "base -> component -> architecture -> systems -> expert\n",
      "base -> knowledge\n",
      "base -> facts\n",
      "base -> facts -> rules\n",
      "base -> facts -> ai\n",
      "driven -> revolution\n",
      "driven -> revolution -> knowledge\n",
      "driven -> realization\n",
      "driven -> realization -> amounts\n",
      "driven -> realization -> amounts -> knowledge\n",
      "driven -> realization -> applications\n",
      "driven -> realization -> applications -> ai\n",
      "seemed -> 1980s\n",
      "seemed -> progress\n",
      "seemed -> systems\n",
      "seemed -> processes\n",
      "seemed -> processes -> cognition\n",
      "seemed -> processes -> perception\n",
      "seemed -> processes -> perception -> robotics\n",
      "seemed -> processes -> perception -> learning\n",
      "seemed -> processes -> perception -> recognition\n",
      "seemed -> processes -> perception -> recognition -> pattern\n",
      "began -> number\n",
      "began -> number -> researchers\n",
      "began -> approaches\n",
      "began -> approaches -> sub-symbolic\n",
      "began -> problems\n",
      "began -> problems -> ai\n",
      "manage -> methods\n",
      "manage -> intelligence\n",
      "manage -> representations\n",
      "manage -> representations -> knowledge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "includes -> ai\n",
      "includes -> ai -> behavior\n",
      "rejected -> researchers\n",
      "rejected -> researchers -> field\n",
      "rejected -> researchers -> field -> robotics\n",
      "rejected -> researchers -> field -> rodney\n",
      "rejected -> researchers -> field -> rodney -> brooks\n",
      "rejected -> ai\n",
      "rejected -> problems\n",
      "rejected -> problems -> engineering\n",
      "rejected -> problems -> robots\n",
      "revived -> work\n",
      "revived -> point\n",
      "revived -> point -> view\n",
      "revived -> point -> view -> researchers\n",
      "revived -> point -> view -> researchers -> cybernetics\n",
      "revived -> point -> view -> researchers -> 1950s\n",
      "revived -> use\n",
      "revived -> use -> theory\n",
      "revived -> use -> theory -> control\n",
      "revived -> ai\n",
      "coincided -> development\n",
      "coincided -> development -> thesis\n",
      "coincided -> development -> thesis -> mind\n",
      "coincided -> development -> thesis -> field\n",
      "coincided -> development -> thesis -> field -> science\n",
      "coincided -> idea\n",
      "coincided -> idea -> aspects\n",
      "coincided -> idea -> aspects -> body\n",
      "coincided -> idea -> aspects -> body -> movement\n",
      "coincided -> idea -> aspects -> body -> movement -> perception\n",
      "coincided -> idea -> aspects -> body -> movement -> visualization\n",
      "coincided -> idea -> intelligence\n",
      "elaborated -> robotics\n",
      "elaborated -> approaches\n",
      "elaborated -> approaches -> learning\n",
      "elaborated -> robots\n",
      "elaborated -> repertoires\n",
      "elaborated -> repertoires -> skills\n",
      "elaborated -> self-exploration\n",
      "elaborated -> self-exploration -> interaction\n",
      "elaborated -> self-exploration -> interaction -> teachers\n",
      "elaborated -> self-exploration -> use\n",
      "elaborated -> self-exploration -> use -> mechanisms\n",
      "elaborated -> self-exploration -> use -> mechanisms -> guidance\n",
      "elaborated -> self-exploration -> use -> mechanisms -> learning\n",
      "elaborated -> self-exploration -> use -> mechanisms -> learning -> maturation\n",
      "elaborated -> self-exploration -> use -> mechanisms -> learning -> synergies\n",
      "elaborated -> self-exploration -> use -> mechanisms -> learning -> synergies -> motor\n",
      "revived -> interest\n",
      "revived -> interest -> networks\n",
      "revived -> interest -> networks -> connectionism\n",
      "revived -> david\n",
      "revived -> david -> rumelhart\n",
      "revived -> david -> others\n",
      "revived -> middle\n",
      "revived -> middle -> 1980s\n",
      "example -> networks\n",
      "example -> computing\n",
      "example -> solutions\n",
      "example -> solutions -> problems\n",
      "example -> solutions -> problems -> certainty\n",
      "example -> solutions -> problems -> solution\n",
      "include -> approaches\n",
      "include -> approaches -> computing\n",
      "include -> systems\n",
      "include -> systems -> theory\n",
      "include -> systems -> theory -> system\n",
      "include -> systems -> computation\n",
      "include -> systems -> tools\n",
      "studied -> application\n",
      "studied -> application -> computing\n",
      "studied -> application -> computing -> ai\n",
      "studied -> discipline\n",
      "studied -> discipline -> intelligence\n",
      "bogged -> gofai\n",
      "bogged -> patches\n",
      "bogged -> patches -> hoc\n",
      "bogged -> patches -> hoc -> ad\n",
      "bogged -> computation\n",
      "bogged -> computation -> models\n",
      "bogged -> computation -> models -> toy\n",
      "bogged -> computation -> results\n",
      "ai -> 1990s\n",
      "ai -> researchers\n",
      "ai -> tools\n",
      "ai -> tools -> models\n",
      "ai -> tools -> models -> hmm\n",
      "ai -> tools -> models -> theory\n",
      "ai -> tools -> models -> theory -> information\n",
      "ai -> tools -> models -> theory\n",
      "ai -> tools -> models -> theory -> decision\n",
      "ai -> tools -> models -> theory -> architectures\n",
      "permitted -> language\n",
      "permitted -> level\n",
      "permitted -> level -> collaboration\n",
      "permitted -> fields\n",
      "permitted -> fields -> mathematics\n",
      "permitted -> fields -> mathematics -> economics\n",
      "permitted -> fields -> mathematics -> research\n",
      "permitted -> fields -> mathematics -> research -> operations\n",
      "gaining -> gofai\n",
      "gaining -> techniques\n",
      "gaining -> techniques -> learning\n",
      "gaining -> techniques -> hmm\n",
      "gaining -> techniques -> hmm -> networks\n",
      "gaining -> levels\n",
      "gaining -> levels -> accuracy\n",
      "gaining -> levels -> domains\n",
      "gaining -> levels -> domains -> mining\n",
      "gaining -> levels -> domains -> mining -> data\n",
      "gaining -> understanding\n",
      "gaining -> understanding -> datasets\n",
      "led -> successes\n",
      "led -> successes -> data\n",
      "led -> emphasis\n",
      "led -> emphasis -> approaches\n",
      "led -> emphasis -> approaches -> data\n",
      "led -> emphasis -> approaches -> data -> test\n",
      "led -> emphasis -> approach\n",
      "led -> emphasis -> context\n",
      "led -> emphasis -> context -> models\n",
      "led -> emphasis -> context -> models -> toy\n",
      "led -> research\n",
      "measurable -> results\n",
      "measurable -> results -> experiments\n",
      "measurable -> difficulty\n",
      "have -> techniques\n",
      "have -> techniques -> learning\n",
      "have -> limitations\n",
      "have -> example\n",
      "have -> hmm\n",
      "have -> combinations\n",
      "have -> combinations -> language\n",
      "note -> critics\n",
      "note -> shift\n",
      "note -> shift\n",
      "note -> shift -> gofai\n",
      "note -> shift -> gofai -> learning\n",
      "note -> ai\n",
      "caution -> research\n",
      "caution -> research -> agi\n",
      "caution -> scholars\n",
      "caution -> learning\n",
      "caution -> research\n",
      "caution -> research -> gofai\n",
      "caution -> intelligence\n",
      "developed -> tools\n",
      "developed -> tools -> problems\n",
      "developed -> tools -> problems -> science\n",
      "developed -> tools -> problems -> science -> computer\n",
      "discussed -> methods\n",
      "solved -> problems\n",
      "solved -> problems -> ai\n",
      "solved -> theory\n",
      "solved -> solutions\n",
      "reduced -> reasoning\n",
      "reduced -> search\n",
      "viewed -> example\n",
      "viewed -> proof\n",
      "viewed -> path\n",
      "viewed -> path -> premises\n",
      "viewed -> path -> conclusions\n",
      "viewed -> path -> application\n",
      "viewed -> path -> application -> step\n",
      "viewed -> path -> application -> rule\n",
      "viewed -> path -> application -> rule -> inference\n",
      "search -> algorithms\n",
      "search -> trees\n",
      "search -> trees -> goals\n",
      "search -> trees -> goals -> subgoals\n",
      "search -> path\n",
      "search -> path -> goal\n",
      "search -> path -> goal -> target\n",
      "search -> path -> goal -> process\n",
      "search -> path -> goal -> process -> analysis\n",
      "search -> path -> goal -> process -> analysis -> means-ends\n",
      "use -> algorithms\n",
      "use -> algorithms -> robotics\n",
      "use -> algorithms -> limbs\n",
      "use -> algorithms -> limbs -> objects\n",
      "use -> searches\n",
      "use -> space\n",
      "use -> space -> configuration\n",
      "use -> algorithms\n",
      "use -> algorithms -> learning\n",
      "use -> algorithms\n",
      "use -> algorithms -> search\n",
      "use -> algorithms -> optimization\n",
      "sufficient -> searches\n",
      "sufficient -> problems\n",
      "sufficient -> space\n",
      "sufficient -> space -> search\n",
      "sufficient -> space -> number\n",
      "sufficient -> space -> number -> places\n",
      "sufficient -> numbers\n",
      "search -> result\n",
      "use -> solution\n",
      "use -> problems\n",
      "use -> heuristics\n",
      "use -> heuristics -> rules\n",
      "use -> heuristics -> rules -> thumb\n",
      "use -> heuristics -> choices\n",
      "use -> heuristics -> favor\n",
      "use -> heuristics -> favor -> goal\n",
      "use -> heuristics -> favor -> number\n",
      "use -> heuristics -> favor -> number -> steps\n",
      "serve -> methodologies\n",
      "serve -> methodologies -> search\n",
      "serve -> heuristics\n",
      "serve -> choices\n",
      "serve -> choices -> goal\n",
      "serve -> choices -> goal -> tree\n",
      "serve -> choices -> goal -> tree -> search\n",
      "supply -> heuristics\n",
      "supply -> program\n",
      "supply -> guess\n",
      "supply -> path\n",
      "supply -> path -> solution\n",
      "limit -> heuristics\n",
      "limit -> search\n",
      "limit -> search -> solutions\n",
      "limit -> size\n",
      "limit -> size -> sample\n",
      "came -> kind\n",
      "came -> kind -> search\n",
      "came -> prominence\n",
      "came -> 1990s\n",
      "came -> theory\n",
      "came -> theory -> optimization\n",
      "possible -> problems\n",
      "possible -> search\n",
      "possible -> form\n",
      "possible -> form -> guess\n",
      "possible -> guess\n",
      "possible -> refinements\n",
      "visualized -> algorithms\n",
      "visualized -> climbing\n",
      "visualized -> climbing -> hill\n",
      "visualized -> search\n",
      "visualized -> point\n",
      "visualized -> point -> landscape\n",
      "visualized -> jumps\n",
      "visualized -> jumps -> steps\n",
      "visualized -> guess\n",
      "visualized -> top\n",
      "annealing -> algorithms\n",
      "annealing -> algorithms -> optimization\n",
      "annealing -> search\n",
      "annealing -> search -> beam\n",
      "annealing -> optimization\n",
      "uses -> computation\n",
      "uses -> form\n",
      "uses -> form -> search\n",
      "uses -> form -> search -> optimization\n",
      "begin -> example\n",
      "begin -> population\n",
      "begin -> population -> organisms\n",
      "begin -> population -> organisms -> guesses\n",
      "begin -> fittest\n",
      "begin -> fittest -> generation\n",
      "begin -> fittest -> guesses\n",
      "include -> algorithms\n",
      "include -> algorithms\n",
      "include -> algorithms -> programming\n",
      "include -> algorithms -> programming -> gene\n",
      "include -> algorithms -> programming -> expression\n",
      "include -> algorithms -> programming\n",
      "coordinate -> processes\n",
      "coordinate -> processes -> search\n",
      "coordinate -> algorithms\n",
      "coordinate -> algorithms -> swarm\n",
      "coordinate -> algorithms -> intelligence\n",
      "optimization -> algorithms\n",
      "optimization -> algorithms -> swarm\n",
      "optimization -> algorithms -> search\n",
      "optimization -> particle\n",
      "optimization -> swarm\n",
      "optimization -> flocking\n",
      "optimization -> flocking -> bird\n",
      "optimization -> optimization\n",
      "optimization -> optimization -> colony\n",
      "optimization -> optimization -> colony -> ant\n",
      "optimization -> optimization -> trails\n",
      "optimization -> optimization -> trails -> ant\n",
      "used -> logic\n",
      "used -> representation\n",
      "used -> representation -> knowledge\n",
      "used -> representation -> solving\n",
      "used -> representation -> solving -> problem\n",
      "used -> problems\n",
      "uses -> example\n",
      "uses -> algorithm\n",
      "uses -> logic\n",
      "uses -> planning\n",
      "uses -> method\n",
      "uses -> method -> programming\n",
      "uses -> method -> programming -> logic\n",
      "uses -> method -> learning\n",
      "used -> forms\n",
      "used -> forms -> logic\n",
      "used -> research\n",
      "used -> research -> ai\n",
      "involves -> logic\n",
      "involves -> functions\n",
      "involves -> functions -> truth\n",
      "adds -> logic\n",
      "adds -> quantifiers\n",
      "adds -> quantifiers -> predicates\n",
      "adds -> facts\n",
      "adds -> facts -> objects\n",
      "adds -> facts -> objects -> properties\n",
      "adds -> facts -> objects -> relations\n",
      "assigns -> theory\n",
      "assigns -> theory -> set\n",
      "assigns -> degree\n",
      "assigns -> degree -> truth\n",
      "assigns -> statements\n",
      "assigns -> statements -> alice\n",
      "used -> logic\n",
      "used -> systems\n",
      "used -> systems -> control\n",
      "used -> experts\n",
      "used -> rules\n",
      "used -> station\n",
      "used -> station -> destination\n",
      "used -> pressure\n",
      "used -> pressure -> train\n",
      "used -> pressure -> brake\n",
      "used -> rules\n",
      "used -> system\n",
      "fails -> logic\n",
      "fails -> bases\n",
      "fails -> bases -> knowledge\n",
      "fails -> researchers\n",
      "fails -> researchers -> ai\n",
      "fails -> validity\n",
      "fails -> validity -> inferences\n",
      "fails -> validity -> inferences -> -logic\n",
      "forms -> logics\n",
      "forms -> logics -> default\n",
      "forms -> logics -> logics\n",
      "forms -> logics -> circumscription\n",
      "forms -> logic\n",
      "forms -> logic -> reasoning\n",
      "forms -> logic -> reasoning -> default\n",
      "forms -> logic -> reasoning -> problem\n",
      "forms -> logic -> reasoning -> problem -> qualification\n",
      "designed -> extensions\n",
      "designed -> extensions -> logic\n",
      "designed -> domains\n",
      "designed -> domains -> knowledge\n",
      "designed -> domains -> logics\n",
      "designed -> domains -> logics -> description\n",
      "designed -> domains -> logics -> calculus\n",
      "designed -> domains -> logics -> calculus -> situation\n",
      "designed -> domains -> logics -> calculus\n",
      "designed -> domains -> logics -> calculus -> event\n",
      "designed -> domains -> logics -> calculus\n",
      "designed -> domains -> logics -> calculus\n",
      "designed -> domains -> logics -> calculus -> calculus\n",
      "designed -> domains -> logics -> calculus -> calculus -> belief\n",
      "designed -> domains -> logics -> calculus -> calculus -> revision\n",
      "designed -> domains -> logics -> calculus -> calculus -> revision -> belief\n",
      "designed -> domains -> logics -> calculus -> logics\n",
      "designed -> events\n",
      "designed -> events -> time\n",
      "designed -> logics\n",
      "designed -> logics -> statements\n",
      "designed -> logics -> statements -> systems\n",
      "designed -> logics\n",
      "designed -> logics -> paraconsistent\n",
      "require -> problems\n",
      "require -> problems -> ai\n",
      "require -> problems -> reasoning\n",
      "require -> problems -> reasoning -> planning\n",
      "require -> problems -> reasoning -> learning\n",
      "require -> problems -> reasoning -> perception\n",
      "require -> problems -> reasoning -> robotics\n",
      "require -> agent\n",
      "require -> agent -> information\n",
      "devised -> researchers\n",
      "devised -> number\n",
      "devised -> number -> tools\n",
      "devised -> problems\n",
      "devised -> methods\n",
      "devised -> methods -> theory\n",
      "devised -> methods -> theory -> probability\n",
      "devised -> methods -> theory -> economics\n",
      "tool -> networks\n",
      "tool -> problems\n",
      "tool -> problems -> reasoning\n",
      "tool -> problems -> reasoning -> algorithm\n",
      "tool -> problems -> reasoning -> algorithm -> inference\n",
      "tool -> problems -> reasoning -> planning\n",
      "tool -> problems -> reasoning -> planning -> networks\n",
      "tool -> problems -> reasoning -> planning -> networks -> decision\n",
      "tool -> problems -> reasoning -> perception\n",
      "tool -> problems -> reasoning -> perception -> networks\n",
      "tool -> algorithm\n",
      "tool -> algorithm -> maximization\n",
      "tool -> algorithm -> maximization -> expectation\n",
      "used -> algorithms\n",
      "used -> filtering\n",
      "used -> filtering -> prediction\n",
      "used -> filtering -> finding\n",
      "used -> filtering -> explanations\n",
      "used -> filtering -> explanations -> streams\n",
      "used -> filtering -> explanations -> streams -> data\n",
      "used -> systems\n",
      "used -> systems -> perception\n",
      "used -> processes\n",
      "used -> processes -> time\n",
      "used -> processes -> time -> models\n",
      "used -> processes -> time -> models -> filters\n",
      "used -> processes -> time -> models -> filters -> kalman\n",
      "expensive -> logic\n",
      "expensive -> inference\n",
      "independent -> inference\n",
      "independent -> observations\n",
      "require -> graphs\n",
      "require -> graphs -> diamonds\n",
      "require -> graphs -> diamonds -> loops\n",
      "require -> graphs -> diamonds -> loops -> cycles\n",
      "require -> method\n",
      "require -> method -> chain\n",
      "require -> method -> chain -> monte\n",
      "require -> method -> chain -> monte -> carlo\n",
      "require -> method -> chain -> ensemble\n",
      "require -> method -> chain -> ensemble -> walkers\n",
      "require -> method -> chain -> network\n",
      "require -> method -> chain -> network -> attempts\n",
      "require -> method -> chain -> network -> attempts -> assessment\n",
      "require -> method -> chain -> network -> attempts -> assessment -> probabilities\n",
      "used -> networks\n",
      "used -> live\n",
      "used -> live -> xbox\n",
      "used -> players\n",
      "used -> evidence\n",
      "used -> evidence -> wins\n",
      "used -> evidence -> wins -> losses\n",
      "used -> evidence -> player\n",
      "uses -> adsense\n",
      "uses -> network\n",
      "uses -> edges\n",
      "uses -> ads\n",
      "utility -> concept\n",
      "utility -> concept -> science\n",
      "utility -> concept -> science -> economics\n",
      "utility -> measure\n",
      "utility -> measure -> something\n",
      "utility -> measure -> agent\n",
      "developed -> tools\n",
      "developed -> agent\n",
      "developed -> choices\n",
      "developed -> choices -> plan\n",
      "developed -> theory\n",
      "developed -> theory -> decision\n",
      "developed -> theory -> analysis\n",
      "developed -> theory -> analysis -> decision\n",
      "developed -> theory -> theory\n",
      "developed -> theory -> theory -> information\n",
      "developed -> theory -> theory -> value\n",
      "include -> tools\n",
      "include -> models\n",
      "include -> models -> processes\n",
      "include -> models -> processes -> decision\n",
      "include -> models -> processes -> networks\n",
      "include -> models -> processes -> networks -> decision\n",
      "include -> models -> processes -> theory\n",
      "include -> models -> processes -> theory -> game\n",
      "include -> models -> processes -> design\n",
      "include -> models -> processes -> design -> mechanism\n",
      "divided -> applications\n",
      "divided -> applications -> ai\n",
      "divided -> types\n",
      "divided -> types -> classifiers\n",
      "divided -> types -> classifiers -> diamond\n",
      "divided -> types -> classifiers -> controllers\n",
      "classify -> controllers\n",
      "classify -> conditions\n",
      "classify -> actions\n",
      "classify -> classification\n",
      "classify -> part\n",
      "classify -> part -> systems\n",
      "classify -> part -> systems -> ai\n",
      "functions -> classifiers\n",
      "functions -> pattern\n",
      "functions -> match\n",
      "tuned -> examples\n",
      "tuned -> use\n",
      "tuned -> use -> ai\n",
      "known -> examples\n",
      "known -> observations\n",
      "known -> observations -> patterns\n",
      "belongs -> learning\n",
      "belongs -> pattern\n",
      "belongs -> class\n",
      "seen -> class\n",
      "seen -> decision\n",
      "known -> observations\n",
      "known -> observations -> labels\n",
      "known -> observations -> labels -> class\n",
      "known -> set\n",
      "known -> set -> data\n",
      "classified -> observation\n",
      "classified -> observation\n",
      "classified -> experience\n",
      "trained -> classifier\n",
      "trained -> ways\n",
      "trained -> approaches\n",
      "trained -> approaches -> machine\n",
      "trained -> approaches -> learning\n",
      "algorithm -> tree\n",
      "algorithm -> tree -> decision\n",
      "algorithm -> machine\n",
      "algorithm -> learning\n",
      "network -> classifiers\n",
      "network -> algorithm\n",
      "network -> algorithm -> neighbor\n",
      "network -> methods\n",
      "network -> methods -> kernel\n",
      "network -> machine\n",
      "network -> machine -> vector\n",
      "network -> machine -> vector -> support\n",
      "network -> machine -> svm\n",
      "network -> machine -> model\n",
      "network -> machine -> model -> mixture\n",
      "network -> machine -> classifier\n",
      "network -> machine -> classifier -> bayes\n",
      "depends -> performance\n",
      "depends -> performance -> classifier\n",
      "depends -> characteristics\n",
      "depends -> characteristics -> data\n",
      "depends -> characteristics -> size\n",
      "depends -> characteristics -> size -> dataset\n",
      "depends -> characteristics -> size -> distribution\n",
      "depends -> characteristics -> size -> distribution -> samples\n",
      "depends -> characteristics -> size -> distribution -> samples -> classes\n",
      "depends -> characteristics -> size -> dimensionality\n",
      "depends -> characteristics -> size -> level\n",
      "depends -> characteristics -> size -> level -> noise\n",
      "perform -> classifiers\n",
      "perform -> classifiers -> model\n",
      "perform -> fit\n",
      "perform -> fit -> model\n",
      "perform -> fit -> data\n",
      "is -> model\n",
      "is -> model -> matching\n",
      "is -> concern\n",
      "is -> concern -> accuracy\n",
      "is -> concern -> accuracy -> speed\n",
      "is -> concern -> accuracy -> speed -> scalability\n",
      "is -> wisdom\n",
      "is -> classifiers\n",
      "is -> classifiers -> svm\n",
      "is -> classifiers\n",
      "is -> classifiers -> model\n",
      "is -> classifiers -> bayes\n",
      "is -> classifiers -> sets\n",
      "is -> classifiers -> sets -> data\n",
      "inspired -> networks\n",
      "inspired -> architecture\n",
      "inspired -> architecture -> neurons\n",
      "inspired -> architecture -> neurons -> brain\n",
      "accepts -> n\n",
      "accepts -> n -> neuron\n",
      "accepts -> input\n",
      "accepts -> neurons\n",
      "accepts -> vote\n",
      "accepts -> n\n",
      "accepts -> n -> neuron\n",
      "requires -> learning\n",
      "requires -> algorithm\n",
      "requires -> algorithm -> weights\n",
      "requires -> algorithm -> data\n",
      "requires -> algorithm -> data -> training\n",
      "requires -> algorithm\n",
      "requires -> algorithm -> fire\n",
      "requires -> algorithm -> wire\n",
      "requires -> weight\n",
      "requires -> weight -> neurons\n",
      "requires -> activation\n",
      "requires -> activation\n",
      "forms -> network\n",
      "forms -> concepts\n",
      "forms -> concepts -> subnetwork\n",
      "forms -> concepts -> subnetwork -> neurons\n",
      "forms -> concepts -> subnetwork -> neurons -> meaning\n",
      "forms -> concepts -> subnetwork -> neurons -> meaning -> concept\n",
      "forms -> concepts -> subnetwork -> neurons -> meaning -> leg\n",
      "forms -> concepts -> subnetwork -> neurons -> meaning\n",
      "forms -> concepts -> subnetwork -> neurons -> meaning -> subnetwork\n",
      "forms -> concepts -> subnetwork -> neurons -> meaning -> foot\n",
      "forms -> concepts -> subnetwork -> neurons -> meaning -> sound\n",
      "forms -> concepts -> subnetwork -> neurons -> meaning -> sound -> foot\n",
      "have -> neurons\n",
      "have -> spectrum\n",
      "have -> spectrum -> activation\n",
      "have -> addition\n",
      "have -> neurons\n",
      "have -> inputs\n",
      "have -> way\n",
      "have -> votes\n",
      "learn -> networks\n",
      "learn -> functions\n",
      "learn -> functions -> operations\n",
      "included -> successes\n",
      "included -> successes -> networks\n",
      "included -> market\n",
      "included -> market -> stock\n",
      "included -> market -> car\n",
      "ai -> 2010s\n",
      "ai -> advances\n",
      "ai -> advances -> networks\n",
      "ai -> advances -> networks -> thrust\n",
      "ai -> advances -> networks -> thrust -> learning\n",
      "ai -> consciousness\n",
      "ai -> upshift\n",
      "ai -> upshift -> spending\n",
      "ai -> upshift -> spending -> ai\n",
      "ai -> example\n",
      "ai -> m&a\n",
      "ai -> m&a -> ai\n",
      "ai -> times\n",
      "began -> study\n",
      "began -> study -> networks\n",
      "began -> decade\n",
      "began -> field\n",
      "began -> field -> research\n",
      "began -> field -> research -> ai\n",
      "began -> work\n",
      "began -> work -> walter\n",
      "began -> work -> walter -> pitts\n",
      "began -> work -> walter -> warren\n",
      "began -> work -> walter -> warren -> mccullouch\n",
      "invented -> frank\n",
      "invented -> frank -> rosenblatt\n",
      "invented -> perceptron\n",
      "invented -> perceptron -> network\n",
      "invented -> perceptron -> network -> learning\n",
      "invented -> perceptron -> network -> layer\n",
      "invented -> perceptron -> concept\n",
      "invented -> perceptron -> concept -> regression\n",
      "include -> pioneers\n",
      "include -> alexey\n",
      "include -> alexey -> grigorevich\n",
      "include -> alexey -> ivakhnenko\n",
      "include -> alexey -> teuvo\n",
      "include -> alexey -> teuvo -> kohonen\n",
      "include -> alexey -> stephen\n",
      "include -> alexey -> stephen -> grossberg\n",
      "include -> alexey -> kunihiko\n",
      "include -> alexey -> kunihiko -> fukushima\n",
      "include -> alexey -> christoph\n",
      "include -> alexey -> christoph -> von\n",
      "include -> alexey -> christoph -> der\n",
      "include -> alexey -> christoph -> malsburg\n",
      "include -> alexey -> david\n",
      "include -> alexey -> david -> willshaw\n",
      "include -> alexey -> shun-ichi\n",
      "include -> alexey -> shun-ichi -> amari\n",
      "include -> alexey -> bernard\n",
      "include -> alexey -> bernard -> widrow\n",
      "include -> alexey -> john\n",
      "include -> alexey -> john -> hopfield\n",
      "include -> alexey -> eduardo\n",
      "include -> alexey -> eduardo -> r.\n",
      "include -> alexey -> eduardo -> caianiello\n",
      "include -> alexey -> others\n",
      "networks -> categories\n",
      "networks -> categories -> networks\n",
      "networks -> signal\n",
      "networks -> direction\n",
      "networks -> networks\n",
      "networks -> networks -> memories\n",
      "networks -> networks -> memories -> feedback\n",
      "networks -> networks -> memories -> feedback -> term\n",
      "networks -> networks -> memories -> events\n",
      "networks -> networks -> memories -> events -> input\n",
      "perceptrons -> networks\n",
      "perceptrons -> perceptrons\n",
      "perceptrons -> networks\n",
      "perceptrons -> networks -> basis\n",
      "applied -> networks\n",
      "applied -> problem\n",
      "applied -> problem -> control\n",
      "applied -> problem -> control -> robotics\n",
      "applied -> problem -> control -> learning\n",
      "applied -> techniques\n",
      "applied -> learning\n",
      "applied -> learning -> hebbian\n",
      "applied -> learning -> fire\n",
      "applied -> learning -> fire -> wire\n",
      "applied -> learning -> gmdh\n",
      "applied -> learning -> gmdh -> learning\n",
      "trained -> today\n",
      "trained -> networks\n",
      "trained -> algorithm\n",
      "trained -> algorithm -> backpropagation\n",
      "trained -> algorithm -> mode\n",
      "trained -> algorithm -> mode -> differentiation\n",
      "trained -> algorithm -> mode -> differentiation -> seppo\n",
      "trained -> algorithm -> mode -> differentiation -> seppo -> linnainmaa\n",
      "trained -> networks\n",
      "trained -> paul\n",
      "trained -> paul -> werbos\n",
      "approach -> memory\n",
      "approach -> properties\n",
      "approach -> properties -> neocortex\n",
      "use -> networks\n",
      "use -> form\n",
      "use -> form -> descent\n",
      "use -> form -> descent -> gradient\n",
      "use -> topology\n",
      "argue -> groups\n",
      "argue -> groups -> research\n",
      "argue -> groups -> uber\n",
      "argue -> neuroevolution\n",
      "argue -> neuroevolution -> topologies\n",
      "argue -> neuroevolution -> topologies -> network\n",
      "argue -> neuroevolution -> topologies -> weights\n",
      "argue -> approaches\n",
      "argue -> approaches -> descent\n",
      "argue -> approaches -> descent -> gradient\n",
      "is -> advantage\n",
      "is -> advantage -> neuroevolution\n",
      "is -> ends\n",
      "network -> learning\n",
      "network -> chain\n",
      "network -> chain -> links\n",
      "learn -> example\n",
      "learn -> network\n",
      "learn -> network -> layers\n",
      "learn -> chain\n",
      "learn -> chain -> layers\n",
      "learn -> chain -> layers -> layer\n",
      "learn -> chain -> layers -> layer -> output\n",
      "learn -> depth\n",
      "learn -> depth -> path\n",
      "learn -> depth -> path -> assignment\n",
      "learn -> depth -> path -> assignment -> credit\n",
      "learn -> depth -> path -> cap\n",
      "need -> systems\n",
      "need -> systems -> learning\n",
      "need -> chains\n",
      "need -> links\n",
      "need -> links -> length\n",
      "transformed -> learning\n",
      "transformed -> subfields\n",
      "transformed -> subfields -> intelligence\n",
      "transformed -> subfields -> vision\n",
      "transformed -> subfields -> vision -> computer\n",
      "transformed -> subfields -> vision -> recognition\n",
      "transformed -> subfields -> vision -> recognition -> speech\n",
      "transformed -> subfields -> vision -> processing\n",
      "transformed -> subfields -> vision -> processing -> language\n",
      "transformed -> subfields -> vision -> others\n",
      "introduced -> overview\n",
      "introduced -> expression\n",
      "introduced -> expression -> learning\n",
      "introduced -> community\n",
      "introduced -> community -> machine\n",
      "introduced -> community -> learning\n",
      "introduced -> rina\n",
      "introduced -> rina -> dechter\n",
      "introduced -> traction\n",
      "introduced -> igor\n",
      "introduced -> igor -> aizenberg\n",
      "introduced -> igor -> colleagues\n",
      "introduced -> networks\n",
      "published -> networks\n",
      "published -> networks -> learning\n",
      "published -> alexey\n",
      "published -> alexey -> grigorevich\n",
      "published -> alexey -> ivakhnenko\n",
      "published -> alexey -> v.\n",
      "published -> alexey -> v. -> g.\n",
      "published -> alexey -> v. -> lapa\n",
      "trained -> networks\n",
      "trained -> layer\n",
      "trained -> time\n",
      "describes -> paper\n",
      "describes -> paper -> ivakhnenko\n",
      "describes -> learning\n",
      "describes -> learning -> perceptron\n",
      "describes -> learning -> perceptron -> multilayer\n",
      "describes -> layers\n",
      "describes -> networks\n",
      "introduced -> publication\n",
      "introduced -> publication -> geoffrey\n",
      "introduced -> publication -> geoffrey -> hinton\n",
      "introduced -> publication -> geoffrey -> ruslan\n",
      "introduced -> publication -> geoffrey -> ruslan -> salakhutdinov\n",
      "introduced -> way\n",
      "introduced -> way -> networks\n",
      "introduced -> way -> networks -> fnns\n",
      "introduced -> way -> layer\n",
      "introduced -> way -> layer -> time\n",
      "introduced -> way -> layer\n",
      "introduced -> way -> turn\n",
      "introduced -> way -> machine\n",
      "introduced -> way -> machine -> boltzmann\n",
      "introduced -> way -> backpropagation\n",
      "introduced -> way -> backpropagation -> fine-tuning\n",
      "model -> networks\n",
      "model -> networks\n",
      "model -> relationships\n",
      "led -> years\n",
      "led -> advances\n",
      "led -> advances -> algorithms\n",
      "led -> advances -> algorithms -> machine\n",
      "led -> advances -> algorithms -> learning\n",
      "led -> advances -> algorithms -> hardware\n",
      "led -> advances -> algorithms -> hardware -> computer\n",
      "led -> methods\n",
      "led -> methods -> networks\n",
      "led -> methods -> networks -> layers\n",
      "led -> methods -> networks -> layers -> units\n",
      "led -> methods -> networks -> layers -> units -> layer\n",
      "led -> methods -> networks -> layers -> units -> layer -> output\n",
      "uses -> learning\n",
      "uses -> networks\n",
      "uses -> networks -> cnns\n",
      "uses -> networks -> origins\n",
      "uses -> networks -> neocognitron\n",
      "uses -> networks -> neocognitron -> kunihiko\n",
      "uses -> networks -> neocognitron -> kunihiko -> fukushima\n",
      "applied -> yann\n",
      "applied -> yann -> lecun\n",
      "applied -> yann -> colleagues\n",
      "applied -> backpropagation\n",
      "applied -> architecture\n",
      "processed -> 2000s\n",
      "processed -> application\n",
      "processed -> cnns\n",
      "processed -> %\n",
      "processed -> % -> %\n",
      "processed -> % -> checks\n",
      "processed -> % -> checks -> us\n",
      "won -> implementations\n",
      "won -> implementations -> cnns\n",
      "won -> implementations -> cnns -> gpus\n",
      "won -> competitions\n",
      "won -> competitions -> pattern\n",
      "won -> competitions -> recognition\n",
      "used -> cnns\n",
      "used -> cnns -> layers\n",
      "used -> conjunction\n",
      "used -> conjunction -> reinforcement\n",
      "used -> conjunction -> reinforcement -> alphago\n",
      "used -> conjunction -> reinforcement -> alphago -> deepmind\n",
      "used -> conjunction -> reinforcement -> alphago -> lee\n",
      "used -> conjunction -> reinforcement -> alphago -> program\n",
      "used -> conjunction -> reinforcement -> alphago -> program -> champion\n",
      "used -> conjunction -> reinforcement -> alphago -> program -> champion -> go\n",
      "applied -> learning\n",
      "applied -> learning\n",
      "applied -> learning -> sequence\n",
      "applied -> learning -> networks\n",
      "applied -> learning -> networks -> rnns\n",
      "applied -> learning -> networks -> theory\n",
      "applied -> learning -> networks -> theory -> turing\n",
      "applied -> learning -> networks -> theory -> programs\n",
      "applied -> learning -> networks -> theory -> sequences\n",
      "applied -> learning -> networks -> theory -> sequences -> inputs\n",
      "unlimited -> depth\n",
      "unlimited -> depth -> rnn\n",
      "unlimited -> length\n",
      "unlimited -> length -> sequence\n",
      "unlimited -> length -> sequence -> input\n",
      "unlimited -> example\n",
      "unlimited -> example -> rnn\n",
      "unlimited -> example -> learning\n",
      "trained -> rnns\n",
      "trained -> descent\n",
      "trained -> descent -> gradient\n",
      "trained -> problem\n",
      "trained -> problem -> gradient\n",
      "shown -> pre-training\n",
      "shown -> pre-training -> stack\n",
      "shown -> pre-training -> stack -> networks\n",
      "shown -> learning\n",
      "shown -> learning -> problems\n",
      "use -> researchers\n",
      "use -> variants\n",
      "use -> variants -> nn\n",
      "use -> variants -> nn -> learning\n",
      "use -> variants -> nn -> memory\n",
      "use -> variants -> nn -> memory -> term\n",
      "use -> variants -> nn -> memory -> lstm\n",
      "use -> variants -> nn -> memory -> network\n",
      "use -> variants -> nn -> memory -> network -> hochreiter\n",
      "use -> variants -> nn -> memory -> network -> hochreiter -> schmidhuber\n",
      "trained -> lstm\n",
      "trained -> classification\n",
      "trained -> classification -> connectionist\n",
      "trained -> classification -> temporal\n",
      "trained -> classification -> ctc\n",
      "revolutionized -> google\n",
      "revolutionized -> microsoft\n",
      "revolutionized -> microsoft -> baidu\n",
      "revolutionized -> approach\n",
      "revolutionized -> recognition\n",
      "revolutionized -> recognition -> speech\n",
      "experienced -> example\n",
      "experienced -> recognition\n",
      "experienced -> recognition -> google\n",
      "experienced -> recognition -> speech\n",
      "experienced -> jump\n",
      "experienced -> jump -> performance\n",
      "experienced -> jump -> %\n",
      "experienced -> jump -> % -> lstm\n",
      "experienced -> jump -> % -> lstm -> ctc\n",
      "experienced -> jump -> % -> lstm -> google\n",
      "experienced -> jump -> % -> lstm -> google -> voice\n",
      "experienced -> jump -> % -> lstm -> billions\n",
      "experienced -> jump -> % -> lstm -> billions -> users\n",
      "experienced -> jump -> % -> lstm -> billions -> users -> smartphone\n",
      "used -> google\n",
      "used -> lstm\n",
      "used -> translation\n",
      "used -> translation -> machine\n",
      "used -> translation -> modeling\n",
      "used -> translation -> modeling -> language\n",
      "used -> translation -> processing\n",
      "used -> translation -> processing -> language\n",
      "improved -> lstm\n",
      "improved -> lstm -> cnns\n",
      "improved -> captioning\n",
      "improved -> captioning -> image\n",
      "improved -> captioning -> plethora\n",
      "improved -> captioning -> plethora -> applications\n",
      "ai -> technology\n",
      "ai -> technology -> electricity\n",
      "ai -> technology -> electricity -> engine\n",
      "ai -> technology -> electricity -> engine -> steam\n",
      "ai -> technology -> purpose\n",
      "is -> consensus\n",
      "is -> consensus -> tasks\n",
      "require -> projects\n",
      "require -> projects -> alphazero\n",
      "require -> knowledge\n",
      "require -> scratch\n",
      "require -> projects\n",
      "require -> projects -> machine\n",
      "require -> projects -> learning\n",
      "require -> datasets\n",
      "require -> datasets -> training\n",
      "andrew -> researcher\n",
      "suggested -> ng\n",
      "suggested -> rule\n",
      "suggested -> rule -> thumb\n",
      "suggested -> anything\n",
      "suggested -> human\n",
      "suggested -> second\n",
      "suggested -> second -> thought\n",
      "suggested -> future\n",
      "suggests -> paradox\n",
      "suggests -> paradox -> moravec\n",
      "suggests -> humans\n",
      "suggests -> tasks\n",
      "suggests -> tasks -> brain\n",
      "provide -> games\n",
      "provide -> benchmark\n",
      "provide -> benchmark -> rates\n",
      "provide -> benchmark -> rates -> progress\n",
      "brought -> alphago\n",
      "brought -> era\n",
      "brought -> era -> benchmarks\n",
      "brought -> era -> benchmarks -> game\n",
      "brought -> era -> benchmarks -> game -> board\n",
      "brought -> close\n",
      "provide -> games\n",
      "provide -> games -> knowledge\n",
      "provide -> challenges\n",
      "provide -> challenges -> area\n",
      "provide -> challenges -> area -> theory\n",
      "provide -> challenges -> area -> theory -> game\n",
      "continue -> e-sports\n",
      "continue -> e-sports -> starcraft\n",
      "continue -> benchmarks\n",
      "are -> competitions\n",
      "are -> competitions -> prizes\n",
      "are -> competitions -> challenge\n",
      "are -> competitions -> challenge -> imagenet\n",
      "are -> research\n",
      "are -> intelligence\n",
      "include -> areas\n",
      "include -> areas -> competition\n",
      "include -> intelligence\n",
      "include -> intelligence -> machine\n",
      "include -> intelligence -> behavior\n",
      "include -> intelligence -> cars\n",
      "include -> intelligence -> soccer\n",
      "include -> intelligence -> soccer -> robot\n",
      "include -> intelligence -> games\n",
      "considered -> game\n",
      "considered -> game -> imitation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "considered -> game -> interpretation\n",
      "considered -> game -> interpretation -> test\n",
      "considered -> game -> interpretation -> test -> turing\n",
      "considered -> game -> interpretation -> test -> computer\n",
      "considered -> benchmark\n",
      "test -> derivative\n",
      "test -> derivative -> test\n",
      "test -> derivative -> test -> turing\n",
      "test -> automated\n",
      "test -> turing\n",
      "test -> turing -> public\n",
      "test -> computers\n",
      "test -> computers -> humans\n",
      "test -> computers -> captcha\n",
      "helps -> name\n",
      "helps -> person\n",
      "helps -> person -> user\n",
      "helps -> person -> computer\n",
      "helps -> person -> computer -> human\n",
      "administered -> contrast\n",
      "administered -> contrast -> test\n",
      "administered -> contrast -> test -> turing\n",
      "administered -> captcha\n",
      "administered -> machine\n",
      "administered -> machine\n",
      "asks -> computer\n",
      "asks -> user\n",
      "asks -> test\n",
      "asks -> grade\n",
      "asks -> grade -> test\n",
      "unable -> computers\n",
      "unable -> problem\n",
      "unable -> solutions\n",
      "unable -> result\n",
      "unable -> result -> person\n",
      "unable -> result -> person -> test\n",
      "test -> type\n",
      "test -> type -> captcha\n",
      "test -> typing\n",
      "test -> typing -> letters\n",
      "test -> typing -> letters -> numbers\n",
      "test -> typing -> letters -> symbols\n",
      "test -> typing -> letters -> image\n",
      "test -> typing -> letters -> image -> computer\n",
      "aim -> tests\n",
      "aim -> tests -> intelligence\n",
      "aim -> machines\n",
      "aim -> machines -> humans\n",
      "aim -> machines -> animals\n",
      "aim -> sets\n",
      "aim -> sets -> problem\n",
      "contain -> suite\n",
      "contain -> suite -> test\n",
      "contain -> problem\n",
      "contain -> problem -> complexity\n",
      "contain -> problem -> complexity -> kolmogorov\n",
      "contain -> sets\n",
      "contain -> sets -> problem\n",
      "contain -> exercises\n",
      "contain -> exercises -> pattern\n",
      "contain -> exercises -> ai\n",
      "contain -> exercises -> levels\n",
      "contain -> exercises -> levels -> performance\n",
      "relevant -> task\n",
      "pervasive -> techniques\n",
      "pervasive -> techniques -> intelligence\n",
      "considered -> technique\n",
      "considered -> use\n",
      "considered -> intelligence\n",
      "considered -> phenomenon\n",
      "considered -> effect\n",
      "considered -> effect -> ai\n",
      "include -> examples\n",
      "include -> examples -> profile\n",
      "include -> examples -> ai\n",
      "include -> vehicles\n",
      "include -> vehicles -> drones\n",
      "include -> vehicles -> drones -> self-\n",
      "include -> vehicles -> drones -> cars\n",
      "include -> vehicles -> drones -> cars -> driving\n",
      "include -> vehicles -> diagnosis\n",
      "include -> vehicles -> assistants\n",
      "include -> vehicles -> assistants -> siri\n",
      "include -> vehicles -> recognition\n",
      "include -> vehicles -> recognition -> image\n",
      "include -> vehicles -> recognition -> photographs\n",
      "include -> vehicles -> recognition -> photographs -> filtering\n",
      "include -> vehicles -> recognition -> photographs -> filtering -> spam\n",
      "include -> vehicles -> recognition -> delays\n",
      "include -> vehicles -> recognition -> delays -> flight\n",
      "include -> vehicles -> recognition -> delays -> prediction\n",
      "include -> vehicles -> recognition -> delays -> prediction -> decisions\n",
      "include -> vehicles -> recognition -> advertisements\n",
      "include -> vehicles -> recognition -> advertisements -> storage\n",
      "include -> vehicles -> recognition -> advertisements -> storage -> energy\n",
      "include -> art\n",
      "include -> art -> poetry\n",
      "include -> theorems\n",
      "include -> games\n",
      "include -> games -> chess\n",
      "include -> games -> chess -> go\n",
      "include -> games -> chess -> engines\n",
      "include -> games -> chess -> engines -> search\n",
      "include -> games -> chess -> engines -> google\n",
      "include -> games -> chess -> engines -> google -> search\n",
      "use -> sites\n",
      "use -> sites -> media\n",
      "use -> sites -> tv\n",
      "use -> sites -> source\n",
      "use -> sites -> source -> news\n",
      "use -> sites -> source -> news -> people\n",
      "use -> sites -> source -> news -> people -> organizations\n",
      "use -> sites -> source -> news -> people -> organizations -> news\n",
      "use -> sites -> source -> news -> people -> platforms\n",
      "use -> sites -> source -> news -> people -> platforms -> media\n",
      "use -> sites -> source -> news -> people -> platforms -> distribution\n",
      "use -> publishers\n",
      "use -> technology\n",
      "use -> technology -> intelligence\n",
      "use -> technology -> ai\n",
      "use -> stories\n",
      "use -> volumes\n",
      "use -> volumes -> traffic\n",
      "produce -> deepfakes\n",
      "produce -> deepfakes -> technology\n",
      "reports -> zdnet\n",
      "reports -> something\n",
      "reports -> %\n",
      "reports -> % -> americans\n",
      "reports -> deepfakes\n",
      "reports -> harm\n",
      "reports -> %\n",
      "opens -> boom\n",
      "opens -> boom -> year\n",
      "opens -> boom -> year -> election\n",
      "opens -> discourse\n",
      "opens -> threats\n",
      "opens -> threats -> videos\n",
      "opens -> threats -> videos -> media\n",
      "opens -> threats -> videos -> media -> politician\n",
      "used -> healthcare\n",
      "used -> classification\n",
      "used -> evaluation\n",
      "used -> evaluation -> scan\n",
      "used -> evaluation -> scan -> ct\n",
      "used -> evaluation -> scan -> ekg\n",
      "used -> patients\n",
      "used -> patients -> risk\n",
      "used -> patients -> health\n",
      "used -> patients -> health -> population\n",
      "increasing -> breadth\n",
      "increasing -> breadth -> applications\n",
      "applied -> example\n",
      "applied -> problem\n",
      "applied -> problem -> issues\n",
      "applied -> problem -> issues -> dosage\n",
      "applied -> problem -> issues -> findings\n",
      "applied -> problem -> issues -> ai\n",
      "found -> study\n",
      "found -> study -> california\n",
      "found -> formula\n",
      "found -> help\n",
      "found -> help -> dose\n",
      "found -> help -> dose -> drugs\n",
      "found -> help -> patients\n",
      "found -> help -> patients -> organ\n",
      "assisting -> intelligence\n",
      "assisting -> doctors\n",
      "ai -> technology\n",
      "ai -> technology -> bloomberg\n",
      "ai -> microsoft\n",
      "ai -> doctors\n",
      "ai -> treatments\n",
      "ai -> treatments -> cancer\n",
      "is -> amount\n",
      "is -> amount -> research\n",
      "is -> amount -> research -> drugs\n",
      "is -> amount -> research -> cancer\n",
      "are -> detail\n",
      "are -> medicines\n",
      "are -> medicines -> vaccines\n",
      "are -> cancer\n",
      "affects -> doctors\n",
      "affects -> options\n",
      "affects -> drugs\n",
      "affects -> patients\n",
      "working -> microsoft\n",
      "working -> project\n",
      "working -> project -> machine\n",
      "working -> project -> machine -> hanover\n",
      "is -> goal\n",
      "is -> papers\n",
      "is -> papers -> cancer\n",
      "is -> combinations\n",
      "is -> combinations -> drugs\n",
      "is -> patient\n",
      "fighting -> project\n",
      "fighting -> project -> moment\n",
      "fighting -> leukemia\n",
      "fighting -> leukemia -> cancer\n",
      "fighting -> leukemia -> cancer -> treatment\n",
      "fighting -> leukemia -> cancer -> decades\n",
      "reported -> study\n",
      "reported -> intelligence\n",
      "reported -> doctors\n",
      "reported -> doctors -> cancers\n",
      "reported -> doctors -> cancers -> skin\n",
      "using -> study\n",
      "using -> intelligence\n",
      "using -> patients\n",
      "using -> patients -> risk\n",
      "using -> questions\n",
      "using -> questions -> data\n",
      "using -> questions -> data -> doctor\n",
      "using -> questions -> data -> interactions\n",
      "done -> study\n",
      "done -> learning\n",
      "done -> learning -> transfer\n",
      "done -> machine\n",
      "done -> diagnosis\n",
      "done -> ophthalmologist\n",
      "done -> decision\n",
      "done -> decision -> seconds\n",
      "done -> patient\n",
      "done -> treatment\n",
      "done -> accuracy\n",
      "done -> accuracy -> %\n",
      "demonstrated -> cnn\n",
      "demonstrated -> study\n",
      "demonstrated -> study -> surgeons\n",
      "demonstrated -> study -> center\n",
      "demonstrated -> study -> center -> children\n",
      "demonstrated -> study -> center -> national\n",
      "demonstrated -> study -> center -> medical\n",
      "demonstrated -> study -> center -> washington\n",
      "demonstrated -> surgery\n",
      "demonstrated -> robot\n",
      "supervised -> team\n",
      "supervised -> robot\n",
      "supervised -> surgery\n",
      "supervised -> bowel\n",
      "supervised -> bowel -> pig\n",
      "supervised -> surgery\n",
      "supervised -> surgeon\n",
      "supervised -> team\n",
      "created -> ibm\n",
      "created -> computer\n",
      "created -> computer -> intelligence\n",
      "created -> computer -> ibm\n",
      "created -> computer -> watson\n",
      "created -> computer -> intelligence\n",
      "created -> computer -> levels\n",
      "struggled -> watson\n",
      "struggled -> success\n",
      "struggled -> success -> adoption\n",
      "struggled -> healthcare\n",
      "contributed -> advancements\n",
      "contributed -> advancements -> ai\n",
      "contributed -> growth\n",
      "contributed -> growth -> industry\n",
      "contributed -> creation\n",
      "contributed -> creation -> evolution\n",
      "contributed -> creation -> vehicles\n",
      "contributed -> companies\n",
      "contributed -> companies -> ai\n",
      "contributed -> companies -> creation\n",
      "contributed -> companies -> creation -> cars\n",
      "include -> companies\n",
      "include -> tesla\n",
      "include -> tesla -> google\n",
      "include -> tesla -> apple\n",
      "contribute -> components\n",
      "contribute -> functioning\n",
      "contribute -> functioning -> cars\n",
      "incorporate -> vehicles\n",
      "incorporate -> systems\n",
      "incorporate -> systems -> braking\n",
      "incorporate -> systems -> braking -> changing\n",
      "incorporate -> systems -> braking -> changing -> lane\n",
      "incorporate -> systems -> braking -> prevention\n",
      "incorporate -> systems -> braking -> prevention -> collision\n",
      "incorporate -> systems -> braking -> navigation\n",
      "incorporate -> systems -> braking -> mapping\n",
      "integrated -> systems\n",
      "integrated -> systems -> computers\n",
      "integrated -> systems -> computers -> performance\n",
      "integrated -> vehicle\n",
      "made -> developments\n",
      "made -> developments -> automobiles\n",
      "made -> innovation\n",
      "made -> innovation -> trucks\n",
      "made -> innovation -> trucks -> self-\n",
      "made -> innovation -> trucks -> driving\n",
      "made -> phase\n",
      "made -> phase -> testing\n",
      "passed -> government\n",
      "passed -> government -> uk\n",
      "passed -> legislation\n",
      "passed -> testing\n",
      "passed -> testing -> platoons\n",
      "passed -> testing -> platoons -> truck\n",
      "fleet -> platoons\n",
      "fleet -> platoons -> driving\n",
      "fleet -> platoons -> driving -> self\n",
      "fleet -> platoons -> truck\n",
      "fleet -> trucks\n",
      "fleet -> trucks -> self-\n",
      "fleet -> trucks -> driving\n",
      "fleet -> lead\n",
      "fleet -> lead -> truck\n",
      "fleet -> lead -> truck -> driving\n",
      "fleet -> platoons\n",
      "fleet -> platoons -> truck\n",
      "testing -> daimler\n",
      "testing -> daimler -> corporation\n",
      "testing -> daimler -> corporation -> automobile\n",
      "testing -> inspiration\n",
      "testing -> inspiration -> freightliner\n",
      "testing -> inspiration -> truck\n",
      "testing -> inspiration -> truck -> highway\n",
      "mapping -> factor\n",
      "mapping -> factor -> ability\n",
      "mapping -> factor -> ability -> automobile\n",
      "mapping -> factor -> ability -> automobile -> function\n",
      "pre-programmed -> general\n",
      "pre-programmed -> vehicle\n",
      "pre-programmed -> map\n",
      "pre-programmed -> map -> area\n",
      "include -> map\n",
      "include -> data\n",
      "include -> data -> approximations\n",
      "include -> data -> approximations -> light\n",
      "include -> data -> approximations -> light -> street\n",
      "include -> heights\n",
      "include -> vehicle\n",
      "include -> vehicle -> order\n",
      "include -> vehicle -> surroundings\n",
      "working -> google\n",
      "working -> algorithm\n",
      "working -> algorithm -> purpose\n",
      "working -> algorithm -> purpose -> need\n",
      "working -> algorithm -> purpose -> need -> maps\n",
      "working -> device\n",
      "working -> device -> variety\n",
      "working -> device -> variety -> surroundings\n",
      "equipped -> cars\n",
      "equipped -> cars -> driving\n",
      "equipped -> cars -> driving -> self\n",
      "equipped -> wheels\n",
      "equipped -> wheels -> steering\n",
      "equipped -> wheels -> pedals\n",
      "equipped -> wheels -> pedals -> brake\n",
      "equipped -> research\n",
      "equipped -> research -> algorithm\n",
      "equipped -> research -> algorithm -> environment\n",
      "equipped -> research -> algorithm -> environment -> passengers\n",
      "equipped -> research -> algorithm -> environment -> passengers -> vehicle\n",
      "equipped -> research -> algorithm -> awareness\n",
      "equipped -> research -> algorithm -> awareness -> speed\n",
      "equipped -> research -> algorithm -> awareness -> speed -> conditions\n",
      "equipped -> research -> algorithm -> awareness -> speed -> conditions -> driving\n",
      "safety -> factor\n",
      "safety -> factor -> ability\n",
      "safety -> factor -> ability -> automobile\n",
      "safety -> passenger\n",
      "program -> automobile\n",
      "program -> engineers\n",
      "program -> situations\n",
      "program -> situations -> risk\n",
      "include -> situations\n",
      "include -> collision\n",
      "include -> collision -> head\n",
      "include -> collision -> pedestrians\n",
      "be -> goal\n",
      "be -> goal -> car\n",
      "be -> decision\n",
      "be -> decision -> pedestrians\n",
      "be -> decision -> passengers\n",
      "be -> decision -> car\n",
      "is -> possibility\n",
      "is -> possibility -> car\n",
      "is -> possibility -> decision\n",
      "is -> possibility -> decision -> someone\n",
      "is -> possibility -> decision -> danger\n",
      "need -> words\n",
      "need -> car\n",
      "need -> pedestrians\n",
      "need -> pedestrians -> passengers\n",
      "crucial -> programming\n",
      "crucial -> programming -> car\n",
      "crucial -> programming -> car -> situations\n",
      "crucial -> automobile\n",
      "used -> institutions\n",
      "used -> systems\n",
      "used -> systems -> network\n",
      "used -> charges\n",
      "used -> charges -> claims\n",
      "used -> norm\n",
      "used -> investigation\n",
      "traced -> use\n",
      "traced -> use -> ai\n",
      "traced -> use -> ai -> banking\n",
      "traced -> bank\n",
      "traced -> bank -> security\n",
      "traced -> bank -> pacific\n",
      "traced -> bank -> national\n",
      "traced -> bank -> prevention\n",
      "traced -> bank -> prevention -> us\n",
      "traced -> bank -> prevention -> set\n",
      "traced -> bank -> prevention -> fraud\n",
      "force -> task\n",
      "force -> use\n",
      "force -> use -> cards\n",
      "force -> use -> cards -> debit\n",
      "using -> programs\n",
      "using -> programs -> kasisto\n",
      "using -> programs -> kasisto -> moneystream\n",
      "using -> ai\n",
      "using -> services\n",
      "use -> banks\n",
      "use -> systems\n",
      "use -> systems -> intelligence\n",
      "use -> today\n",
      "use -> operations\n",
      "use -> book-keeping\n",
      "use -> stocks\n",
      "use -> properties\n",
      "react -> changes\n",
      "react -> business\n",
      "react -> place\n",
      "beat -> august\n",
      "beat -> robots\n",
      "beat -> humans\n",
      "beat -> competition\n",
      "beat -> competition -> trading\n",
      "reduced -> crimes\n",
      "reduced -> crimes -> fraud\n",
      "reduced -> patterns\n",
      "reduced -> patterns -> users\n",
      "reduced -> changes\n",
      "reduced -> changes -> anomalies\n",
      "used -> corporations\n",
      "predicted -> jack\n",
      "predicted -> jack -> ma\n",
      "predicted -> ceo\n",
      "predicted -> ceo -> ai\n",
      "predicted -> years\n",
      "changed -> use\n",
      "changed -> use -> machines\n",
      "changed -> use -> machines -> ai\n",
      "changed -> use -> machines -> market\n",
      "changed -> use -> machines -> market -> applications\n",
      "changed -> use -> machines -> market -> applications -> making\n",
      "changed -> use -> machines -> market -> applications -> making -> trading\n",
      "changed -> use -> machines -> market -> applications -> making -> trading -> decision\n",
      "changed -> theories\n",
      "changed -> example\n",
      "changed -> platforms\n",
      "changed -> platforms -> ai\n",
      "changed -> law\n",
      "changed -> law -> supply\n",
      "changed -> law -> supply -> demand\n",
      "changed -> demand\n",
      "changed -> demand -> curves\n",
      "changed -> demand -> curves -> supply\n",
      "changed -> demand -> pricing\n",
      "reduce -> machines\n",
      "reduce -> asymmetry\n",
      "reduce -> asymmetry -> information\n",
      "reduce -> asymmetry -> market\n",
      "reduce -> markets\n",
      "reduce -> volume\n",
      "reduce -> volume -> trades\n",
      "limits -> markets\n",
      "limits -> consequences\n",
      "limits -> consequences -> behavior\n",
      "limits -> consequences -> behavior -> markets\n",
      "limits -> markets\n",
      "include -> theories\n",
      "include -> theories -> ai\n",
      "include -> theories -> impact\n",
      "include -> choice\n",
      "include -> choice -> expectations\n",
      "include -> choice -> theory\n",
      "include -> choice -> theory -> game\n",
      "include -> choice -> point\n",
      "include -> choice -> point -> lewis\n",
      "include -> choice -> point -> turning\n",
      "include -> choice -> optimization\n",
      "include -> choice -> optimization -> portfolio\n",
      "include -> choice -> thinking\n",
      "include -> choice -> thinking -> counterfactual\n",
      "course -> august\n",
      "course -> aicpa\n",
      "course -> training\n",
      "course -> professionals\n",
      "course -> professionals -> accounting\n",
      "faces -> arena\n",
      "faces -> arena -> cybersecurity\n",
      "faces -> challenges\n",
      "faces -> challenges -> form\n",
      "faces -> challenges -> form -> attacks\n",
      "faces -> challenges -> form -> attacks -> hacking\n",
      "faces -> challenges -> form -> attacks -> types\n",
      "faces -> challenges -> form -> attacks -> types -> organizations\n",
      "faces -> challenges -> form -> attacks -> types -> organizations -> kinds\n",
      "faces -> challenges -> form -> attacks -> types -> billions\n",
      "faces -> challenges -> form -> attacks -> types -> billions -> dollars\n",
      "faces -> challenges -> form -> attacks -> types -> damage\n",
      "faces -> challenges -> form -> attacks -> types -> damage -> business\n",
      "begun -> intelligence\n",
      "begun -> intelligence -> processing\n",
      "begun -> intelligence -> processing -> language\n",
      "begun -> intelligence -> processing -> nlp\n",
      "begun -> companies\n",
      "begun -> companies -> security\n",
      "begun -> solutions\n",
      "begun -> solutions -> example\n",
      "begun -> solutions -> siem\n",
      "begun -> solutions -> siem -> information\n",
      "begun -> solutions -> siem -> information -> security\n",
      "begun -> solutions -> siem -> information -> management\n",
      "begun -> solutions -> siem -> information -> management -> event\n",
      "use -> solutions\n",
      "use -> ai\n",
      "use -> ai -> nlp\n",
      "use -> data\n",
      "use -> data -> networks\n",
      "use -> information\n",
      "use -> information -> risk\n",
      "enables -> teams\n",
      "enables -> teams -> security\n",
      "enables -> attacks\n",
      "enables -> attacks -> potential\n",
      "enables -> attacks -> potential -> harm\n",
      "enables -> attacks -> potential -> organization\n",
      "enables -> victims\n",
      "enables -> victims -> attacks\n",
      "enables -> victims -> attacks -> denial\n",
      "enables -> victims -> attacks -> denial -> service\n",
      "enables -> victims -> attacks -> denial -> dos\n",
      "enables -> victims -> attacks -> denial -> malware\n",
      "enables -> victims -> attacks -> denial -> malware -> others\n",
      "consists -> intelligence\n",
      "consists -> intelligence -> government\n",
      "consists -> applications\n",
      "consists -> applications -> regulation\n",
      "used -> intelligence\n",
      "used -> intelligence -> systems\n",
      "used -> intelligence -> systems -> recognition\n",
      "used -> surveillance\n",
      "case -> parts\n",
      "case -> parts -> china\n",
      "competed -> intelligence\n",
      "competed -> elections\n",
      "competed -> elections -> city\n",
      "competed -> elections -> city -> tama\n",
      "set -> city\n",
      "set -> city -> tech\n",
      "set -> city -> bengaluru\n",
      "set -> city -> bengaluru -> india\n",
      "set -> systems\n",
      "set -> systems -> signal\n",
      "set -> systems -> signal -> traffic\n",
      "set -> systems -> signals\n",
      "set -> systems -> signals -> traffic\n",
      "set -> systems -> signals -> city\n",
      "involve -> system\n",
      "involve -> use\n",
      "involve -> use -> cameras\n",
      "involve -> density\n",
      "involve -> density -> traffic\n",
      "involve -> time\n",
      "involve -> time -> volume\n",
      "involve -> time -> volume -> traffic\n",
      "involve -> time -> volume -> duration\n",
      "involve -> time -> volume -> duration -> signal\n",
      "involve -> time -> volume -> duration -> traffic\n",
      "involve -> time -> volume -> duration -> traffic -> vehicular\n",
      "involve -> time -> volume -> duration -> traffic -> streets\n",
      "becoming -> intelligence\n",
      "becoming -> intelligence -> ai\n",
      "becoming -> component\n",
      "becoming -> component -> professions\n",
      "using -> circumstances\n",
      "using -> technology\n",
      "using -> technology -> analytics\n",
      "using -> algorithms\n",
      "using -> algorithms -> learning\n",
      "using -> algorithms -> learning -> machine\n",
      "using -> work\n",
      "using -> work -> lawyers\n",
      "using -> work -> lawyers -> level\n",
      "using -> work -> lawyers -> level -> entry\n",
      "focused -> discovery\n",
      "focused -> discovery -> electronic\n",
      "focused -> discovery -> ediscovery\n",
      "focused -> industry\n",
      "focused -> learning\n",
      "focused -> learning -> machine\n",
      "focused -> learning -> review\n",
      "focused -> learning -> review -> coding\n",
      "focused -> learning -> review -> coding -> technology\n",
      "focused -> learning -> subset\n",
      "focused -> learning -> subset -> ai\n",
      "vogue -> soup\n",
      "vogue -> soup -> applications\n",
      "vogue -> processing\n",
      "vogue -> processing -> language\n",
      "vogue -> processing -> nlp\n",
      "vogue -> processing -> recognition\n",
      "vogue -> processing -> recognition -> speech\n",
      "vogue -> processing -> recognition -> asr\n",
      "vogue -> industry\n",
      "used -> games\n",
      "used -> games -> video\n",
      "used -> intelligence\n",
      "used -> behavior\n",
      "used -> behavior -> characters\n",
      "used -> behavior -> characters -> npcs\n",
      "used -> addition\n",
      "used -> techniques\n",
      "used -> techniques -> ai\n",
      "used -> pathfinding\n",
      "consider -> researchers\n",
      "consider -> games\n",
      "consider -> games -> npc\n",
      "consider -> games -> problem\n",
      "consider -> games -> problem -> tasks\n",
      "consider -> games -> problem -> tasks -> production\n",
      "include -> games\n",
      "include -> games -> ai\n",
      "include -> director\n",
      "include -> director -> ai\n",
      "include -> director -> dead\n",
      "include -> director -> training\n",
      "include -> director -> training -> platoons\n",
      "include -> director -> training -> platoons -> commander\n",
      "include -> director -> training -> platoons -> commander -> supreme\n",
      "developing -> states\n",
      "developing -> states -> united\n",
      "developing -> states -> nations\n",
      "developing -> applications\n",
      "developing -> applications -> range\n",
      "developing -> applications -> range -> functions\n",
      "enhance -> applications\n",
      "enhance -> applications -> intelligence\n",
      "enhance -> applications -> intelligence -> artificial\n",
      "enhance -> applications -> intelligence -> learning\n",
      "enhance -> applications -> intelligence -> learning -> machine\n",
      "enhance -> c2\n",
      "enhance -> c2 -> communications\n",
      "enhance -> c2 -> sensors\n",
      "enhance -> c2 -> integration\n",
      "enhance -> c2 -> interoperability\n",
      "underway -> research\n",
      "underway -> research -> ai\n",
      "underway -> fields\n",
      "underway -> fields -> collection\n",
      "underway -> fields -> collection -> intelligence\n",
      "underway -> fields -> collection -> analysis\n",
      "underway -> fields -> collection -> logistics\n",
      "underway -> fields -> collection -> operations\n",
      "underway -> fields -> collection -> operations -> cyber\n",
      "underway -> fields -> collection -> operations\n",
      "underway -> fields -> collection -> operations -> information\n",
      "underway -> fields -> collection -> command\n",
      "underway -> fields -> collection -> control\n",
      "underway -> fields -> variety\n",
      "underway -> fields -> variety -> vehicles\n",
      "enable -> technologies\n",
      "enable -> technologies -> intelligence\n",
      "enable -> coordination\n",
      "enable -> coordination -> sensors\n",
      "enable -> coordination -> sensors -> effectors\n",
      "enable -> coordination -> sensors -> detection\n",
      "enable -> coordination -> sensors -> detection -> threat\n",
      "enable -> coordination -> sensors -> identification\n",
      "enable -> coordination -> sensors -> marking\n",
      "enable -> coordination -> sensors -> marking -> positions\n",
      "enable -> coordination -> sensors -> marking -> positions -> enemy\n",
      "enable -> coordination -> sensors -> acquisition\n",
      "enable -> coordination -> sensors -> acquisition -> target\n",
      "enable -> coordination -> sensors -> coordination\n",
      "enable -> coordination -> sensors -> deconfliction\n",
      "enable -> coordination -> sensors -> deconfliction -> fires\n",
      "enable -> coordination -> sensors -> deconfliction -> fires -> join\n",
      "enable -> coordination -> sensors -> deconfliction -> fires -> vehicles\n",
      "enable -> coordination -> sensors -> deconfliction -> fires -> vehicles -> combat\n",
      "enable -> coordination -> sensors -> deconfliction -> fires -> vehicles -> tanks\n",
      "enable -> coordination -> sensors -> deconfliction -> fires -> vehicles -> teams\n",
      "enable -> coordination -> sensors -> deconfliction -> fires -> vehicles -> teams -> unmanned\n",
      "enable -> coordination -> sensors -> deconfliction -> fires -> vehicles -> teams -> mum\n",
      "enable -> coordination -> sensors -> deconfliction -> fires -> vehicles -> teams -> mum -> t\n",
      "incorporated -> operations\n",
      "incorporated -> operations -> iraq\n",
      "incorporated -> operations -> iraq -> syria\n",
      "rose -> spending\n",
      "rose -> spending -> robotics\n",
      "rose -> us\n",
      "rose -> us\n",
      "considered -> drones\n",
      "considered -> drones -> action\n",
      "considered -> asset\n",
      "seek -> researchers\n",
      "seek -> researchers -> intelligence\n",
      "seek -> applications\n",
      "seek -> applications -> ai\n",
      "used -> industry\n",
      "used -> industry -> hospitality\n",
      "used -> solutions\n",
      "used -> solutions -> intelligence\n",
      "used -> load\n",
      "used -> load -> staff\n",
      "used -> efficiency\n",
      "used -> frequency\n",
      "used -> frequency -> tasks\n",
      "used -> frequency -> analysis\n",
      "used -> frequency -> analysis -> trends\n",
      "used -> frequency -> interaction\n",
      "used -> frequency -> interaction -> guest\n",
      "used -> frequency -> prediction\n",
      "used -> frequency -> prediction -> needs\n",
      "used -> frequency -> prediction -> needs -> customer\n",
      "represented -> services\n",
      "represented -> services -> hotel\n",
      "represented -> services -> intelligence\n",
      "represented -> services -> intelligence -> artificial\n",
      "represented -> form\n",
      "represented -> form -> chatbot\n",
      "represented -> form -> chatbot -> application\n",
      "represented -> form -> chatbot -> assistant\n",
      "represented -> form -> chatbot -> assistant -> voice\n",
      "represented -> form -> chatbot -> robots\n",
      "represented -> form -> chatbot -> robots -> service\n",
      "makes -> audit\n",
      "makes -> audit -> statements\n",
      "makes -> audit\n",
      "ai -> tools\n",
      "ai -> sets\n",
      "ai -> sets -> information\n",
      "reduced -> benefit\n",
      "reduced -> risk\n",
      "reduced -> risk -> audit\n",
      "reduced -> level\n",
      "reduced -> level -> assurance\n",
      "reduced -> duration\n",
      "reduced -> duration -> time\n",
      "reduced -> duration -> audit\n",
      "possible -> ai\n",
      "possible -> ai -> behavior\n",
      "possible -> ai -> behavior -> customers\n",
      "possible -> ai -> behavior -> footprints\n",
      "possible -> ai -> order\n",
      "possible -> ai -> promotions\n",
      "possible -> ai -> personas\n",
      "possible -> ai -> personas -> customer\n",
      "reports -> case\n",
      "reports -> companies\n",
      "reports -> companies -> gambling\n",
      "reports -> ai\n",
      "reports -> targeting\n",
      "reports -> targeting -> customer\n",
      "help -> application\n",
      "help -> application -> computing\n",
      "help -> application -> computing -> personality\n",
      "help -> models\n",
      "help -> cost\n",
      "help -> cost -> campaigns\n",
      "help -> cost -> campaigns -> advertising\n",
      "help -> targeting\n",
      "help -> targeting\n",
      "inspired -> intelligence\n",
      "inspired -> intelligence -> artificial\n",
      "inspired -> applications\n",
      "inspired -> applications -> usage\n",
      "inspired -> applications -> usage -> art\n",
      "provides -> exhibition\n",
      "provides -> exhibition -> thinking\n",
      "provides -> exhibition -> thinking -> machines\n",
      "provides -> exhibition -> thinking -> art\n",
      "provides -> exhibition -> thinking -> art -> design\n",
      "provides -> exhibition -> thinking -> art -> age\n",
      "provides -> exhibition -> thinking -> art -> age -> computer\n",
      "provides -> moma\n",
      "provides -> overview\n",
      "provides -> overview -> applications\n",
      "provides -> overview -> applications -> ai\n",
      "provides -> overview -> applications -> art\n",
      "provides -> overview -> applications -> art -> architecture\n",
      "provides -> overview -> applications -> art -> design\n",
      "include -> exhibitions\n",
      "include -> exhibitions -> usage\n",
      "include -> exhibitions -> usage -> ai\n",
      "include -> exhibitions -> usage -> ai -> art\n",
      "include -> benefit\n",
      "include -> benefit -> auction\n",
      "include -> benefit -> foundation\n",
      "include -> benefit -> foundation -> area\n",
      "include -> benefit -> foundation -> area -> gray\n",
      "include -> benefit -> foundation -> san\n",
      "include -> benefit -> foundation -> san -> francisco\n",
      "include -> benefit -> foundation -> artists\n",
      "include -> benefit -> foundation -> algorithm\n",
      "include -> benefit -> foundation -> algorithm -> deepdream\n",
      "include -> benefit -> foundation -> algorithm -> exhibition\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> unhuman\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> unhuman -> art\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> unhuman -> art -> age\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> unhuman -> art -> age -> ai\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> place\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> angeles\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> angeles -> los\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> angeles -> frankfurt\n",
      "include -> benefit -> foundation -> algorithm -> exhibition -> fall\n",
      "dedicated -> spring\n",
      "dedicated -> association\n",
      "dedicated -> association -> machinery\n",
      "dedicated -> association -> machinery -> computing\n",
      "dedicated -> issue\n",
      "dedicated -> issue -> magazine\n",
      "dedicated -> subject\n",
      "dedicated -> subject -> computers\n",
      "dedicated -> subject -> computers -> art\n",
      "dedicated -> role\n",
      "dedicated -> role -> machine\n",
      "dedicated -> role -> arts\n",
      "opened -> electronica\n",
      "opened -> electronica -> ars\n",
      "opened -> electronica -> museum\n",
      "opened -> electronica -> arts\n",
      "opened -> electronica -> arts -> applied\n",
      "opened -> electronica -> arts -> vienna\n",
      "opened -> exhibitions\n",
      "opened -> ai\n",
      "thematized -> festival\n",
      "thematized -> festival -> electronica\n",
      "thematized -> festival -> electronica -> ars\n",
      "thematized -> festival -> box\n",
      "thematized -> role\n",
      "thematized -> role -> arts\n",
      "thematized -> transformation\n",
      "thematized -> transformation -> ai\n",
      "are -> questions\n",
      "are -> questions -> ai\n",
      "intelligent -> machine\n",
      "have -> use\n",
      "have -> use -> intelligence\n",
      "have -> consequences\n",
      "described -> scientists\n",
      "described -> scientists -> future\n",
      "described -> scientists -> future -> life\n",
      "described -> scientists -> institute\n",
      "described -> others\n",
      "described -> goals\n",
      "described -> goals -> term\n",
      "described -> goals -> research\n",
      "described -> economy\n",
      "described -> economy -> laws\n",
      "described -> economy -> laws -> ethics\n",
      "described -> economy -> ai\n",
      "described -> economy -> risks\n",
      "described -> economy -> risks -> security\n",
      "proposed -> long-term\n",
      "proposed -> scientists\n",
      "proposed -> function\n",
      "proposed -> risks\n",
      "proposed -> risks -> security\n",
      "proposed -> risks -> technologies\n",
      "issue -> effects\n",
      "issue -> effects -> ai\n",
      "issue -> effects -> ai -> automation\n",
      "issue -> campaign\n",
      "issue -> campaign -> andrew\n",
      "issue -> campaign -> andrew -> yang\n",
      "issue -> campaign -> states\n",
      "issue -> campaign -> states -> united\n",
      "expressed -> irakli\n",
      "expressed -> irakli -> beridze\n",
      "expressed -> irakli -> head\n",
      "expressed -> irakli -> head -> centre\n",
      "expressed -> irakli -> head -> centre -> intelligence\n",
      "expressed -> irakli -> head -> centre -> intelligence -> artificial\n",
      "expressed -> irakli -> head -> centre -> intelligence -> robotics\n",
      "expressed -> irakli -> head -> centre -> intelligence -> unicri\n",
      "expressed -> irakli -> head -> centre -> intelligence -> unicri -> nations\n",
      "expressed -> irakli -> head -> centre -> intelligence -> unicri -> nations -> united\n",
      "expressed -> criminals\n",
      "expressed -> criminals -> applications\n",
      "expressed -> criminals -> applications -> ai\n",
      "expressed -> criminals -> point\n",
      "expressed -> criminals -> point -> view\n",
      "expressed -> criminals -> organizations\n",
      "expressed -> criminals -> processes\n",
      "expressed -> criminals -> harm\n",
      "cause -> terrorists\n",
      "cause -> harm\n",
      "cause -> warfare\n",
      "cause -> combination\n",
      "cause -> combination -> robotics\n",
      "cause -> combination -> robotics -> drones\n",
      "cause -> combination -> robotics -> ai\n",
      "cause -> combination -> robotics -> ai -> things\n",
      "come -> course\n",
      "come -> risks\n",
      "come -> things\n",
      "come -> things -> losses\n",
      "come -> things -> losses -> job\n",
      "dangerous -> numbers\n",
      "dangerous -> numbers -> people\n",
      "dangerous -> numbers -> people -> jobs\n",
      "dangerous -> solution\n",
      "governed -> things\n",
      "governed -> things -> systems\n",
      "governed -> things -> systems -> weapons\n",
      "governed -> potential\n",
      "governed -> potential -> misuse\n",
      "expressed -> physicist\n",
      "expressed -> physicist -> stephen\n",
      "expressed -> physicist -> hawking\n",
      "expressed -> physicist -> founder\n",
      "expressed -> physicist -> founder -> microsoft\n",
      "expressed -> physicist -> bill\n",
      "expressed -> physicist -> bill -> gates\n",
      "expressed -> physicist -> founder\n",
      "expressed -> physicist -> founder -> spacex\n",
      "expressed -> physicist -> founder -> elon\n",
      "expressed -> physicist -> founder -> elon -> musk\n",
      "expressed -> concerns\n",
      "expressed -> concerns -> possibility\n",
      "expressed -> concerns -> possibility -> point\n",
      "expressed -> concerns -> possibility -> point -> humans\n",
      "expressed -> theorizing\n",
      "expressed -> theorizing -> hawking\n",
      "expressed -> theorizing -> end\n",
      "expressed -> theorizing -> end -> race\n",
      "provides -> book\n",
      "provides -> philosopher\n",
      "provides -> philosopher -> nick\n",
      "provides -> philosopher -> nick -> bostrom\n",
      "provides -> argument\n",
      "provides -> argument -> intelligence\n",
      "provides -> argument -> threat\n",
      "provides -> argument -> threat -> humankind\n",
      "argues -> actions\n",
      "argues -> actions -> goal\n",
      "argues -> behavior\n",
      "argues -> behavior -> resources\n",
      "harm -> goals\n",
      "harm -> goals -> ai\n",
      "harm -> humanity\n",
      "harm -> ai\n",
      "harm -> ai -> example\n",
      "harm -> ai -> digits\n",
      "harm -> ai -> digits -> pi\n",
      "harm -> humanity\n",
      "harm -> order\n",
      "harm -> resources\n",
      "harm -> goal\n",
      "emphasizes -> bostrom\n",
      "emphasizes -> difficulty\n",
      "emphasizes -> difficulty -> values\n",
      "emphasizes -> difficulty -> values -> humanity\n",
      "emphasizes -> difficulty -> ai\n",
      "uses -> example\n",
      "uses -> example -> ai\n",
      "uses -> example -> goal\n",
      "uses -> example -> goal -> humans\n",
      "uses -> example -> goal -> smile\n",
      "uses -> example -> goal -> attempt\n",
      "argues -> ai\n",
      "argues -> ai -> scenario\n",
      "argues -> superintelligent\n",
      "argues -> bostrom\n",
      "argues -> methods\n",
      "argues -> methods -> humans\n",
      "argues -> methods -> electrodes\n",
      "argues -> methods -> muscles\n",
      "argues -> methods -> muscles -> humans\n",
      "argues -> methods -> grins\n",
      "argues -> methods -> way\n",
      "argues -> methods -> way -> goal\n",
      "argues -> methods -> way -> goal -> humans\n",
      "argues -> methods -> way -> goal -> smile\n",
      "echoes -> book\n",
      "echoes -> book -> compatible\n",
      "echoes -> book -> compatible -> human\n",
      "echoes -> researcher\n",
      "echoes -> researcher -> stuart\n",
      "echoes -> researcher -> stuart -> j.\n",
      "echoes -> researcher -> stuart -> russell\n",
      "echoes -> concerns\n",
      "echoes -> concerns -> bostrom\n",
      "echoes -> approach\n",
      "echoes -> approach -> machines\n",
      "echoes -> approach -> machines -> uncertainty\n",
      "echoes -> approach -> machines -> uncertainty -> deference\n",
      "echoes -> approach -> machines -> humans\n",
      "echoes -> approach -> machines -> learning\n",
      "echoes -> approach -> machines -> learning -> reinforcement\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "led -> concern\n",
      "led -> concern -> risk\n",
      "led -> concern -> risk -> intelligence\n",
      "led -> donations\n",
      "led -> donations -> profile\n",
      "led -> donations -> investments\n",
      "committed -> group\n",
      "committed -> group -> titans\n",
      "committed -> group -> titans -> tech\n",
      "committed -> group -> titans -> peter\n",
      "committed -> group -> titans -> peter -> thiel\n",
      "committed -> group -> titans -> peter -> services\n",
      "committed -> group -> titans -> peter -> services -> amazon\n",
      "committed -> group -> titans -> peter -> services -> web\n",
      "committed -> group -> titans -> peter -> musk\n",
      "committed -> openai\n",
      "committed -> openai -> company\n",
      "committed -> openai -> company -> nonprofit\n",
      "committed -> openai -> company -> development\n",
      "committed -> openai -> company -> development -> ai\n",
      "mixed -> opinion\n",
      "mixed -> opinion -> experts\n",
      "mixed -> opinion -> experts -> field\n",
      "mixed -> opinion -> experts -> field -> intelligence\n",
      "mixed -> fractions\n",
      "mixed -> fractions -> risk\n",
      "mixed -> fractions -> risk -> ai\n",
      "believe -> leaders\n",
      "believe -> leaders -> industry\n",
      "believe -> leaders -> industry -> technology\n",
      "believe -> intelligence\n",
      "believe -> form\n",
      "believe -> humans\n",
      "stated -> oracle\n",
      "stated -> oracle -> ceo\n",
      "stated -> oracle -> mark\n",
      "stated -> oracle -> mark -> hurd\n",
      "stated -> jobs\n",
      "stated -> jobs -> jobs\n",
      "stated -> humans\n",
      "stated -> systems\n",
      "stated -> systems -> ai\n",
      "believes -> ceo\n",
      "believes -> ceo -> facebook\n",
      "believes -> mark\n",
      "believes -> mark -> zuckerberg\n",
      "believes -> amount\n",
      "believes -> amount -> things\n",
      "believes -> amount -> things -> disease\n",
      "believes -> amount -> things -> disease -> curing\n",
      "believes -> safety\n",
      "believes -> safety -> cars\n",
      "donated -> january\n",
      "donated -> musk\n",
      "donated -> institute\n",
      "donated -> institute -> future\n",
      "donated -> institute -> future -> life\n",
      "donated -> research\n",
      "donated -> research -> understanding\n",
      "donated -> research -> understanding -> decision\n",
      "grow -> goal\n",
      "grow -> goal -> institute\n",
      "grow -> wisdom\n",
      "grow -> wisdom -> power\n",
      "grow -> wisdom -> power -> technology\n",
      "funds -> musk\n",
      "funds -> companies\n",
      "funds -> companies -> intelligence\n",
      "funds -> companies -> intelligence -> deepmind\n",
      "funds -> companies -> intelligence -> deepmind -> vicarious\n",
      "funds -> companies -> eye\n",
      "funds -> companies -> intelligence\n",
      "think -> outcome\n",
      "have -> danger\n",
      "have -> ai\n",
      "have -> humanity\n",
      "have -> humanity -> minority\n",
      "have -> humanity -> minority -> experts\n",
      "have -> humanity -> possibility\n",
      "have -> humanity -> possibility -> future\n",
      "revolve -> counterarguments\n",
      "revolve -> humans\n",
      "revolve -> perspective\n",
      "revolve -> perspective -> intelligence\n",
      "wrote -> joseph\n",
      "wrote -> joseph -> weizenbaum\n",
      "wrote -> applications\n",
      "wrote -> definition\n",
      "wrote -> empathy\n",
      "wrote -> use\n",
      "wrote -> use -> technology\n",
      "wrote -> use -> technology -> ai\n",
      "wrote -> use -> fields\n",
      "wrote -> use -> fields -> service\n",
      "wrote -> use -> fields -> service -> customer\n",
      "wrote -> use -> fields -> service -> psychotherapy\n",
      "bothered -> weizenbaum\n",
      "bothered -> researchers\n",
      "bothered -> researchers -> philosophers\n",
      "bothered -> mind\n",
      "bothered -> nothing\n",
      "bothered -> nothing -> program\n",
      "bothered -> nothing -> program -> computer\n",
      "bothered -> nothing -> program -> position\n",
      "bothered -> nothing -> program -> position -> computationalism\n",
      "suggest -> weizenbaum\n",
      "suggest -> points\n",
      "suggest -> research\n",
      "suggest -> research -> ai\n",
      "suggest -> life\n",
      "is -> concern\n",
      "is -> programs\n",
      "is -> groups\n",
      "is -> groups -> women\n",
      "is -> groups -> women -> minorities\n",
      "is -> men\n",
      "is -> men -> developers\n",
      "higher -> support\n",
      "higher -> support -> intelligence\n",
      "higher -> men\n",
      "higher -> men -> %\n",
      "higher -> women\n",
      "higher -> women -> approving\n",
      "higher -> women -> approving -> %\n",
      "have -> algorithms\n",
      "have -> host\n",
      "have -> host -> applications\n",
      "have -> host -> applications -> system\n",
      "have -> host -> applications -> system -> today\n",
      "have -> officials\n",
      "have -> officials -> judges\n",
      "have -> officials -> judges -> officers\n",
      "have -> officials -> judges -> officers -> defenders\n",
      "have -> officials -> likelihood\n",
      "have -> officials -> likelihood -> recidivism\n",
      "have -> officials -> likelihood -> recidivism -> defendants\n",
      "counts -> compas\n",
      "counts -> compas -> acronym\n",
      "counts -> compas -> acronym -> profiling\n",
      "counts -> compas -> acronym -> profiling -> management\n",
      "counts -> compas -> acronym -> profiling -> management -> offender\n",
      "counts -> compas -> acronym -> profiling -> sanctions\n",
      "counts -> solutions\n",
      "suggested -> compas\n",
      "suggested -> risk\n",
      "suggested -> risk -> recidivism\n",
      "suggested -> defendants\n",
      "suggested -> estimate\n",
      "suggested -> estimate -> risk\n",
      "suggested -> estimate -> defendants\n",
      "complicated -> relationship\n",
      "complicated -> relationship -> automation\n",
      "complicated -> relationship -> automation -> employment\n",
      "creates -> automation\n",
      "creates -> jobs\n",
      "creates -> jobs\n",
      "creates -> effects\n",
      "eliminated -> waves\n",
      "eliminated -> waves -> automation\n",
      "eliminated -> jobs\n",
      "eliminated -> jobs -> class\n",
      "eliminated -> intelligence\n",
      "eliminated -> economist\n",
      "eliminated -> worry\n",
      "eliminated -> worry -> jobs\n",
      "eliminated -> worry -> jobs -> collar\n",
      "eliminated -> worry -> jobs -> steam\n",
      "eliminated -> worry -> jobs -> power\n",
      "eliminated -> worry -> jobs -> ones\n",
      "eliminated -> worry -> jobs -> ones -> revolution\n",
      "eliminated -> worry -> jobs -> ones -> revolution -> industrial\n",
      "vary -> estimates\n",
      "vary -> estimates -> risk\n",
      "vary -> example\n",
      "vary -> michael\n",
      "vary -> michael -> osborne\n",
      "vary -> michael -> carl\n",
      "vary -> michael -> carl -> benedikt\n",
      "vary -> michael -> carl -> frey\n",
      "vary -> %\n",
      "vary -> % -> jobs\n",
      "vary -> % -> jobs -> u.s.\n",
      "vary -> risk\n",
      "vary -> risk -> automation\n",
      "vary -> report\n",
      "vary -> report -> oecd\n",
      "vary -> %\n",
      "vary -> % -> jobs\n",
      "vary -> % -> jobs -> u.s.\n",
      "vary -> risk\n",
      "jobs -> range\n",
      "jobs -> range -> risk\n",
      "jobs -> range -> paralegals\n",
      "jobs -> range -> paralegals -> cooks\n",
      "jobs -> range -> paralegals -> cooks -> food\n",
      "jobs -> demand\n",
      "jobs -> demand -> job\n",
      "jobs -> professions\n",
      "jobs -> professions -> healthcare\n",
      "jobs -> professions -> clergy\n",
      "go -> author\n",
      "go -> author -> martin\n",
      "go -> author -> ford\n",
      "go -> author -> others\n",
      "go -> routine\n",
      "go -> routine -> jobs\n",
      "go -> routine -> ai\n",
      "warns -> ford\n",
      "warns -> jobs\n",
      "warns -> couple\n",
      "warns -> couple -> decades\n",
      "warns -> jobs\n",
      "warns -> people\n",
      "warns -> people -> capability\n",
      "warns -> retraining\n",
      "point -> economists\n",
      "point -> technology\n",
      "point -> employment\n",
      "point -> territory\n",
      "point -> territory -> ai\n",
      "researching -> countries\n",
      "researching -> robots\n",
      "researching -> robots -> battlefield\n",
      "researching -> robots -> states\n",
      "researching -> robots -> states -> united\n",
      "researching -> robots -> states -> china\n",
      "researching -> robots -> states -> russia\n",
      "researching -> robots -> states -> kingdom\n",
      "researching -> robots -> states -> kingdom -> united\n",
      "want -> people\n",
      "want -> people -> risk\n",
      "want -> people -> risk -> superintelligent\n",
      "want -> use\n",
      "want -> use -> soldiers\n",
      "want -> use -> soldiers -> drones\n",
      "have -> machines\n",
      "have -> machines -> intelligence\n",
      "have -> potential\n",
      "have -> potential -> intelligence\n",
      "have -> potential -> harm\n",
      "have -> potential -> risks\n",
      "have -> ability\n",
      "have -> ability -> reasoning\n",
      "have -> ability -> actions\n",
      "have -> ability -> world\n",
      "is -> need\n",
      "is -> need -> policy\n",
      "is -> need -> policy -> policies\n",
      "is -> need -> policy -> intelligence\n",
      "is -> need -> policy -> intelligence -> robotics\n",
      "includes -> research\n",
      "includes -> research -> area\n",
      "includes -> ethics\n",
      "includes -> ethics -> machine\n",
      "includes -> ethics -> agents\n",
      "includes -> ethics -> ai\n",
      "includes -> ethics -> discussion\n",
      "includes -> ethics -> discussion -> framework\n",
      "includes -> ethics -> discussion -> framework -> rights\n",
      "includes -> talks\n",
      "introduced -> wendell\n",
      "introduced -> wendell -> wallach\n",
      "introduced -> concept\n",
      "introduced -> concept -> agents\n",
      "introduced -> concept -> agents -> ama\n",
      "introduced -> book\n",
      "introduced -> book -> machines\n",
      "introduced -> book -> machines -> moral\n",
      "introduced -> book -> wallach\n",
      "introduced -> amas\n",
      "introduced -> part\n",
      "introduced -> part -> landscape\n",
      "introduced -> part -> landscape -> research\n",
      "introduced -> part -> landscape -> intelligence\n",
      "introduced -> part -> questions\n",
      "introduced -> part -> questions -> humanity\n",
      "introduced -> part -> questions -> computers\n",
      "introduced -> part -> questions -> decisions\n",
      "introduced -> part -> questions -> decisions -> moral\n",
      "introduced -> part -> questions -> bots\n",
      "introduced -> part -> questions -> bots -> ro\n",
      "centered -> wallach\n",
      "centered -> question\n",
      "centered -> issue\n",
      "centered -> issue -> machines\n",
      "centered -> issue -> equivalent\n",
      "centered -> issue -> equivalent -> behavior\n",
      "centered -> issue -> contrast\n",
      "centered -> issue -> contrast -> constraints\n",
      "centered -> issue -> contrast -> constraints -> society\n",
      "centered -> issue -> contrast -> constraints -> development\n",
      "centered -> issue -> contrast -> constraints -> development -> amas\n",
      "concerned -> field\n",
      "concerned -> field -> ethics\n",
      "concerned -> field -> ethics -> machine\n",
      "concerned -> machines\n",
      "concerned -> principles\n",
      "concerned -> principles -> procedure\n",
      "concerned -> principles -> procedure -> way\n",
      "concerned -> principles -> procedure -> way -> dilemmas\n",
      "concerned -> manner\n",
      "concerned -> manner -> decision\n",
      "delineated -> field\n",
      "delineated -> symposium\n",
      "delineated -> symposium -> aaai\n",
      "delineated -> symposium -> fall\n",
      "delineated -> symposium -> ethics\n",
      "delineated -> symposium -> ethics -> machine\n",
      "delineated -> research\n",
      "delineated -> research -> relationship\n",
      "delineated -> research -> relationship -> technology\n",
      "delineated -> research -> relationship -> technology -> ethics\n",
      "delineated -> use\n",
      "delineated -> use -> technology\n",
      "delineated -> use -> beings\n",
      "delineated -> use -> people\n",
      "delineated -> use -> people -> beings\n",
      "delineated -> use -> people -> machines\n",
      "engaged -> cases\n",
      "engaged -> beings\n",
      "engaged -> reasoning\n",
      "come -> time\n",
      "come -> dimension\n",
      "come -> machines\n",
      "necessitate -> recognition\n",
      "necessitate -> recognition -> ramifications\n",
      "necessitate -> recognition -> ramifications -> behavior\n",
      "necessitate -> recognition -> ramifications -> behavior -> machines\n",
      "necessitate -> recognition -> ramifications -> developments\n",
      "necessitate -> recognition -> ramifications -> developments -> autonomy\n",
      "necessitate -> recognition -> ramifications -> developments -> autonomy -> machine\n",
      "concerned -> contrast\n",
      "concerned -> contrast -> hacking\n",
      "concerned -> contrast -> hacking -> computer\n",
      "concerned -> contrast -> hacking -> issues\n",
      "concerned -> contrast -> hacking -> issues -> software\n",
      "concerned -> contrast -> hacking -> issues -> property\n",
      "concerned -> contrast -> hacking -> issues\n",
      "concerned -> contrast -> hacking -> issues -> privacy\n",
      "concerned -> contrast -> hacking -> topics\n",
      "concerned -> contrast -> hacking -> topics -> ethics\n",
      "concerned -> contrast -> hacking -> topics -> ethics -> computer\n",
      "concerned -> ethics\n",
      "concerned -> ethics -> machine\n",
      "concerned -> behavior\n",
      "concerned -> behavior -> machines\n",
      "concerned -> behavior -> machines -> users\n",
      "concerned -> behavior -> machines -> users -> machines\n",
      "key -> research\n",
      "key -> research -> ethics\n",
      "key -> research -> ethics -> machine\n",
      "key -> concerns\n",
      "key -> concerns -> systems\n",
      "key -> root\n",
      "key -> root -> notion\n",
      "key -> root -> notion -> machines\n",
      "key -> root -> notion -> machines -> dimension\n",
      "key -> root -> fear\n",
      "key -> root -> fear -> intelligence\n",
      "key -> root -> fear -> intelligence -> machine\n",
      "enable -> investigation\n",
      "enable -> investigation -> ethics\n",
      "enable -> investigation -> ethics -> machine\n",
      "enable -> discovery\n",
      "enable -> discovery -> problems\n",
      "enable -> discovery -> problems -> theories\n",
      "enable -> thinking\n",
      "enable -> thinking -> ethics\n",
      "referred -> ethics\n",
      "referred -> ethics -> machine\n",
      "referred -> morality\n",
      "referred -> morality -> machine\n",
      "referred -> morality -> ethics\n",
      "referred -> morality -> morality\n",
      "found -> variety\n",
      "found -> variety -> perspectives\n",
      "found -> variety -> perspectives -> field\n",
      "found -> edition\n",
      "found -> edition -> ethics\n",
      "found -> edition -> ethics -> machine\n",
      "found -> edition -> symposium\n",
      "found -> edition -> symposium -> aaai\n",
      "found -> edition -> symposium -> fall\n",
      "found -> edition -> symposium -> ethics\n",
      "found -> edition -> symposium -> ethics -> machine\n",
      "believes -> scientist\n",
      "believes -> scientist -> charles\n",
      "believes -> scientist -> charles -> t.\n",
      "believes -> scientist -> charles -> rubin\n",
      "argues -> benevolence\n",
      "argues -> malevolence\n",
      "assume -> humans\n",
      "assume -> machines\n",
      "assume -> machines -> robots\n",
      "assume -> reason\n",
      "assume -> reason -> system\n",
      "assume -> reason -> system -> morality\n",
      "assume -> reason -> system -> biology\n",
      "assume -> reason -> system -> biology -> ais\n",
      "decide -> software\n",
      "decide -> existence\n",
      "decide -> existence -> humanity\n",
      "begun -> topic\n",
      "begun -> publications\n",
      "begun -> source\n",
      "begun -> source -> risks\n",
      "begun -> source -> risks -> civilization\n",
      "begun -> source -> risks -> civilization -> humans\n",
      "begun -> source -> risks -> civilization -> earth\n",
      "begun -> source -> risks -> civilization -> earth -> planet\n",
      "ensure -> proposal\n",
      "ensure -> ai\n",
      "ensure -> ai -> ai\n",
      "ensure -> ai -> ais\n",
      "question -> kind\n",
      "question -> kind -> check\n",
      "question -> place\n",
      "writes -> researcher\n",
      "writes -> rodney\n",
      "writes -> rodney -> brooks\n",
      "writes -> mistake\n",
      "writes -> mistake -> ai\n",
      "writes -> mistake -> years\n",
      "think -> worry\n",
      "think -> error\n",
      "think -> difference\n",
      "think -> difference -> advances\n",
      "think -> difference -> advances -> aspect\n",
      "think -> difference -> advances -> aspect -> ai\n",
      "think -> difference -> advances -> aspect -> ai -> enormity\n",
      "think -> difference -> advances -> aspect -> ai -> enormity -> complexity\n",
      "think -> difference -> advances -> aspect -> ai -> enormity -> intelligence\n",
      "sentient -> system\n",
      "sentient -> system\n",
      "sentient -> system -> ai\n",
      "sentient -> aspects\n",
      "sentient -> aspects -> intelligence\n",
      "sentient -> mind\n",
      "sentient -> mind -> experiences\n",
      "related -> question\n",
      "related -> problem\n",
      "related -> nature\n",
      "related -> nature -> consciousness\n",
      "related -> nature -> problem\n",
      "related -> nature -> problem -> consciousness\n",
      "identified -> david\n",
      "identified -> david -> chalmers\n",
      "identified -> problems\n",
      "identified -> problems -> mind\n",
      "identified -> problems -> mind -> problems\n",
      "identified -> problems -> mind -> problems -> consciousness\n",
      "understanding -> problem\n",
      "understanding -> brain\n",
      "understanding -> signals\n",
      "understanding -> plans\n",
      "understanding -> plans -> behavior\n",
      "understanding -> plans -> behavior -> controls\n",
      "explaining -> problem\n",
      "explaining -> anything\n",
      "easy -> processing\n",
      "easy -> processing -> information\n",
      "easy -> experience\n",
      "consider -> example\n",
      "consider -> person\n",
      "consider -> swatch\n",
      "consider -> swatch -> color\n",
      "requires -> problem\n",
      "requires -> machinery\n",
      "requires -> machinery -> brain\n",
      "requires -> machinery -> brain -> person\n",
      "requires -> machinery -> brain -> swatch\n",
      "requires -> machinery -> brain -> swatch -> color\n",
      "is -> problem\n",
      "is -> people\n",
      "is -> something\n",
      "is -> red\n",
      "consider -> person\n",
      "consider -> something\n",
      "consider -> red\n",
      "knows -> everyone\n",
      "knows -> experience\n",
      "knows -> day\n",
      "knows -> people\n",
      "knows -> red\n",
      "explaining -> problem\n",
      "explaining -> brain\n",
      "explaining -> knowledge\n",
      "explaining -> knowledge -> aspects\n",
      "explaining -> knowledge -> aspects -> brain\n",
      "position -> computationalism\n",
      "position -> philosophy\n",
      "position -> philosophy -> mind\n",
      "position -> system\n",
      "position -> system -> mind\n",
      "position -> system -> mind -> brain\n",
      "position -> system -> processing\n",
      "position -> system -> processing -> information\n",
      "position -> system -> form\n",
      "position -> system -> form -> computing\n",
      "argues -> computationalism\n",
      "argues -> relationship\n",
      "argues -> relationship -> mind\n",
      "argues -> relationship -> mind -> body\n",
      "argues -> relationship\n",
      "argues -> relationship -> software\n",
      "argues -> relationship -> software -> hardware\n",
      "argues -> solution\n",
      "argues -> solution -> problem\n",
      "inspired -> position\n",
      "inspired -> work\n",
      "inspired -> work -> researchers\n",
      "inspired -> work -> researchers -> ai\n",
      "inspired -> work -> researchers -> scientists\n",
      "inspired -> 1960s\n",
      "inspired -> philosophers\n",
      "inspired -> philosophers -> jerry\n",
      "inspired -> philosophers -> jerry -> fodor\n",
      "inspired -> philosophers -> jerry -> hilary\n",
      "inspired -> philosophers -> jerry -> hilary -> putnam\n",
      "have -> position\n",
      "have -> position -> john\n",
      "have -> position -> john -> searle\n",
      "have -> position -> states\n",
      "have -> position -> states -> ai\n",
      "have -> computer\n",
      "have -> computer -> inputs\n",
      "have -> computer -> inputs -> outputs\n",
      "have -> mind\n",
      "have -> mind -> sense\n",
      "have -> mind -> sense -> beings\n",
      "have -> mind -> sense -> minds\n",
      "counters -> searle\n",
      "counters -> assertion\n",
      "counters -> argument\n",
      "counters -> argument -> room\n",
      "counters -> argument -> computer\n",
      "counters -> argument -> mind\n",
      "feel -> machine\n",
      "feel -> intelligence\n",
      "have -> rights\n",
      "have -> human\n",
      "considered -> issue\n",
      "considered -> issue -> rights\n",
      "considered -> issue -> rights -> robot\n",
      "considered -> example\n",
      "considered -> institute\n",
      "considered -> institute -> california\n",
      "considered -> institute -> future\n",
      "considered -> critics\n",
      "considered -> discussion\n",
      "argue -> critics\n",
      "argue -> critics -> transhumanism\n",
      "argue -> rights\n",
      "argue -> rights -> robot\n",
      "argue -> spectrum\n",
      "argue -> spectrum -> rights\n",
      "argue -> spectrum -> rights -> animal\n",
      "argue -> spectrum -> rights -> rights\n",
      "discussed -> subject\n",
      "discussed -> film\n",
      "discussed -> film -> documentary\n",
      "discussed -> film -> plug\n",
      "discussed -> film -> plug -> pray\n",
      "discussed -> film -> media\n",
      "discussed -> film -> media -> sci\n",
      "discussed -> film -> media -> fi\n",
      "discussed -> film -> media -> generation\n",
      "discussed -> film -> media -> generation -> trek\n",
      "discussed -> film -> media -> generation -> trek -> star\n",
      "discussed -> film -> media -> generation -> next\n",
      "discussed -> film -> media -> character\n",
      "discussed -> film -> media -> character -> data\n",
      "discussed -> film -> media -> character -> data -> commander\n",
      "discussed -> film -> media -> character -> data -> research\n",
      "discussed -> film -> media -> character -> data -> holograms\n",
      "discussed -> film -> media -> character -> data -> holograms -> voyager\n",
      "are -> limits\n",
      "are -> machines\n",
      "are -> machines -> hybrids\n",
      "agent -> superintelligence\n",
      "agent -> superintelligence -> hyperintelligence\n",
      "agent -> superintelligence -> intelligence\n",
      "agent -> intelligence\n",
      "agent -> mind\n",
      "refer -> superintelligence\n",
      "refer -> form\n",
      "refer -> form -> degree\n",
      "refer -> form -> intelligence\n",
      "refer -> form -> intelligence -> agent\n",
      "able -> research\n",
      "able -> software\n",
      "better -> software\n",
      "better -> self-improvement\n",
      "increase -> intelligence\n",
      "increase -> humans\n",
      "named -> writer\n",
      "named -> writer -> fiction\n",
      "named -> writer -> fiction -> science\n",
      "named -> writer -> vernor\n",
      "named -> writer -> vernor -> vinge\n",
      "named -> scenario\n",
      "named -> singularity\n",
      "is -> singularity\n",
      "is -> progress\n",
      "is -> progress -> technologies\n",
      "is -> effect\n",
      "is -> intelligence\n",
      "is -> capacity\n",
      "is -> capacity -> control\n",
      "is -> civilization\n",
      "occurrence -> capabilities\n",
      "occurrence -> capabilities -> intelligence\n",
      "occurrence -> singularity\n",
      "occurrence -> events\n",
      "used -> ray\n",
      "used -> ray -> kurzweil\n",
      "used -> law\n",
      "used -> law -> moore\n",
      "used -> law -> improvement\n",
      "used -> law -> improvement -> technology\n",
      "used -> computers\n",
      "used -> computers -> desktop\n",
      "used -> power\n",
      "used -> power -> processing\n",
      "used -> power -> brains\n",
      "used -> year\n",
      "used -> singularity\n",
      "predicted -> designer\n",
      "predicted -> designer -> robot\n",
      "predicted -> hans\n",
      "predicted -> hans -> moravec\n",
      "predicted -> hans -> kevin\n",
      "predicted -> hans -> kevin -> warwick\n",
      "predicted -> hans -> kevin -> ray\n",
      "predicted -> hans -> kevin -> ray -> inventor\n",
      "predicted -> hans -> kevin -> ray -> kurzweil\n",
      "predicted -> humans\n",
      "predicted -> humans -> machines\n",
      "predicted -> future\n",
      "predicted -> cyborgs\n",
      "has -> idea\n",
      "has -> idea -> transhumanism\n",
      "has -> roots\n",
      "has -> roots -> aldous\n",
      "has -> roots -> aldous -> huxley\n",
      "has -> roots -> aldous -> robert\n",
      "has -> roots -> aldous -> robert -> ettinger\n",
      "argues -> edward\n",
      "argues -> edward -> fredkin\n",
      "argues -> stage\n",
      "argues -> stage -> intelligence\n",
      "argues -> stage -> evolution\n",
      "argues -> stage -> idea\n",
      "argues -> stage -> idea -> darwin\n",
      "argues -> stage -> idea -> darwin -> samuel\n",
      "argues -> stage -> idea -> darwin -> samuel -> butler\n",
      "argues -> stage -> idea -> darwin -> machines\n",
      "argues -> stage -> idea -> george\n",
      "argues -> stage -> idea -> george -> dyson\n",
      "argues -> stage -> idea -> book\n",
      "argues -> stage -> idea -> book -> name\n",
      "uncertain -> effects\n",
      "uncertain -> effects -> ai\n",
      "showed -> survey\n",
      "showed -> survey -> economists\n",
      "showed -> disagreement\n",
      "showed -> use\n",
      "showed -> use -> robots\n",
      "showed -> use -> robots -> ai\n",
      "showed -> increase\n",
      "showed -> increase -> unemployment\n",
      "showed -> benefit\n",
      "showed -> benefit -> net\n",
      "showed -> benefit -> gains\n",
      "showed -> benefit -> gains -> productivity\n",
      "advocated -> paper\n",
      "advocated -> paper -> february\n",
      "advocated -> paper -> union\n",
      "advocated -> paper -> intelligence\n",
      "advocated -> intelligence\n",
      "advocated -> intelligence -> benefits\n",
      "advocated -> intelligence -> benefits -> healthcare\n",
      "advocated -> intelligence -> benefits -> diagnosis\n",
      "advocated -> intelligence -> benefits -> prevention\n",
      "advocated -> intelligence -> benefits -> prevention -> diseases\n",
      "advocated -> intelligence -> benefits -> efficiency\n",
      "advocated -> intelligence -> benefits -> efficiency -> farming\n",
      "advocated -> intelligence -> benefits -> mitigation\n",
      "advocated -> intelligence -> benefits -> mitigation -> change\n",
      "advocated -> intelligence -> benefits -> mitigation -> change -> climate\n",
      "advocated -> intelligence -> benefits -> mitigation -> adaptation\n",
      "advocated -> intelligence -> benefits -> efficiency\n",
      "advocated -> intelligence -> benefits -> efficiency -> systems\n",
      "advocated -> intelligence -> benefits -> efficiency -> systems -> production\n",
      "advocated -> intelligence -> benefits -> efficiency -> systems -> maintenance\n",
      "advocated -> intelligence -> benefits -> risks\n",
      "considered -> development\n",
      "considered -> development -> policies\n",
      "considered -> development -> policies -> sector\n",
      "considered -> development -> policies -> intelligence\n",
      "considered -> development -> policies -> intelligence -> ai\n",
      "considered -> ai\n",
      "considered -> risks\n",
      "called -> elon\n",
      "called -> elon -> musk\n",
      "called -> regulation\n",
      "called -> regulation -> development\n",
      "called -> regulation -> development -> ai\n",
      "have -> states\n",
      "have -> policies\n",
      "have -> policies -> development\n",
      "have -> policies -> development -> place\n",
      "have -> february\n",
      "have -> union\n",
      "have -> union -> european\n",
      "have -> paper\n",
      "have -> paper -> strategy\n",
      "have -> paper -> strategy -> draft\n",
      "have -> ai\n",
      "appeared -> beings\n",
      "appeared -> devices\n",
      "appeared -> devices -> storytelling\n",
      "appeared -> antiquity\n",
      "appeared -> theme\n",
      "appeared -> theme -> fiction\n",
      "appeared -> theme -> fiction -> science\n",
      "began -> trope\n",
      "began -> trope -> works\n",
      "began -> frankenstein\n",
      "began -> frankenstein -> mary\n",
      "began -> frankenstein -> mary -> shelley\n",
      "began -> frankenstein -> creation\n",
      "began -> frankenstein -> threat\n",
      "began -> frankenstein -> threat -> masters\n",
      "includes -> works\n",
      "includes -> hal\n",
      "includes -> hal -> computer\n",
      "includes -> hal -> computer -> charge\n",
      "includes -> hal -> computer -> charge -> spaceship\n",
      "includes -> hal -> computer -> charge -> spaceship -> one\n",
      "includes -> hal -> computer -> charge -> spaceship -> one -> discovery\n",
      "includes -> hal -> computer -> charge -> spaceship -> terminator\n",
      "includes -> hal -> computer -> charge -> spaceship -> terminator -> matrix\n",
      "prominent -> contrast\n",
      "prominent -> robots\n",
      "prominent -> robots -> gort\n",
      "prominent -> robots -> gort -> day\n",
      "prominent -> robots -> gort -> day -> earth\n",
      "prominent -> robots -> gort -> day -> earth -> stood\n",
      "prominent -> robots -> gort -> bishop\n",
      "prominent -> robots -> gort -> bishop -> aliens\n",
      "prominent -> culture\n",
      "introduced -> isaac\n",
      "introduced -> isaac -> asimov\n",
      "introduced -> laws\n",
      "introduced -> laws -> three\n",
      "introduced -> laws -> robotics\n",
      "introduced -> books\n",
      "introduced -> books -> stories\n",
      "introduced -> books -> series\n",
      "introduced -> books -> series -> multivac\n",
      "introduced -> books -> series -> computer\n",
      "introduced -> books -> series -> computer -> name\n",
      "brought -> laws\n",
      "brought -> laws -> asimov\n",
      "brought -> discussions\n",
      "brought -> discussions -> ethics\n",
      "brought -> discussions -> ethics -> machine\n",
      "brought -> researchers\n",
      "brought -> researchers -> intelligence\n",
      "brought -> laws\n",
      "brought -> laws -> asimov\n",
      "brought -> laws -> culture\n",
      "brought -> laws\n",
      "brought -> laws -> reasons\n",
      "brought -> laws -> reasons -> ambiguity\n",
      "explored -> transhumanism\n",
      "explored -> transhumanism -> merging\n",
      "explored -> transhumanism -> merging -> humans\n",
      "explored -> transhumanism -> merging -> humans -> machines\n",
      "explored -> manga\n",
      "explored -> ghost\n",
      "explored -> ghost -> shell\n",
      "explored -> ghost -> series\n",
      "explored -> ghost -> series -> science-fiction\n",
      "explored -> ghost -> series -> dune\n",
      "painted -> 1980s\n",
      "painted -> series\n",
      "painted -> series -> artist\n",
      "painted -> series -> hajime\n",
      "painted -> series -> hajime -> sorayama's\n",
      "painted -> series -> robots\n",
      "painted -> series -> robots -> sexy\n",
      "painted -> japan\n",
      "painted -> form\n",
      "painted -> form -> skins\n",
      "painted -> form -> skins -> book\n",
      "painted -> form -> skins -> book -> gynoids\n",
      "painted -> form -> skins -> book -> makers\n",
      "painted -> form -> skins -> book -> makers -> movie\n",
      "painted -> form -> skins -> book -> makers -> george\n",
      "painted -> form -> skins -> book -> makers -> george -> lucas\n",
      "painted -> form -> skins -> book -> makers -> george -> creatives\n",
      "considered -> sorayama\n",
      "considered -> robots\n",
      "considered -> robots -> organic\n",
      "considered -> part\n",
      "considered -> part -> nature\n",
      "considered -> part -> product\n",
      "considered -> part -> product -> mind\n",
      "considered -> part -> product -> fantasy\n",
      "considered -> part -> product -> fantasy -> mind\n",
      "considered -> part -> product -> fantasy -> form\n",
      "ai -> works\n",
      "ai -> question\n",
      "ai -> question -> beings\n",
      "ai -> question -> beings -> ability\n",
      "appears -> r.u.r.\n",
      "appears -> r.u.r. -> karel\n",
      "appears -> r.u.r. -> karel -> čapek\n",
      "appears -> r.u.r. -> films\n",
      "appears -> r.u.r. -> films -> intelligence\n",
      "appears -> r.u.r. -> films -> intelligence -> a.i.\n",
      "appears -> r.u.r. -> films -> intelligence -> artificial\n",
      "appears -> r.u.r. -> machina\n",
      "appears -> r.u.r. -> machina -> ex\n",
      "appears -> r.u.r. -> novel\n",
      "appears -> r.u.r. -> novel -> androids\n",
      "appears -> r.u.r. -> novel -> dream\n",
      "appears -> r.u.r. -> novel -> dream -> sheep\n",
      "appears -> r.u.r. -> novel -> dream -> sheep -> electric\n",
      "appears -> r.u.r. -> novel -> philip\n",
      "appears -> r.u.r. -> novel -> philip -> k.\n",
      "appears -> r.u.r. -> novel -> philip -> dick\n",
      "considers -> dick\n",
      "considers -> idea\n",
      "considers -> idea -> understanding\n",
      "considers -> idea -> understanding -> subjectivity\n",
      "considers -> idea -> technology\n",
      "considers -> idea -> technology -> intelligence\n"
     ]
    }
   ],
   "source": [
    "def _find_node(word: Word, component: list, paths: list) -> None:\n",
    "    for child in word.children:\n",
    "        new_tab = component.copy()\n",
    "        if child.pos.startswith(\"N\"):\n",
    "            new_tab.append(child.text)\n",
    "            paths.append(\" -> \".join(new_tab))\n",
    "        _find_node(child, new_tab, paths)\n",
    "\n",
    "_paths = []\n",
    "for sentence in _sentences:\n",
    "    for word in sentence:\n",
    "        if word.head == -1:\n",
    "            path = [word.text]\n",
    "            _find_node(word, path, _paths)\n",
    "            \n",
    "for path in _paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 49. Extract the shortest path between two nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X <- Y\n",
      "X <- science <- Y\n",
      "X <- science <- intelligence -> Y\n",
      "X <- science <- intelligence -> intelligence <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- intelligence -> Y\n",
      "X <- intelligence -> intelligence <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- intelligence -> Y\n",
      "X <- intelligence -> science -> Y\n",
      "X <- Y\n",
      "X <- intelligence <- Y\n",
      "X <- intelligence <- intelligence -> Y\n",
      "X <- intelligence <- intelligence -> science -> Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- science -> Y\n",
      "X <- intelligence <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- agents <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- agents -> Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- learning <- Y\n",
      "X <- learning <- solving -> Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- solving -> Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- learning -> Y\n",
      "X <- Y\n",
      "X <- solving -> Y\n",
      "X <- solving -> learning -> Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- definition <- Y\n",
      "X <- Y\n",
      "X <- definition <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n",
      "X <- Y\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def _add_node(word: Word, g: object) -> None:\n",
    "    if word.pos.startswith(\"N\"):\n",
    "        g.add_node(word.id)\n",
    "        for child in word.children:\n",
    "            if child.pos.startswith(\"N\"):\n",
    "                g.add_edge(word.id, child.id)\n",
    "            _add_node(child, g)\n",
    "\n",
    "for sentence in _sentences[:5]:\n",
    "    graph = nx.Graph()\n",
    "    for word in sentence:\n",
    "        _add_node(word, graph)\n",
    "    paths = dict(nx.all_pairs_shortest_path(graph))\n",
    "    for begin_node in paths:\n",
    "        for end_node in paths[begin_node]:\n",
    "            path_length = len(paths[begin_node][end_node])\n",
    "            for index in range(0, path_length-1):\n",
    "                path_node = paths[begin_node][end_node][index]\n",
    "                next_node = paths[begin_node][end_node][index+1]\n",
    "                if path_node == begin_node:\n",
    "                    print(\"X <- \", end='') \n",
    "                elif path_node > next_node:\n",
    "                    print(f\"{sentence[path_node].text} -> \", end='')\n",
    "                elif path_node < next_node:\n",
    "                    print(f\"{sentence[path_node].text} <- \", end='')\n",
    "            if path_length > 1:\n",
    "                print(\"Y\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
